{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/osss-mcr/blob/coords7/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f871f0d-a9f0-4be5-fa50-23f55f526462"
      },
      "source": [
        "!pip install icecream\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/lm_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.8.0)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.7/dist-packages (0.9.19)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.7/dist-packages (from kora) (1.3.26)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d313f56-7729-494b-e374-5e1a7fb4638a"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "9f07a4cc-246c-4b04-e2f9-afa6f36be629"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf osss-mcr\n",
        "  !git clone --branch coords7 https://github.com/DiMorten/osss-mcr.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'osss-mcr'...\n",
            "remote: Enumerating objects: 2530, done.\u001b[K\n",
            "remote: Counting objects: 100% (329/329), done.\u001b[K\n",
            "remote: Compressing objects: 100% (242/242), done.\u001b[K\n",
            "remote: Total 2530 (delta 224), reused 153 (delta 62), pack-reused 2201\u001b[K\n",
            "Receiving objects: 100% (2530/2530), 37.66 MiB | 25.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1690/1690), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/lm_data /content/osss-mcr/dataset/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f590a5-2ba5-44d5-af7c-04649c3f0cf9"
      },
      "source": [
        "os.chdir('/content/osss-mcr/')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['obj',\n",
              " 'evaluate_open_set.py',\n",
              " 'parameters',\n",
              " 'README.md',\n",
              " 'train_and_evaluate_open_set.ipynb',\n",
              " '__init__.py',\n",
              " '.gitignore',\n",
              " 'dataset',\n",
              " 'train_and_evaluate_openset.ipynb',\n",
              " '.git',\n",
              " 'evaluate.py',\n",
              " 'deb.py',\n",
              " 'train_and_evaluate.ipynb',\n",
              " 'environment.yml',\n",
              " 'train_and_evaluate_open_set.py',\n",
              " 'train_and_evaluate.py',\n",
              " 'src']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from src.densnet import DenseNetFCN\n",
        "from src.densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from src.keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from tensorflow.keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from tensorflow.keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#from datagenerator import DataGenerator\n",
        "from src.generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from src.dataSource import DataSource, SARSource, Dataset, LEM, LEM2, CampoVerde\n",
        "from src.model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.params_train import ParamsTrain\n",
        "from parameters.params_mosaic import ParamsReconstruct\n",
        "\n",
        "from icecream import ic\n",
        "from src.monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from src.model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from src.dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from src.patch_extractor import PatchExtractor\n",
        "\n",
        "from src.mosaic import seq_add_padding, add_padding, Mosaic, MosaicHighRAM, MosaicHighRAMPostProcessing\n",
        "from src.postprocessing import PostProcessingMosaic\n",
        "\n",
        "from src.metrics import Metrics, MetricsTranslated\n",
        "\n",
        "ic.configureOutput(includeContext=True)\n",
        "np.random.seed(2021)\n",
        "tf.random.set_seed(2021)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "\n",
        "from train_and_evaluate import TrainTest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f449e4-041f-4c60-d2f8-9c3addccbd5c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  8 20:40:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/osss-mcr/networks/convlstm_networks/train_src/parameters/params_train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb4082f-477c-4062-c3e4-05c78985a2a2"
      },
      "source": [
        "paramsTrainCustom = {\n",
        "\t'getFullIms': True,\n",
        "\t'coordsExtract': True,\n",
        "\t'train': True,\n",
        "\t'openSetMethod': None, # Options: None, OpenPCS, OpenPCS++\n",
        "#\t\t'openSetLoadModel': True,\n",
        "\t'selectMainClasses': True,\n",
        "\t'dataset': 'lm', # lm: L Eduardo Magalhaes.\n",
        "\t'seq_date': 'mar',\t# jun, mar\t\n",
        "    'dataSource': SARSource()\n",
        "}\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/', **paramsTrainCustom)\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] params_train.py:107 in __init__()- self.seq_date: 'mar'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] params_train.py:166 in __init__()- self.stride: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no_mode.json', 'parameters_openset.json', 'params_batchprocessing.py', '__init__.py', '__pycache__', 'parameters_closedset_groupclasses.json', 'params_mosaic.py', 'save_nonaugmented_train_patches.json', 'params_train.py']\n",
            "[@debug] self.seq_mode = fixed\n",
            "[@debug] self.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7f18177e8bd0>\n",
            "[@debug] self.ds = <src.dataSource.LEM object at 0x7f18177a5310>\n",
            "[@debug] dataSource.name = SARSource\n",
            "self.im_list ['20170413_S1', '20170519_S1', '20170612_S1', '20170706_S1', '20170811_S1', '20170916_S1', '20171010_S1', '20171115_S1', '20171209_S1', '20180114_S1', '20180219_S1', '20180315_S1']\n",
            "fixed mar\n",
            "[@debug] self.t_len = 12\n",
            "20170413\n",
            "20170519\n",
            "20170612\n",
            "20170706\n",
            "20170811\n",
            "20170916\n",
            "20171010\n",
            "20171115\n",
            "20171209\n",
            "20180114\n",
            "20180219\n",
            "20180315\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[103, 139, 163, 187, 223, 259, 283, 319, 343, 14, 50, 74]\n",
            "[[0.9917   0.4104  ]\n",
            " [0.849    0.142   ]\n",
            " [0.6763   0.03214 ]\n",
            " [0.4744   0.000663]\n",
            " [0.1897   0.1079  ]\n",
            " [0.01993  0.3604  ]\n",
            " [0.00414  0.564   ]\n",
            " [0.133    0.84    ]\n",
            " [0.2998   0.958   ]\n",
            " [0.611    0.988   ]\n",
            " [0.8726   0.8335  ]\n",
            " [0.975    0.6562  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-XFXeoNjGXSo",
        "outputId": "94bf8d3b-1c5d-436f-aea7-c754281be1aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "trainTest.main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <src.dataSource.SARSource object at 0x7f1879e8e910>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('dataset/lm_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('dataset/lm_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/osss-mcr'\n",
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8484, 8658, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20170413_S1',\n",
            "                                '20170519_S1',\n",
            "                                '20170612_S1',\n",
            "                                '20170706_S1',\n",
            "                                '20170811_S1',\n",
            "                                '20170916_S1',\n",
            "                                '20171010_S1',\n",
            "                                '20171115_S1',\n",
            "                                '20171209_S1',\n",
            "                                '20180114_S1',\n",
            "                                '20180219_S1',\n",
            "                                '20180315_S1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170413_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.136962890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 133.125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "dataset/lm_data/labels/20170413_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170413_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "1 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170519_S1.npy\n"
          ]
        }
      ]
    }
  ]
}