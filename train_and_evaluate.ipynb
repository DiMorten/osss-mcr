{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set/blob/coords5/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5d3244-8ba1-4b20-9e05-65790ddcaad6"
      },
      "source": [
        "!pip install icecream\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/cv_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.0 icecream-2.1.1\n",
            "Collecting kora\n",
            "  Downloading kora-0.9.19-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting fastcore\n",
            "  Downloading fastcore-1.3.26-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Installing collected packages: fastcore, kora\n",
            "Successfully installed fastcore-1.3.26 kora-0.9.19\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb5ffeb-db25-4c13-dd73-609888677e82"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "355a04c5-1d20-4ad3-c071-de557ca435ce"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf FCN_ConvLSTM_Crop_Recognition_Open_Set\n",
        "  !git clone --branch coords5 https://github.com/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FCN_ConvLSTM_Crop_Recognition_Open_Set'...\n",
            "remote: Enumerating objects: 2189, done.\u001b[K\n",
            "remote: Counting objects: 100% (2189/2189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1618/1618), done.\u001b[K\n",
            "remote: Total 2189 (delta 1440), reused 1062 (delta 366), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2189/2189), 37.52 MiB | 29.35 MiB/s, done.\n",
            "Resolving deltas: 100% (1440/1440), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/cv_data /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18461916-1b98-4653-a0d1-29212fe8896e"
      },
      "source": [
        "os.chdir('/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mosaic.py.old',\n",
              " 'postprocessing.py',\n",
              " 'model_input_mode.py',\n",
              " 'model_best_UUnet4ConvLSTM_jun_cv_criteria_0_92',\n",
              " 'densnet_timedistributed.py',\n",
              " '__init__.py',\n",
              " 'keras_weighted_categorical_crossentropy.py',\n",
              " 'deb.py',\n",
              " 'model.py',\n",
              " 'modelArchitecture.py',\n",
              " 'main.py',\n",
              " 'patch_extractor.py',\n",
              " 'parameters',\n",
              " 'mosaic.py',\n",
              " 'metrics.py',\n",
              " 'monitor.py',\n",
              " 'dataset.py',\n",
              " 'generator.py',\n",
              " 'open_set.py',\n",
              " 'obj',\n",
              " 'dataSource.py',\n",
              " 'densnet.py',\n",
              " 'analysis']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from densnet import DenseNetFCN\n",
        "from densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from tensorflow.keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from tensorflow.keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#from datagenerator import DataGenerator\n",
        "from generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from dataSource import DataSource, SARSource, OpticalSource, Dataset, LEM, LEM2, CampoVerde, OpticalSourceWithClouds, Humidity\n",
        "from model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.parameters_reader import ParamsTrain\n",
        "\n",
        "from icecream import ic\n",
        "from monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from patch_extractor import PatchExtractor\n",
        "ic.configureOutput(includeContext=False)\n",
        "np.random.seed(2021)\n",
        "tf.random.set_seed(2021)\n",
        "\n",
        "from main import TrainTest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b82085-c870-4a85-b557-727917031716"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 22 23:03:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/parameters/parameters_reader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc0931e-d849-4a39-a9a8-5286ac596868"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/')\n",
        "paramsTrain.mim = MIMFixed_PaddedSeq()\n",
        "\n",
        "paramsTrain.getFullIms = True\n",
        "paramsTrain.coordsExtract = True\n",
        "paramsTrain.train = True\n",
        "\n",
        "paramsTrain.train_overlap_percentage = 0\n",
        "paramsTrain.trainGeneratorRandom = False\n",
        "paramsTrain.patch_len = 32\n",
        "paramsTrain.stride = int(paramsTrain.patch_len - paramsTrain.patch_len * paramsTrain.train_overlap_percentage)\n",
        "paramsTrain.patch_step_train = paramsTrain.stride\n",
        "paramsTrain.patch_step_test = paramsTrain.patch_len # to do: paramsTrain.getCalculatedParams() does these calculations\n",
        "\n",
        "paramsTrain.dataset = 'cv'\n",
        "paramsTrain.seq_date = 'jun'\n",
        "paramsTrain.path = Path(\"../../../dataset/dataset/\") / (paramsTrain.dataset + \"_data\")\n",
        "\n",
        "paramsTrain.test_overlap_percentage = 0\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "paramsTrain.openSetMethod = None\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n",
        "patchExtractor = PatchExtractor(paramsTrain, trainTest.ds)\t"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:115 in __init__()- self.seq_date: 'mar'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:174 in __init__()- self.stride: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['parameters_reader.py', 'save_nonaugmented_train_patches_unknownclasses.json', 'save_nonaugmented_train_patches.json', 'cv', 'twokkc_parameters_closedset_groupclasses.json', 'twokkc_parameters_openset.json', '__pycache__', 'twokkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches_lessclass8.json', 'allkkc_save_nonaugmented_train_patches.json', 'params_batchprocessing.py', 'parameters_openset_lessclass8.json', '__init__.py', 'params_reconstruct.py', 'no_mode.json', 'allkkc_parameters_openset.json', 'parameters_openset.json', 'parameters_closedset_groupclasses.json', 'parameters_openset_specifyunknownclasses.json', 'parameters_closedset_groupclasses_lessclass8.json']\n",
            "[@debug] self.seq_mode = fixed\n",
            "[@debug] self.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7fd425ecec10>\n",
            "[@debug] self.ds = <dataSource.CampoVerde object at 0x7fd4264cab10>\n",
            "20151029\n",
            "20151110\n",
            "20151122\n",
            "20151204\n",
            "20151216\n",
            "20160121\n",
            "20160214\n",
            "20160309\n",
            "20160321\n",
            "20160508\n",
            "20160520\n",
            "20160613\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[302, 314, 326, 338, 350, 21, 45, 69, 81, 129, 141, 165]\n",
            "[[0.05084 0.7197 ]\n",
            " [0.1053  0.807  ]\n",
            " [0.1764  0.8813 ]\n",
            " [0.2612  0.9395 ]\n",
            " [0.3562  0.979  ]\n",
            " [0.6685  0.9707 ]\n",
            " [0.843   0.8643 ]\n",
            " [0.96    0.6963 ]\n",
            " [0.99    0.598  ]\n",
            " [0.905   0.2068 ]\n",
            " [0.8364  0.1301 ]\n",
            " [0.66    0.02637]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <dataSource.SARSource object at 0x7fd425ff8e10>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('../../../dataset/dataset/cv_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('../../../dataset/dataset/cv_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqA-z0Ju9-xO"
      },
      "source": [
        "## Download or load sequence of images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaFQV6M9yKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b28e97-2b48-4e29-fe12-ece010cd9ae5"
      },
      "source": [
        "if paramsTrain.getFullIms == True:\n",
        "  patchExtractor.getFullIms()\t\n",
        "else:\n",
        "  patchExtractor.fullImsLoad()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8492, 7995, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20151029_S1',\n",
            "                                '20151110_S1',\n",
            "                                '20151122_S1',\n",
            "                                '20151204_S1',\n",
            "                                '20151216_S1',\n",
            "                                '20160121_S1',\n",
            "                                '20160214_S1',\n",
            "                                '20160309_S1',\n",
            "                                '20160321_S1',\n",
            "                                '20160508_S1',\n",
            "                                '20160520_S1',\n",
            "                                '20160613_S1']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151029_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1871337890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 4.172325134277344e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151029_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151029_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    45178,    51808,   131138,   438371,   155189,\n",
            "        5136068,     1007,   156217]))\n",
            "1 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151110_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.180419921875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.9267578125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 2.384185791015625e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151110_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151110_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1524080,    27056,    11783,   432952,   419824,\n",
            "         155189,  3386868,     1007,   156217]))\n",
            "2 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151122_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1802978515625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.7099609375\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 2.384185791015625e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151122_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151122_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1524080,    27056,    11783,   432952,   419824,\n",
            "         155189,  3386868,     1007,   156217]))\n",
            "3 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151204_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1793212890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.447265625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 1.1920928955078125e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151204_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151204_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  4496663,    35095,    18211,     2197,    11783,\n",
            "         366875,   419824,   155189,   451915,     1007,   156217]))\n",
            "4 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151216_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1737060546875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.373046875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 1.7881393432617188e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151216_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151216_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  4496663,    35095,    18211,     2197,    11783,\n",
            "         366875,   419824,   155189,   451915,     1007,   156217]))\n",
            "5 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160121_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.159912109375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 138.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 3.2186508178710938e-06\n",
            "../../../dataset/dataset/cv_data/labels/20160121_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160121_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2956904,     8039,    18211,     2197,     8859,\n",
            "         419824,   155189,  2388529,     1007,   156217]))\n",
            "6 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160214_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.171630859375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.4169921875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 7.748603820800781e-07\n",
            "../../../dataset/dataset/cv_data/labels/20160214_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160214_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2183414,     8039,   116684,     2197,     8006,\n",
            "         419824,   155189,  3064399,     1007,   156217]))\n",
            "7 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160309_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.188232421875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 2.869140625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 3.5762786865234375e-07\n",
            "../../../dataset/dataset/cv_data/labels/20160309_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160309_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    10049,   900649,  2084968,     2197,     8006,\n",
            "         419824,   155189,  2376870,     1007,   156217]))\n",
            "8 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160321_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.16064453125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.5390625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160321_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160321_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    10049,   900649,  2084968,     2197,     8006,\n",
            "         419824,   155189,  2376870,     1007,   156217]))\n",
            "9 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160508_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.154541015625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.1572265625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160508_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160508_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2187712,  2771075,    57536,     2285,   236822,\n",
            "         525054,   155189,    22079,     1007,   156217]))\n",
            "10 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160520_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.16552734375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.634765625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160520_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160520_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2187712,  2771075,    57536,     2285,   236822,\n",
            "         525054,   155189,    22079,     1007,   156217]))\n",
            "11 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160613_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.140380859375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 4.57421875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160613_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160613_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1441022,  2573657,    57536,   225585,   525054,\n",
            "         155189,   979709,     1007,   156217]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataSource.py:369 in im_load()\n",
            "         patch[\"full_ims\"].shape: (12, 8492, 7995, 2)\n",
            "[@debug] dataSource.py:370 in im_load()\n",
            "         patch[\"full_label_ims\"].shape: (12, 8492, 7995)\n",
            "[@debug] dataSource.py:371 in im_load()\n",
            "         patch[\"full_ims\"].dtype: dtype('float16')\n",
            "[@debug] dataSource.py:372 in im_load()\n",
            "         patch[\"full_label_ims\"].dtype: dtype('int8')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] np.unique(patch['full_label_ims'],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([741342768,  17247080,   7809932,  12457060,    185790,     51702,\n",
            "         2462898,   5372125,   1862268,  24044169,     12084,   1874604]))\n",
            "0.0 1.0 0.1702\n",
            "[@debug] self.dataset.name = cv\n",
            "[@debug] self.dataset.scaler_name = cv\n",
            "[@debug] self.dataset.seq_mode = fixed\n",
            "[@debug] self.dataset.seq_date = jun\n",
            "[@debug] self.dataset.scaler_load = False\n",
            "[@debug] im.shape = (12, 8492, 7995, 2)\n",
            "[@debug] im_flat[mask_flat==1,:].shape = (38664648, 2)\n",
            "0.0001407 1.0 0.0779\n",
            "[@debug] im_norm.shape = (12, 8492, 7995, 2)\n",
            "FINISHED NORMALIZING, RESULT:\n",
            "-1.432 51.53 3.117\n",
            "[@debug] im.shape = (12, 8492, 7995)\n",
            "[@debug] mask_train.shape = (8492, 7995)\n",
            "[@debug] im.dtype = uint8\n",
            "[@debug] mask_train.dtype = uint8\n",
            "[@debug] im_train.shape = (12, 8492, 7995)\n",
            "Train masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11] [776057832   9399025   4170646   6930141    103494     34628   1280237\n",
            "   2371008    861648  12705225      8388    800208]\n",
            "Test masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11] [780007416   7848055   3639286   5526919     82296     17074   1182661\n",
            "   3001117   1000620  11338944      3696   1074396]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:127 in getFullIms()\n",
            "         self.paramsTrain.path / 'full_ims/full_ims_test.npy': PosixPath('../../../dataset/dataset/cv_data/full_ims/full_ims_test.npy')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FPmIpS-Hqu"
      },
      "source": [
        "## Extract coords of image patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzJoNO896wl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da2f8c1-7384-46cb-dafd-7efac02c3576"
      },
      "source": [
        "\n",
        "if paramsTrain.coordsExtract == True:\n",
        "  patchExtractor.extract()\n",
        "\n",
        "del patchExtractor\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTED PATCH EXTRACTION\n",
            "[@debug] gridx.shape = (250,)\n",
            "[@debug] gridy.shape = (266,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:205 in extract()\n",
            "         coords_train.shape: (4983, 2)\n",
            "         coords_test.shape: (4626, 2)\n",
            "[@debug] patch_extractor.py:206 in extract()\n",
            "         coords_train.dtype: dtype('int64')\n",
            "[@debug] patch_extractor.py:207 in extract()\n",
            "         coords_train[0]: array([7568,  656])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZztSJXG977M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79fefe14-f33f-4b64-b1d4-56c089657a08"
      },
      "source": [
        "\ttrainTest.setData()\n",
        "\n",
        "\n",
        "\ttrainTest.preprocess(paramsTrain.model_name_id) # move into if\n",
        "\n",
        "\ttrainTest.setModel()\n",
        "\n",
        "\tif paramsTrain.train == True:\n",
        "\t\ttrainTest.train()\n",
        "\telse:\n",
        "\t\ttrainTest.modelLoad(paramsTrain.model_name_id)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:96 in __init__()- self.class_n: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] self.t_len = 12\n",
            "Initializing Dataset instance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] main.py:118 in setData()- self.data.class_n: 10\n",
            "[@debug] main.py:146 in preprocess()\n",
            "         self.model_name: '../results/convlstm_results/model/lm/model_best_UUnetConvLSTM_mar_lm_nomode.h5'\n",
            "[@debug] dataset.py:186 in create_load()\n",
            "         os.path.dirname(os.path.abspath(__file__)): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n",
            "[@debug] dataset.py:187 in create_load()\n",
            "         os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n",
            "[@debug] dataset.py:191 in create_load()\n",
            "         self.patches['train']['coords'].shape: (4983, 2)\n",
            "[@debug] dataset.py:284 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8),\n",
            "                                                                array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "                                                                         71804,   617076,      699,    66684]))\n",
            "[@debug] dataset.py:285 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8),\n",
            "                                                               array([65000618,   730790,  1199149,    25986,    88785,   312353,\n",
            "                                                                        83385,   362633,      308,    89533]))\n",
            "[@debug] dataset.py:289 in labelPreprocess()\n",
            "         self.paramsTrain.known_classes: array([ 1,  2,  3,  5,  6,  7,  8,  9, 10], dtype=uint8)\n",
            "[@debug] dataset.py:333 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8),\n",
            "                                                                array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "                                                                         71804,   617076,      699,    66684]))\n",
            "[@debug] dataset.py:339 in labelPreprocess()\n",
            "         self.classes: array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] np.unique(self.full_label_train, return_counts=True) = (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8), array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "          71804,   617076,      699,    66684]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:343 in labelPreprocess()\n",
            "         self.labels2new_labels: {0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8, 11: 9}\n",
            "         self.new_labels2labels: {0: 0, 1: 2, 2: 3, 3: 4, 4: 6, 5: 7, 6: 8, 7: 9, 8: 10, 9: 11}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Transforming labels2new_labels...\n",
            "Transformed labels2new_labels. Moving bcknd to last...\n",
            "[@debug] dict_filename = results/label_translations/new_labels2labels_cv_20160613_S1.pkl\n",
            "[@debug] self.new_labels2labels = {0: 0, 1: 2, 2: 3, 3: 4, 4: 6, 5: 7, 6: 8, 7: 9, 8: 10, 9: 11}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:364 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                                array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "                                                                         71804,   617076,      699,    66684]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Moved bcknd to last\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:373 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                                array([  710232,  1374508,    31550,   136800,   212701,    71804,\n",
            "                                                                        617076,      699,    66684, 64671486]))\n",
            "[@debug] dataset.py:374 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                               array([  730790,  1199149,    25986,    88785,   312353,    83385,\n",
            "                                                                       362633,      308,    89533, 65000618]))\n",
            "[@debug] dataset.py:377 in labelPreprocess()- self.class_n: 10\n",
            "[@debug] dataset.py:215 in create_load()\n",
            "         self.patches['train']['label'].shape: (4983, 32, 32)\n",
            "[@debug] dataset.py:216 in create_load()\n",
            "         np.unique(self.patches['train']['label'], return_counts = True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
            "                                                                           array([ 710232, 1374508,   31550,  136800,  212701,   71804,  617076,\n",
            "                                                                                     699,   66684, 1880538]))\n",
            "[@debug] dataset.py:217 in create_load()\n",
            "         self.patches['test']['label'].shape: (4626, 32, 32)\n",
            "[@debug] dataset.py:218 in create_load()\n",
            "         np.unique(self.patches['test']['label'], return_counts = True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
            "                                                                          array([ 730790, 1199149,   25986,   88785,  312353,   83385,  362633,\n",
            "                                                                                    308,   89533, 1844102]))\n",
            "[@debug] dataset.py:223 in create_load()\n",
            "         np.unique(self.full_label_train,return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                               array([  710232,  1374508,    31550,   136800,   212701,    71804,\n",
            "                                                                       617076,      699,    66684, 64671486]))\n",
            "[@debug] dataset.py:224 in create_load()- self.class_n: 10\n",
            "[@debug] main.py:151 in preprocess()- self.paramsTrain.class_n: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== SELECT VALIDATION SET FROM TRAIN SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] main.py:159 in preprocess()- self.paramsTrain.val_set: True\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] self.paramsTrain.val_set_mode = random\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:402 in val_set_get()\n",
            "         self.patches['train']['n']: 4983\n",
            "         self.patches['val']['n']: 747\n",
            "[@debug] dataset.py:403 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (4983, 2)\n",
            "[@debug] dataset.py:412 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (4236, 2)\n",
            "[@debug] dataset.py:413 in val_set_get()\n",
            "         self.patches['val']['coords'].shape: (747, 2)\n",
            "[@debug] main.py:163 in preprocess()\n",
            "         self.data.patches['val']['coords'].shape: (747, 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== AUGMENTING TRAINING DATA\n",
            "[@debug] label_type = Nto1\n",
            "Before balancing:\n",
            "data.semantic_balance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:439 in semantic_balance()\n",
            "         balance[\"coords\"].shape: (6300, 2)\n",
            "[@debug] dataset.py:443 in semantic_balance()\n",
            "         np.unique(self.full_label_train, return_counts = True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                                  array([  710232,  1374508,    31550,   136800,   212701,    71804,\n",
            "                                                                          617076,      699,    66684, 64671486]))\n",
            "[@debug] dataset.py:449 in semantic_balance()\n",
            "         coords_classes.shape: (4236, 10)\n",
            "[@debug] dataset.py:451 in semantic_balance()\n",
            "         unique_train: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n",
            "[@debug] dataset.py:453 in semantic_balance()- bcknd_idx: 9\n",
            "[@debug] dataset.py:455 in semantic_balance()- psize: 32\n",
            "[@debug] dataset.py:468 in semantic_balance()\n",
            "         patch_count: array([1055., 1820.,   55.,  196.,  352.,  125.,  882.,    6.,  120.,\n",
            "                                0.])\n",
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 1055.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 0\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([3181, 1055]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (1055, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 1820.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 1\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([2416, 1820]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (1820, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()- patch_count[clss]: 55.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 2\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4181,   55]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (55, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 196.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 3\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4040,  196]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (196, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 352.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 4\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([3884,  352]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (352, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 125.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 5\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4111,  125]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (125, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 882.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 6\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([3354,  882]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (882, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()- patch_count[clss]: 6.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 7\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4230,    6]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (6, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 120.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 8\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4116,  120]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (120, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 8\n",
            "Balanced train unique (coords):\n",
            "[@debug] self.patches['train']['coords'].shape = (6300, 2)\n",
            "[@debug] self.data.patches['train']['coords'].shape = (6300, 2)\n",
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n",
            "[@debug] self.t_len = 12\n",
            "Initializing Model instance\n",
            "[@debug] self.mp = {'dense': {'recurrent_filters': 128, 'nb_dense_block': 2, 'growth_rate': 64, 'nb_layers_per_block': 1}, 'unet': {'recurrent_filters': 128, 'filter_size': 16}, 'atrous': {'recurrent_filters': 128, 'filter_size': 16, 'dilation_rate_mode': 'auto', 'dilation_rates': [1, 2, 4, 8]}}\n",
            "[@debug] self.stop_epoch = 400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] main.py:132 in setModel()\n",
            "         self.model.name: PosixPath('../results/convlstm_results/model/lm/../results/convlstm_results/model/lm/model_best_UUnetConvLSTM_mar_lm_nomode.h5')\n",
            "[@debug] main.py:134 in setModel()- self.model.class_n: 9\n",
            "[@debug] main.py:135 in setModel()- self.data.class_n: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] self.data.class_n = 10\n",
            "[@debug] self.t_len = 12\n",
            "[@debug] self.model_t_len = 12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[@debug] K.int_shape(x) = (None, 12, 8, 8, 64)\n",
            "[@debug] K.int_shape(res2) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(p3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(d3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(x) = (None, 12, 16, 16, 32)\n",
            "[@debug] K.int_shape(res2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(p2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(d2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(x) = (None, 12, 32, 32, 16)\n",
            "[@debug] K.int_shape(res2) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(p1) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(d1) = (None, 32, 32, 16)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 32, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 12, 32, 32, 1 304         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 12, 32, 32, 1 64          time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 12, 32, 32, 1 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 12, 32, 32, 1 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 12, 32, 32, 1 64          time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 12, 32, 32, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 12, 16, 16, 1 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 12, 16, 16, 3 4640        time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 12, 16, 16, 3 128         time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 12, 16, 16, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 12, 8, 8, 32) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 12, 8, 8, 64) 18496       time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 12, 8, 8, 64) 256         time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 12, 8, 8, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 12, 4, 4, 64) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 4, 4, 256)    2950144     time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     147520      conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8, 8, 64)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 128)    0           activation_4[0][0]               \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 64)     73792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 32)   18464       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 16, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 64)   0           activation_6[0][0]               \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   18464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 16)   4624        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           activation_8[0][0]               \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   4624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 9)    153         activation_9[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,244,953\n",
            "Trainable params: 3,244,249\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "[@debug] model.py:243 in train()\n",
            "         data.patches['train']['coords'].shape: (6300, 2)\n",
            "[@debug] model.py:248 in train()- data.t_len: 12\n",
            "[@debug] model.py:249 in train()\n",
            "         data.full_ims_train.shape: (12, 8492, 7995, 2)\n",
            "[@debug] model.py:250 in train()- self.model_t_len: 12\n",
            "[@debug] dataset.py:386 in addPaddingToInput()\n",
            "         im.shape: (12, 8492, 7995, 2)\n",
            "[@debug] model.py:256 in train()\n",
            "         data.full_ims_train.shape: (12, 8492, 7995, 2)\n",
            "[@debug] model.py:311 in applyFitMethod()- self.class_n: 9\n",
            "[@debug] model.py:330 in applyFitMethod()\n",
            "         data.patches['train']['coords'].shape: (6300, 2)\n",
            "[@debug] model.py:331 in applyFitMethod()\n",
            "         data.patches['train']['coords'][0:16]: array([[5744, 1488],\n",
            "                                                       [5552, 2032],\n",
            "                                                       [5328, 3440],\n",
            "                                                       [6544, 1392],\n",
            "                                                       [5712, 1456],\n",
            "                                                       [4080, 3472],\n",
            "                                                       [6992, 2000],\n",
            "                                                       [2928, 2224],\n",
            "                                                       [ 432, 6160],\n",
            "                                                       [5680, 1456],\n",
            "                                                       [5680, 1488],\n",
            "                                                       [2288, 4976],\n",
            "                                                       [3984, 7664],\n",
            "                                                       [ 688, 5808],\n",
            "                                                       [5680, 1456],\n",
            "                                                       [1616, 4624]])\n",
            "[@debug] model.py:332 in applyFitMethod()\n",
            "         data.patches['val']['coords'][0:16]: array([[4048, 7472],\n",
            "                                                     [ 528, 6256],\n",
            "                                                     [ 496, 6288],\n",
            "                                                     [3632, 2736],\n",
            "                                                     [3536, 4464],\n",
            "                                                     [ 944, 5520],\n",
            "                                                     [7344,  976],\n",
            "                                                     [1776, 4240],\n",
            "                                                     [7344, 1040],\n",
            "                                                     [4752, 1808],\n",
            "                                                     [7824,  848],\n",
            "                                                     [3440, 5040],\n",
            "                                                     [4368, 3472],\n",
            "                                                     [3600, 2992],\n",
            "                                                     [1488, 4368],\n",
            "                                                     [4048, 3664]])\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] model.py:345 in applyFitMethod()\n",
            "         data.patches['val']['coords'].shape: (747, 2)\n",
            "[@debug] model.py:346 in applyFitMethod()\n",
            "         data.patches['val']['coords']: array([[4048, 7472],\n",
            "                                               [ 528, 6256],\n",
            "                                               [ 496, 6288],\n",
            "                                               ...,\n",
            "                                               [4304, 6416],\n",
            "                                               [1776, 4048],\n",
            "                                               [3024, 2096]])\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 393\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 393\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.2291 - accuracy: 0.3700"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [67.61 89.79 20.7   5.98 60.15 78.25 57.5   0.   32.74]\n",
            " — val_precision: [61.71 89.07 27.16 51.13 58.68 73.61 62.27  0.   30.59]\n",
            " — val_recall: [74.76 90.51 16.72  3.17 61.69 83.52 53.41  0.   35.22]\n",
            " — mean_f1: 45.857777777777784\n",
            "oa 72.86\n",
            "Found best weights at epoch 1\n",
            "393/393 [==============================] - 59s 97ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.2291 - accuracy: 0.3700 - val_loss: 0.1395 - val_accuracy: 0.2819 - mean_f1: 45.8578\n",
            "Epoch 2/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.1563 - accuracy: 0.2802"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [72.31 91.32 40.02 50.05 46.26 71.58 60.39  0.   31.13]\n",
            " — val_precision: [69.16 89.87 27.23 59.37 67.98 57.35 71.7   0.   22.56]\n",
            " — val_recall: [75.75 92.81 75.48 43.25 35.06 95.21 52.16  0.   50.2 ]\n",
            " — mean_f1: 51.45111111111111\n",
            "oa 74.69\n",
            "Found best weights at epoch 2\n",
            "393/393 [==============================] - 38s 96ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.1563 - accuracy: 0.2802 - val_loss: 0.1173 - val_accuracy: 0.2475 - mean_f1: 51.4511\n",
            "Epoch 3/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.1266 - accuracy: 0.2101"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [73.5  92.17 56.24 59.17 52.51 81.84 67.93  0.   47.35]\n",
            " — val_precision: [80.49 90.86 39.61 45.19 74.35 71.2  74.64  0.   33.21]\n",
            " — val_recall: [67.63 93.51 96.91 85.66 40.59 96.22 62.33  0.   82.43]\n",
            " — mean_f1: 58.96777777777778\n",
            "oa 77.9\n",
            "Found best weights at epoch 3\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.1266 - accuracy: 0.2101 - val_loss: 0.1017 - val_accuracy: 0.1883 - mean_f1: 58.9678\n",
            "Epoch 4/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.1033 - accuracy: 0.1749"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [77.51 92.6  78.34 61.92 69.44 85.81 70.89  0.   59.28]\n",
            " — val_precision: [81.38 91.61 65.21 47.45 86.34 77.35 77.04  0.   44.66]\n",
            " — val_recall: [73.99 93.6  98.07 89.1  58.07 96.34 65.65  0.   88.12]\n",
            " — mean_f1: 66.19888888888889\n",
            "oa 81.43\n",
            "Found best weights at epoch 4\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.1033 - accuracy: 0.1749 - val_loss: 0.0876 - val_accuracy: 0.1970 - mean_f1: 66.1989\n",
            "Epoch 5/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0870 - accuracy: 0.1645"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [78.49 93.1  84.72 68.11 78.77 87.67 74.42  0.   64.83]\n",
            " — val_precision: [84.79 92.19 74.36 53.51 89.31 80.01 76.67  0.   52.14]\n",
            " — val_recall: [73.07 94.03 98.43 93.66 70.45 96.96 72.31  0.   85.7 ]\n",
            " — mean_f1: 70.01222222222222\n",
            "oa 83.66\n",
            "Found best weights at epoch 5\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0870 - accuracy: 0.1645 - val_loss: 0.0784 - val_accuracy: 0.1871 - mean_f1: 70.0122\n",
            "Epoch 6/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0745 - accuracy: 0.1611"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [81.17 93.48 80.66 72.34 85.06 87.27 77.51  0.   64.39]\n",
            " — val_precision: [89.7  92.19 68.23 58.49 86.86 78.8  79.09  0.   59.72]\n",
            " — val_recall: [74.12 94.8  98.63 94.77 83.34 97.77 75.99  0.   69.87]\n",
            " — mean_f1: 71.32\n",
            "oa 85.59\n",
            "Found best weights at epoch 6\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0745 - accuracy: 0.1611 - val_loss: 0.0730 - val_accuracy: 0.1721 - mean_f1: 71.3200\n",
            "Epoch 7/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0658 - accuracy: 0.1609"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [82.45 94.62 89.26 74.11 88.27 92.83 80.62  0.   69.46]\n",
            " — val_precision: [90.05 94.3  81.38 60.21 86.04 88.68 80.22  0.   71.28]\n",
            " — val_recall: [76.04 94.94 98.82 96.35 90.62 97.37 81.03  0.   67.73]\n",
            " — mean_f1: 74.62444444444446\n",
            "oa 87.54\n",
            "Found best weights at epoch 7\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0658 - accuracy: 0.1609 - val_loss: 0.0654 - val_accuracy: 0.1821 - mean_f1: 74.6244\n",
            "Epoch 8/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0591 - accuracy: 0.1615"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [85.16 95.47 92.06 76.78 89.27 93.11 84.18  0.   73.39]\n",
            " — val_precision: [91.08 95.53 86.14 63.62 88.41 88.8  83.69  0.   72.04]\n",
            " — val_recall: [79.97 95.4  98.87 96.8  90.15 97.86 84.67  0.   74.79]\n",
            " — mean_f1: 76.60222222222222\n",
            "oa 89.4\n",
            "Found best weights at epoch 8\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0591 - accuracy: 0.1615 - val_loss: 0.0594 - val_accuracy: 0.1885 - mean_f1: 76.6022\n",
            "Epoch 9/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0532 - accuracy: 0.1593"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [85.11 96.29 94.61 76.37 90.4  94.09 85.93  0.   77.97]\n",
            " — val_precision: [91.48 97.75 90.78 62.85 90.61 90.3  82.63  0.   71.5 ]\n",
            " — val_recall: [79.57 94.87 98.78 97.29 90.19 98.2  89.5   0.   85.72]\n",
            " — mean_f1: 77.86333333333333\n",
            "oa 90.21\n",
            "Found best weights at epoch 9\n",
            "393/393 [==============================] - 36s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0532 - accuracy: 0.1593 - val_loss: 0.0582 - val_accuracy: 0.1880 - mean_f1: 77.8633\n",
            "Epoch 10/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0496 - accuracy: 0.1603"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [86.48 96.63 94.61 77.72 90.25 92.04 87.96  0.   79.4 ]\n",
            " — val_precision: [91.82 96.94 90.54 64.55 90.66 86.43 87.39  0.   74.48]\n",
            " — val_recall: [81.72 96.32 99.05 97.66 89.84 98.42 88.54  0.   85.02]\n",
            " — mean_f1: 78.34333333333333\n",
            "oa 91.12\n",
            "Found best weights at epoch 10\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0496 - accuracy: 0.1603 - val_loss: 0.0553 - val_accuracy: 0.1875 - mean_f1: 78.3433\n",
            "Epoch 11/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0454 - accuracy: 0.1583"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [87.27 96.78 93.04 81.02 91.55 93.16 87.74  0.   80.23]\n",
            " — val_precision: [92.99 97.87 87.95 69.66 90.66 88.57 84.4   0.   79.07]\n",
            " — val_recall: [82.21 95.71 98.75 96.83 92.47 98.26 91.35  0.   81.42]\n",
            " — mean_f1: 78.97666666666666\n",
            "oa 91.56\n",
            "Found best weights at epoch 11\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0454 - accuracy: 0.1583 - val_loss: 0.0514 - val_accuracy: 0.1884 - mean_f1: 78.9767\n",
            "Epoch 12/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0421 - accuracy: 0.1590"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [88.85 96.67 92.96 81.85 90.64 94.63 88.52  0.   79.07]\n",
            " — val_precision: [92.74 98.17 88.35 70.79 90.23 91.51 85.81  0.   75.39]\n",
            " — val_recall: [85.28 95.22 98.09 96.99 91.05 97.97 91.39  0.   83.13]\n",
            " — mean_f1: 79.24333333333331\n",
            "oa 91.96\n",
            "Found best weights at epoch 12\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0421 - accuracy: 0.1590 - val_loss: 0.0495 - val_accuracy: 0.1962 - mean_f1: 79.2433\n",
            "Epoch 13/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0401 - accuracy: 0.1593"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [91.15 97.81 93.83 83.96 90.65 96.45 90.73  0.   77.43]\n",
            " — val_precision: [92.03 98.64 89.39 74.63 94.   94.94 91.34  0.   67.27]\n",
            " — val_recall: [90.28 97.   98.73 95.96 87.52 98.02 90.13  0.   91.2 ]\n",
            " — mean_f1: 80.22333333333333\n",
            "oa 93.47\n",
            "Found best weights at epoch 13\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0401 - accuracy: 0.1593 - val_loss: 0.0463 - val_accuracy: 0.2097 - mean_f1: 80.2233\n",
            "Epoch 14/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0373 - accuracy: 0.1571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [92.01 97.58 92.57 82.11 91.82 93.08 92.11  0.   84.55]\n",
            " — val_precision: [90.75 98.71 87.11 71.71 94.71 88.08 95.47  0.   76.81]\n",
            " — val_recall: [93.31 96.47 98.77 96.05 89.1  98.68 88.98  0.   94.03]\n",
            " — mean_f1: 80.64777777777778\n",
            "oa 93.87\n",
            "Found best weights at epoch 14\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0373 - accuracy: 0.1571 - val_loss: 0.0450 - val_accuracy: 0.2211 - mean_f1: 80.6478\n",
            "Epoch 15/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0358 - accuracy: 0.1559"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [92.34 97.62 92.55 84.92 92.67 95.57 91.98  0.   87.73]\n",
            " — val_precision: [93.4  98.35 87.06 75.45 95.07 93.12 92.29  0.   81.66]\n",
            " — val_recall: [91.29 96.9  98.77 97.1  90.38 98.16 91.67  0.   94.76]\n",
            " — mean_f1: 81.70888888888891\n",
            "oa 94.25\n",
            "Found best weights at epoch 15\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0358 - accuracy: 0.1559 - val_loss: 0.0425 - val_accuracy: 0.2057 - mean_f1: 81.7089\n",
            "Epoch 16/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0339 - accuracy: 0.1572"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [91.87 96.17 94.65 84.02 91.29 91.87 89.84 82.42]\n",
            " — val_precision: [91.54 98.92 90.87 75.21 93.9  85.93 88.3  72.78]\n",
            " — val_recall: [92.2  93.56 98.77 95.16 88.81 98.69 91.44 95.01]\n",
            " — mean_f1: 80.23666666666668\n",
            "oa 92.79\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0339 - accuracy: 0.1572 - val_loss: 0.0456 - val_accuracy: 0.2098 - mean_f1: 80.2367\n",
            "Epoch 17/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0334 - accuracy: 0.1582"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.12 97.91 91.58 85.78 91.95 93.54 92.97 83.13]\n",
            " — val_precision: [93.76 98.77 85.49 76.86 93.52 89.92 93.43 79.87]\n",
            " — val_recall: [92.49 97.07 98.61 97.03 90.42 97.46 92.51 86.66]\n",
            " — mean_f1: 81.10888888888888\n",
            "oa 94.58\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0334 - accuracy: 0.1582 - val_loss: 0.0410 - val_accuracy: 0.2080 - mean_f1: 81.1089\n",
            "Epoch 18/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0312 - accuracy: 0.1584"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.09 97.72 91.42 83.04 93.17 93.75 93.15 88.44]\n",
            " — val_precision: [93.39 98.55 84.88 72.25 94.04 89.61 95.03 87.58]\n",
            " — val_recall: [92.78 96.91 99.04 97.62 92.32 98.29 91.33 89.33]\n",
            " — mean_f1: 81.5311111111111\n",
            "oa 94.58\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0312 - accuracy: 0.1584 - val_loss: 0.0412 - val_accuracy: 0.2093 - mean_f1: 81.5311\n",
            "Epoch 19/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0297 - accuracy: 0.1558"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [91.72 97.84 93.59 84.68 92.98 91.27 93.15 87.76]\n",
            " — val_precision: [91.85 98.77 88.93 75.44 93.2  85.27 94.94 84.44]\n",
            " — val_recall: [91.59 96.92 98.77 96.49 92.76 98.17 91.43 91.36]\n",
            " — mean_f1: 81.44333333333333\n",
            "oa 94.36\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0297 - accuracy: 0.1558 - val_loss: 0.0406 - val_accuracy: 0.2081 - mean_f1: 81.4433\n",
            "Epoch 20/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0292 - accuracy: 0.1548"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [92.46 97.83 93.02 82.73 92.26 94.12 92.8   0.   83.81]\n",
            " — val_precision: [93.49 98.83 87.91 72.53 92.27 90.06 93.94  0.   78.71]\n",
            " — val_recall: [91.45 96.86 98.77 96.29 92.25 98.56 91.68  0.   89.6 ]\n",
            " — mean_f1: 81.00333333333333\n",
            "oa 94.28\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0292 - accuracy: 0.1548 - val_loss: 0.0410 - val_accuracy: 0.2042 - mean_f1: 81.0033\n",
            "Epoch 21/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0275 - accuracy: 0.1526"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [92.18 96.77 91.68 84.25 92.54 94.67 89.76 81.56]\n",
            " — val_precision: [92.52 99.16 85.73 77.98 93.8  91.04 86.95 78.06]\n",
            " — val_recall: [91.84 94.5  98.53 91.62 91.31 98.61 92.74 85.38]\n",
            " — mean_f1: 80.37888888888888\n",
            "oa 93.23\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0275 - accuracy: 0.1526 - val_loss: 0.0404 - val_accuracy: 0.2070 - mean_f1: 80.3789\n",
            "Epoch 22/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0260 - accuracy: 0.1541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.35 98.32 91.92 85.18 93.85 94.05 94.34 88.46]\n",
            " — val_precision: [93.55 98.78 85.96 75.99 95.11 92.15 96.2  85.74]\n",
            " — val_recall: [93.14 97.86 98.77 96.89 92.63 96.03 92.55 91.36]\n",
            " — mean_f1: 82.16333333333334\n",
            "oa 95.28\n",
            "Found best weights at epoch 22\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0260 - accuracy: 0.1541 - val_loss: 0.0356 - val_accuracy: 0.2114 - mean_f1: 82.1633\n",
            "Epoch 23/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0253 - accuracy: 0.1553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.25 98.04 91.29 84.29 92.43 94.56 93.    0.   86.58]\n",
            " — val_precision: [94.36 98.84 84.87 74.59 93.16 91.34 93.08  0.   89.03]\n",
            " — val_recall: [92.17 97.26 98.77 96.89 91.71 98.01 92.93  0.   84.26]\n",
            " — mean_f1: 81.49333333333334\n",
            "oa 94.73\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0253 - accuracy: 0.1553 - val_loss: 0.0363 - val_accuracy: 0.2045 - mean_f1: 81.4933\n",
            "Epoch 24/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0256 - accuracy: 0.1525"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [91.81 98.21 85.2  84.49 92.48 92.67 93.23  0.   87.41]\n",
            " — val_precision: [94.22 98.53 74.88 74.96 94.11 87.44 94.02  0.   82.64]\n",
            " — val_recall: [89.52 97.88 98.82 96.8  90.91 98.56 92.45  0.   92.77]\n",
            " — mean_f1: 80.6111111111111\n",
            "oa 94.43\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0256 - accuracy: 0.1525 - val_loss: 0.0379 - val_accuracy: 0.1923 - mean_f1: 80.6111\n",
            "Epoch 25/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0245 - accuracy: 0.1531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [91.46 97.87 95.26 78.29 92.39 90.85 93.25 82.01]\n",
            " — val_precision: [94.53 98.62 91.97 65.47 91.19 85.06 93.82 83.63]\n",
            " — val_recall: [88.57 97.12 98.8  97.35 93.61 97.49 92.69 80.45]\n",
            " — mean_f1: 80.15333333333334\n",
            "oa 93.9\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0245 - accuracy: 0.1531 - val_loss: 0.0397 - val_accuracy: 0.1945 - mean_f1: 80.1533\n",
            "Epoch 26/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0236 - accuracy: 0.1586"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [92.92 98.47 94.39 85.82 91.91 94.72 94.07 84.32]\n",
            " — val_precision: [92.26 98.97 89.84 77.28 93.05 91.59 96.16 86.9 ]\n",
            " — val_recall: [93.59 97.98 99.43 96.47 90.8  98.06 92.08 81.9 ]\n",
            " — mean_f1: 81.84666666666665\n",
            "oa 95.09\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0236 - accuracy: 0.1586 - val_loss: 0.0339 - val_accuracy: 0.2196 - mean_f1: 81.8467\n",
            "Epoch 27/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0216 - accuracy: 0.1558"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.45 98.29 94.65 82.92 92.94 94.45 94.06  0.   87.42]\n",
            " — val_precision: [93.64 99.13 90.87 71.88 94.05 90.68 95.28  0.   91.52]\n",
            " — val_recall: [93.26 97.47 98.77 97.95 91.86 98.55 92.87  0.   83.68]\n",
            " — mean_f1: 82.02\n",
            "oa 95.1\n",
            "393/393 [==============================] - 37s 95ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0216 - accuracy: 0.1558 - val_loss: 0.0328 - val_accuracy: 0.2138 - mean_f1: 82.0200\n",
            "Epoch 28/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0208 - accuracy: 0.1553"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.4  98.2  92.61 83.   93.03 94.22 94.43  0.   89.49]\n",
            " — val_precision: [93.17 99.33 86.83 72.17 94.08 90.28 95.98  0.   90.31]\n",
            " — val_recall: [93.63 97.1  99.22 97.65 92.01 98.52 92.92  0.   88.68]\n",
            " — mean_f1: 82.04222222222224\n",
            "oa 95.12\n",
            "393/393 [==============================] - 37s 95ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0208 - accuracy: 0.1553 - val_loss: 0.0332 - val_accuracy: 0.2196 - mean_f1: 82.0422\n",
            "Epoch 29/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0202 - accuracy: 0.1570"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.17 98.44 93.74 84.12 93.14 93.21 94.6   0.   86.98]\n",
            " — val_precision: [93.31 99.14 89.2  74.09 93.68 88.51 96.26  0.   89.87]\n",
            " — val_recall: [93.03 97.75 98.77 97.29 92.6  98.44 92.99  0.   84.26]\n",
            " — mean_f1: 81.93333333333334\n",
            "oa 95.23\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0202 - accuracy: 0.1570 - val_loss: 0.0323 - val_accuracy: 0.2143 - mean_f1: 81.9333\n",
            "Epoch 30/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0222 - accuracy: 0.1571"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [92.78 97.94 85.42 82.39 92.96 93.07 93.55 84.77]\n",
            " — val_precision: [94.54 98.89 74.71 72.18 93.36 88.3  94.77 78.42]\n",
            " — val_recall: [91.09 97.01 99.73 95.95 92.57 98.39 92.37 92.23]\n",
            " — mean_f1: 80.32\n",
            "oa 94.47\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0222 - accuracy: 0.1571 - val_loss: 0.0352 - val_accuracy: 0.1988 - mean_f1: 80.3200\n",
            "Epoch 31/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0196 - accuracy: 0.1532"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.46 98.03 93.72 86.21 93.57 91.38 93.34  0.   92.26]\n",
            " — val_precision: [93.77 98.59 88.85 77.7  93.36 85.08 95.37  0.   92.  ]\n",
            " — val_recall: [93.15 97.49 99.15 96.81 93.77 98.69 91.4   0.   92.52]\n",
            " — mean_f1: 82.44111111111111\n",
            "oa 95.07\n",
            "Found best weights at epoch 31\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0196 - accuracy: 0.1532 - val_loss: 0.0321 - val_accuracy: 0.2091 - mean_f1: 82.4411\n",
            "Epoch 32/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0185 - accuracy: 0.1557"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.87 98.35 94.06 81.5  94.14 95.58 94.56 88.17]\n",
            " — val_precision: [94.95 98.91 89.07 70.31 96.15 93.25 95.81 85.49]\n",
            " — val_recall: [92.81 97.8  99.64 96.92 92.21 98.04 93.35 91.03]\n",
            " — mean_f1: 82.24777777777778\n",
            "oa 95.35\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0185 - accuracy: 0.1557 - val_loss: 0.0314 - val_accuracy: 0.2053 - mean_f1: 82.2478\n",
            "Epoch 33/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0177 - accuracy: 0.1523"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.63 98.52 94.73 85.48 95.02 94.66 95.22 91.38]\n",
            " — val_precision: [93.3  99.27 90.65 75.81 95.52 91.62 97.25 91.07]\n",
            " — val_recall: [93.96 97.78 99.19 97.97 94.52 97.91 93.27 91.7 ]\n",
            " — mean_f1: 83.18222222222222\n",
            "oa 95.79\n",
            "Found best weights at epoch 33\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0177 - accuracy: 0.1523 - val_loss: 0.0295 - val_accuracy: 0.2144 - mean_f1: 83.1822\n",
            "Epoch 34/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0170 - accuracy: 0.1551"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.88 98.15 93.67 82.07 92.82 94.12 94.51 86.95]\n",
            " — val_precision: [94.11 98.85 88.84 71.31 95.81 90.47 96.25 82.6 ]\n",
            " — val_recall: [93.66 97.47 99.05 96.65 90.   98.07 92.82 91.77]\n",
            " — mean_f1: 81.79666666666667\n",
            "oa 95.14\n",
            "393/393 [==============================] - 36s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0170 - accuracy: 0.1551 - val_loss: 0.0307 - val_accuracy: 0.2111 - mean_f1: 81.7967\n",
            "Epoch 35/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0196 - accuracy: 0.1535"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [85.74 95.14 89.03 81.55 88.83 94.37 84.9  73.42]\n",
            " — val_precision: [89.72 97.97 80.83 73.01 94.8  89.87 79.75 59.22]\n",
            " — val_recall: [82.1  92.47 99.09 92.35 83.57 99.34 90.77 96.6 ]\n",
            " — mean_f1: 76.99777777777778\n",
            "oa 89.53\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0196 - accuracy: 0.1535 - val_loss: 0.0436 - val_accuracy: 0.1887 - mean_f1: 76.9978\n",
            "Epoch 36/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0192 - accuracy: 0.1566"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.2  98.63 93.27 84.96 93.81 93.42 94.25 91.11]\n",
            " — val_precision: [93.28 99.16 87.75 75.49 95.82 89.18 96.01 89.95]\n",
            " — val_recall: [93.12 98.1  99.54 97.15 91.89 98.08 92.56 92.31]\n",
            " — mean_f1: 82.51666666666667\n",
            "oa 95.41\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0192 - accuracy: 0.1566 - val_loss: 0.0285 - val_accuracy: 0.2159 - mean_f1: 82.5167\n",
            "Epoch 37/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0161 - accuracy: 0.1547"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.32 98.43 93.05 84.3  93.55 95.5  95.13 90.95]\n",
            " — val_precision: [93.42 99.01 87.97 74.22 94.63 93.12 97.05 90.15]\n",
            " — val_recall: [93.22 97.86 98.77 97.54 92.49 98.01 93.28 91.77]\n",
            " — mean_f1: 82.69222222222223\n",
            "oa 95.5\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0161 - accuracy: 0.1547 - val_loss: 0.0280 - val_accuracy: 0.2114 - mean_f1: 82.6922\n",
            "Epoch 38/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0154 - accuracy: 0.1537"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.43 98.59 94.77 82.71 94.01 93.79 94.98  0.   91.27]\n",
            " — val_precision: [93.91 99.17 91.09 71.76 95.13 91.22 96.91  0.   89.26]\n",
            " — val_recall: [92.96 98.02 98.75 97.6  92.92 96.51 93.13  0.   93.38]\n",
            " — mean_f1: 82.61666666666666\n",
            "oa 95.52\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0154 - accuracy: 0.1537 - val_loss: 0.0281 - val_accuracy: 0.2142 - mean_f1: 82.6167\n",
            "Epoch 39/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0148 - accuracy: 0.1540"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.65 98.51 94.34 82.62 93.34 93.79 94.77  0.   91.84]\n",
            " — val_precision: [94.43 99.1  90.1  71.9  94.05 89.99 96.3   0.   92.3 ]\n",
            " — val_recall: [92.89 97.93 98.99 97.1  92.64 97.91 93.28  0.   91.38]\n",
            " — mean_f1: 82.54\n",
            "oa 95.45\n",
            "393/393 [==============================] - 37s 95ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0148 - accuracy: 0.1540 - val_loss: 0.0282 - val_accuracy: 0.2096 - mean_f1: 82.5400\n",
            "Epoch 40/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0144 - accuracy: 0.1530"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.02 97.9  92.46 81.23 94.44 94.38 93.78  0.   91.39]\n",
            " — val_precision: [93.64 99.08 86.91 69.85 96.75 90.7  94.12  0.   90.83]\n",
            " — val_recall: [92.4  96.74 98.77 97.04 92.24 98.38 93.44  0.   91.96]\n",
            " — mean_f1: 82.06666666666666\n",
            "oa 94.84\n",
            "393/393 [==============================] - 38s 96ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0144 - accuracy: 0.1530 - val_loss: 0.0285 - val_accuracy: 0.2107 - mean_f1: 82.0667\n",
            "Epoch 41/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0146 - accuracy: 0.1520"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [93.56 98.31 94.14 83.   94.33 95.02 94.36  0.   91.76]\n",
            " — val_precision: [95.05 98.77 89.98 72.28 96.18 92.97 94.85  0.   90.34]\n",
            " — val_recall: [92.12 97.85 98.7  97.46 92.56 97.16 93.87  0.   93.23]\n",
            " — mean_f1: 82.72\n",
            "oa 95.38\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0146 - accuracy: 0.1520 - val_loss: 0.0267 - val_accuracy: 0.2043 - mean_f1: 82.7200\n",
            "Epoch 42/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0136 - accuracy: 0.1541"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [94.2  98.82 93.25 85.1  93.24 94.6  94.93  0.   92.01]\n",
            " — val_precision: [94.84 99.19 87.94 74.91 95.76 90.99 96.14  0.   92.9 ]\n",
            " — val_recall: [93.56 98.45 99.24 98.51 90.86 98.52 93.75  0.   91.13]\n",
            " — mean_f1: 82.90555555555555\n",
            "oa 95.85\n",
            "393/393 [==============================] - 37s 95ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0136 - accuracy: 0.1541 - val_loss: 0.0267 - val_accuracy: 0.2082 - mean_f1: 82.9056\n",
            "Epoch 43/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0132 - accuracy: 0.1548"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [94.04 98.49 89.5  84.71 93.77 95.08 93.83  0.   92.91]\n",
            " — val_precision: [94.07 99.15 81.43 75.   94.37 94.13 95.65  0.   93.69]\n",
            " — val_recall: [94.01 97.84 99.36 97.31 93.18 96.06 92.07  0.   92.15]\n",
            " — mean_f1: 82.48111111111112\n",
            "oa 95.45\n",
            "Restoring model weights from the end of the best epoch.\n",
            "393/393 [==============================] - 38s 98ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0132 - accuracy: 0.1548 - val_loss: 0.0267 - val_accuracy: 0.2124 - mean_f1: 82.4811\n",
            "Epoch %05d: early stopping\n",
            "f1 history [45.857777777777784, 51.45111111111111, 58.96777777777778, 66.19888888888889, 70.01222222222222, 71.32, 74.62444444444446, 76.60222222222222, 77.86333333333333, 78.34333333333333, 78.97666666666666, 79.24333333333331, 80.22333333333333, 80.64777777777778, 81.70888888888891, 80.23666666666668, 81.10888888888888, 81.5311111111111, 81.44333333333333, 81.00333333333333, 80.37888888888888, 82.16333333333334, 81.49333333333334, 80.6111111111111, 80.15333333333334, 81.84666666666665, 82.02, 82.04222222222224, 81.93333333333334, 80.32, 82.44111111111111, 82.24777777777778, 83.18222222222222, 81.79666666666667, 76.99777777777778, 82.51666666666667, 82.69222222222223, 82.61666666666666, 82.54, 82.06666666666666, 82.72, 82.90555555555555, 82.48111111111112]\n",
            "oa history [72.86, 74.69, 77.9, 81.43, 83.66, 85.59, 87.54, 89.4, 90.21, 91.12, 91.56, 91.96, 93.47, 93.87, 94.25, 92.79, 94.58, 94.58, 94.36, 94.28, 93.23, 95.28, 94.73, 94.43, 93.9, 95.09, 95.1, 95.12, 95.23, 94.47, 95.07, 95.35, 95.79, 95.14, 89.53, 95.41, 95.5, 95.52, 95.45, 94.84, 95.38, 95.85, 95.45]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lD8P03YG0IX"
      },
      "source": [
        "## Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im68QpP-JvbR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "97f3dca4-b367-41f2-b29f-9a82635be65f"
      },
      "source": [
        "paramsMosaic = ParamsReconstruct(paramsTrain)\n",
        "\n",
        "paramsMosaic.mosaic_flag = True\n",
        "\n",
        "trainTest.evaluate(paramsMosaic)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:562 in loadMask()\n",
            "         str(self.paramsTrain.path): '../../../dataset/dataset/cv_data'\n",
            "[@debug] dataset.py:564 in loadMask()- self.mask.shape: (8492, 7995)\n",
            "[@debug] dataset.py:386 in addPaddingToInput()\n",
            "         im.shape: (12, 8492, 7995, 2)\n",
            "[@debug] params_reconstruct.py:43 in __init__()\n",
            "         self.overlap: 0\n",
            "         self.threshold_idx: 4\n",
            "[@debug] params_reconstruct.py:43 in __init__()\n",
            "         self.overlap: 0\n",
            "         self.threshold_idx: 4\n",
            "[@debug] mosaic.py:45 in __init__()- paramsTrain.seq_date: 'jun'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset = cv\n",
            "[@debug] paramsTrain.model_type = UUnetConvLSTM\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] mosaic.py:133 in create()- self.data.class_n: 10\n",
            "[@debug] mosaic.py:134 in create()\n",
            "         np.unique(self.data.full_label_test): array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8)\n",
            "         len(np.unique(self.data.full_label_test)): 10\n",
            "[@debug] mosaic.py:135 in create()\n",
            "         np.unique(self.data.full_label_train): array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n",
            "         len(np.unique(self.data.full_label_train)): 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-a09e6dd7457e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/main.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \t'''\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/model.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data, ds)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostProcessing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPostProcessingMosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparamsTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mmosaic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparamsTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostProcessing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetricsTranslated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparamsTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/mosaic.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, paramsTrain, model, data, ds, postProcessing)\u001b[0m\n\u001b[1;32m    146\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloopOverImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamsTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadMosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparamsTrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/mosaic.py\u001b[0m in \u001b[0;36mloadMosaic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mloadMosaic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \t\tself.prediction_mosaic = np.load(self.pr.spatial_results_path / \n\u001b[0;32m--> 104\u001b[0;31m \t\t\t('prediction_mosaic_'+self.data.dataset_date+'_'+self.name_id+'_overl'+str(self.pr.overlap)+'.npy'))\n\u001b[0m\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_set_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \t\t\tself.postProcessing.openSetMosaic.scores_mosaic = np.load(self.pr.spatial_results_path / \n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'results/spatial_results/prediction_mosaic_20160613_closed_set_overl0.npy'"
          ]
        }
      ]
    }
  ]
}