{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/osss-mcr/blob/coords7/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f871f0d-a9f0-4be5-fa50-23f55f526462"
      },
      "source": [
        "!pip install icecream\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/lm_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.8.0)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.7/dist-packages (0.9.19)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.7/dist-packages (from kora) (1.3.26)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d313f56-7729-494b-e374-5e1a7fb4638a"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "9f07a4cc-246c-4b04-e2f9-afa6f36be629"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf osss-mcr\n",
        "  !git clone --branch coords7 https://github.com/DiMorten/osss-mcr.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'osss-mcr'...\n",
            "remote: Enumerating objects: 2530, done.\u001b[K\n",
            "remote: Counting objects: 100% (329/329), done.\u001b[K\n",
            "remote: Compressing objects: 100% (242/242), done.\u001b[K\n",
            "remote: Total 2530 (delta 224), reused 153 (delta 62), pack-reused 2201\u001b[K\n",
            "Receiving objects: 100% (2530/2530), 37.66 MiB | 25.76 MiB/s, done.\n",
            "Resolving deltas: 100% (1690/1690), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/lm_data /content/osss-mcr/dataset/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f590a5-2ba5-44d5-af7c-04649c3f0cf9"
      },
      "source": [
        "os.chdir('/content/osss-mcr/')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['obj',\n",
              " 'evaluate_open_set.py',\n",
              " 'parameters',\n",
              " 'README.md',\n",
              " 'train_and_evaluate_open_set.ipynb',\n",
              " '__init__.py',\n",
              " '.gitignore',\n",
              " 'dataset',\n",
              " 'train_and_evaluate_openset.ipynb',\n",
              " '.git',\n",
              " 'evaluate.py',\n",
              " 'deb.py',\n",
              " 'train_and_evaluate.ipynb',\n",
              " 'environment.yml',\n",
              " 'train_and_evaluate_open_set.py',\n",
              " 'train_and_evaluate.py',\n",
              " 'src']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from src.densnet import DenseNetFCN\n",
        "from src.densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from src.keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from tensorflow.keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from tensorflow.keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from src.generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from src.dataSource import DataSource, SARSource, Dataset, LEM, LEM2, CampoVerde\n",
        "from src.model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.params_train import ParamsTrain\n",
        "from parameters.params_mosaic import ParamsReconstruct\n",
        "\n",
        "from icecream import ic\n",
        "from src.monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from src.model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from src.dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from src.patch_extractor import PatchExtractor\n",
        "\n",
        "from src.mosaic import seq_add_padding, add_padding, Mosaic, MosaicHighRAM, MosaicHighRAMPostProcessing\n",
        "from src.postprocessing import PostProcessingMosaic\n",
        "\n",
        "from src.metrics import Metrics, MetricsTranslated\n",
        "\n",
        "ic.configureOutput(includeContext=True)\n",
        "np.random.seed(2021)\n",
        "tf.random.set_seed(2021)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "\n",
        "from train_and_evaluate import TrainTest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f449e4-041f-4c60-d2f8-9c3addccbd5c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  8 20:40:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/osss-mcr/networks/convlstm_networks/train_src/parameters/params_train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbb4082f-477c-4062-c3e4-05c78985a2a2"
      },
      "source": [
        "paramsTrainCustom = {\n",
        "\t'getFullIms': True,\n",
        "\t'coordsExtract': True,\n",
        "\t'train': True,\n",
        "\t'openSetMethod': None, # Options: None, OpenPCS, OpenPCS++\n",
        "#\t\t'openSetLoadModel': True,\n",
        "\t'selectMainClasses': True,\n",
        "\t'dataset': 'lm', # lm: L Eduardo Magalhaes.\n",
        "\t'seq_date': 'mar',\t# jun, mar\t\n",
        "    'dataSource': SARSource()\n",
        "}\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/', **paramsTrainCustom)\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] params_train.py:107 in __init__()- self.seq_date: 'mar'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] params_train.py:166 in __init__()- self.stride: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no_mode.json', 'parameters_openset.json', 'params_batchprocessing.py', '__init__.py', '__pycache__', 'parameters_closedset_groupclasses.json', 'params_mosaic.py', 'save_nonaugmented_train_patches.json', 'params_train.py']\n",
            "[@debug] self.seq_mode = fixed\n",
            "[@debug] self.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7f18177e8bd0>\n",
            "[@debug] self.ds = <src.dataSource.LEM object at 0x7f18177a5310>\n",
            "[@debug] dataSource.name = SARSource\n",
            "self.im_list ['20170413_S1', '20170519_S1', '20170612_S1', '20170706_S1', '20170811_S1', '20170916_S1', '20171010_S1', '20171115_S1', '20171209_S1', '20180114_S1', '20180219_S1', '20180315_S1']\n",
            "fixed mar\n",
            "[@debug] self.t_len = 12\n",
            "20170413\n",
            "20170519\n",
            "20170612\n",
            "20170706\n",
            "20170811\n",
            "20170916\n",
            "20171010\n",
            "20171115\n",
            "20171209\n",
            "20180114\n",
            "20180219\n",
            "20180315\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[103, 139, 163, 187, 223, 259, 283, 319, 343, 14, 50, 74]\n",
            "[[0.9917   0.4104  ]\n",
            " [0.849    0.142   ]\n",
            " [0.6763   0.03214 ]\n",
            " [0.4744   0.000663]\n",
            " [0.1897   0.1079  ]\n",
            " [0.01993  0.3604  ]\n",
            " [0.00414  0.564   ]\n",
            " [0.133    0.84    ]\n",
            " [0.2998   0.958   ]\n",
            " [0.611    0.988   ]\n",
            " [0.8726   0.8335  ]\n",
            " [0.975    0.6562  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XFXeoNjGXSo",
        "outputId": "94bf8d3b-1c5d-436f-aea7-c754281be1aa"
      },
      "source": [
        "trainTest.main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <src.dataSource.SARSource object at 0x7f1879e8e910>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('dataset/lm_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('dataset/lm_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/osss-mcr'\n",
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8484, 8658, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20170413_S1',\n",
            "                                '20170519_S1',\n",
            "                                '20170612_S1',\n",
            "                                '20170706_S1',\n",
            "                                '20170811_S1',\n",
            "                                '20170916_S1',\n",
            "                                '20171010_S1',\n",
            "                                '20171115_S1',\n",
            "                                '20171209_S1',\n",
            "                                '20180114_S1',\n",
            "                                '20180219_S1',\n",
            "                                '20180315_S1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170413_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.136962890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 133.125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "dataset/lm_data/labels/20170413_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170413_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "1 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170519_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.158203125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 358.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "dataset/lm_data/labels/20170519_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170519_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "2 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170612_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1300048828125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 136.875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170612_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170612_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "3 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170706_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1263427734375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 158.75\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170706_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170706_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    12634,   185207,    73895,    45419,    11279,\n",
            "         262098,   939013,    21332,   199301,    45499,   770815,\n",
            "          38849,  2999826]))\n",
            "4 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170811_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1195068359375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 152.125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170811_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170811_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,    74031,    10661,    45419,     5872,   106217,\n",
            "         186264,    21332,   194734,    39957,   770815,    38849,\n",
            "        4105947,     5069]))\n",
            "5 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170916_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1163330078125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 157.875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170916_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170916_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,    25250,    43089,     2529,    10214,    12391,\n",
            "          21332,   194734,    12001,   739031,    70633,  4450376,\n",
            "          23587]))\n",
            "6 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20171010_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.115966796875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 164.75\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20171010_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20171010_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  4,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,     6337,    43089,    21332,    88766,    28092,\n",
            "         734589,    75075,  4574286,    33601]))\n",
            "7 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20171115_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1326904296875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 141.25\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20171115_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20171115_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  4,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,    22686,     9933,    43089,    21332,    75788,\n",
            "          46374,   734589,    75075,  4524955,    51346]))\n",
            "8 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20171209_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1416015625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 142.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20171209_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20171209_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  4,  5,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,   801632,   168412,    43089,     4153,    21332,\n",
            "         117985,    46374,   734589,    75075,  3506223,    86303]))\n",
            "9 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20180114_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.162109375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 151.5\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20180114_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20180114_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,  3322749,   408374,    26142,    43089,     4153,\n",
            "          21332,   153357,    46374,   734589,    75075,   393731,\n",
            "         376202]))\n",
            "10 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20180219_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1680908203125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 154.5\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20180219_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20180219_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,  3442264,   437303,   151144,    43089,      625,\n",
            "          21332,   174664,    46374,   734589,    75075,   255706,\n",
            "         223002]))\n",
            "11 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20180315_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.17919921875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 173.625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20180315_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20180315_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,  3290763,   440171,   151144,    43089,    28864,\n",
            "            625,    21332,   173538,    46374,   734589,    71457,\n",
            "         561917,    41304]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataSource.py:254 in im_load()\n",
            "         patch[\"full_ims\"].shape: (12, 8484, 8658, 2)\n",
            "[@debug] dataSource.py:255 in im_load()\n",
            "         patch[\"full_label_ims\"].shape: (12, 8484, 8658)\n",
            "[@debug] dataSource.py:256 in im_load()\n",
            "         patch[\"full_ims\"].dtype: dtype('float16')\n",
            "[@debug] dataSource.py:257 in im_load()\n",
            "         patch[\"full_label_ims\"].dtype: dtype('int8')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] np.unique(patch['full_label_ims'],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "      dtype=int8), array([814191660,  10948507,   2561907,    665775,    528718,    377736,\n",
            "         1238182,   5116663,    255984,   1996951,    609668,   9000640,\n",
            "          711710,  32409149,    840414]))\n",
            "-1.0 1.0 0.1404\n",
            "[@debug] self.dataset.name = lm\n",
            "[@debug] self.dataset.scaler_name = lm\n",
            "[@debug] self.dataset.seq_mode = fixed\n",
            "[@debug] self.dataset.seq_date = mar\n",
            "[@debug] self.dataset.scaler_load = False\n",
            "[@debug] im.shape = (12, 8484, 8658, 2)\n",
            "[@debug] im_flat[mask_flat==1,:].shape = (51633252, 2)\n",
            "0.0001221 1.0 0.0494\n",
            "[@debug] im_norm.shape = (12, 8484, 8658, 2)\n",
            "FINISHED NORMALIZING, RESULT:\n",
            "-60.66 58.44 3.367\n",
            "[@debug] im.shape = (12, 8484, 8658)\n",
            "[@debug] mask_train.shape = (8484, 8658)\n",
            "[@debug] im.dtype = uint8\n",
            "[@debug] mask_train.dtype = uint8\n",
            "[@debug] im_train.shape = (12, 8484, 8658)\n",
            "Train masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [829820412   8219740   1823768    467950    398108    236613    916694\n",
            "   4216447    139692   1659002    541417   7124176    679430  24636794\n",
            "    573421]\n",
            "Test masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [865824912   2728767    738139    197825    130610    141123    321488\n",
            "    900216    116292    337949     68251   1876464     32280   7772355\n",
            "    266993]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:127 in getFullIms()\n",
            "         self.paramsTrain.path / 'full_ims/full_ims_test.npy': PosixPath('dataset/lm_data/full_ims/full_ims_test.npy')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTED PATCH EXTRACTION\n",
            "[@debug] gridx.shape = (271,)\n",
            "[@debug] gridy.shape = (266,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:205 in extract()\n",
            "         coords_train.shape: (7392, 2)\n",
            "         coords_test.shape: (2528, 2)\n",
            "[@debug] patch_extractor.py:206 in extract()\n",
            "         coords_train.dtype: dtype('int64')\n",
            "[@debug] patch_extractor.py:207 in extract()\n",
            "         coords_train[0]: array([5456,  880])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:96 in __init__()- self.class_n: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] self.t_len = 12\n",
            "Initializing Dataset instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] train_and_evaluate.py:123 in setData()- self.data.class_n: 14\n",
            "[@debug] dataset.py:199 in create_load()\n",
            "         os.path.dirname(os.path.abspath(__file__)): '/content/osss-mcr/src'\n",
            "[@debug] dataset.py:200 in create_load()\n",
            "         os.getcwd(): '/content/osss-mcr'\n",
            "[@debug] dataset.py:204 in create_load()\n",
            "         self.patches['train']['coords'].shape: (7392, 2)\n",
            "[@debug] dataset.py:297 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "                                                                     dtype=uint8),\n",
            "                                                                array([69151701,  2501920,   332862,   116340,    32729,    22874,\n",
            "                                                                           296,    11641,   152495,    44214,   580098,    66886,\n",
            "                                                                        410580,    29836]))\n",
            "[@debug] dataset.py:298 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "                                                                    dtype=uint8),\n",
            "                                                               array([72152076,   788843,   107309,    34804,    10360,     5990,\n",
            "                                                                          329,     9691,    21043,     2160,   154491,     4571,\n",
            "                                                                       151337,    11468]))\n",
            "[@debug] dataset.py:318 in labelPreprocess()\n",
            "         self.paramsTrain.selectMainClasses: True\n",
            "[@debug] dataset.py:252 in knownClassesGet()\n",
            "         unique: array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "                       dtype=uint8)\n",
            "         count: array([69151701,  2501920,   332862,   116340,    32729,    22874,\n",
            "                            296,    11641,   152495,    44214,   580098,    66886,\n",
            "                         410580,    29836])\n",
            "[@debug] dataset.py:256 in knownClassesGet()\n",
            "         unique: array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13], dtype=uint8)\n",
            "         count: array([2501920,  332862,  116340,   32729,   22874,     296,   11641,\n",
            "                        152495,   44214,  580098,   66886,  410580,   29836])\n",
            "[@debug] dataset.py:259 in knownClassesGet()- total_count: 4302771\n",
            "[@debug] dataset.py:261 in knownClassesGet()\n",
            "         count_percentage: array([5.81467152e-01, 7.73599153e-02, 2.70383899e-02, 7.60649358e-03,\n",
            "                                  5.31610908e-03, 6.87928779e-05, 2.70546585e-03, 3.54411146e-02,\n",
            "                                  1.02757037e-02, 1.34819631e-01, 1.55448663e-02, 9.54222291e-02,\n",
            "                                  6.93413616e-03])\n",
            "[@debug] dataset.py:262 in knownClassesGet()\n",
            "         sorted(zip(count_percentage, unique)): [(6.879287789194451e-05, 6),\n",
            "                                                 (0.0027054658497977233, 7),\n",
            "                                                 (0.005316109084122766, 4),\n",
            "                                                 (0.006934136164811002, 13),\n",
            "                                                 (0.007606493582856257, 3),\n",
            "                                                 (0.010275703726737955, 9),\n",
            "                                                 (0.015544866319866894, 11),\n",
            "                                                 (0.027038389911989275, 2),\n",
            "                                                 (0.03544111457477054, 8),\n",
            "                                                 (0.07735991527320417, 1),\n",
            "                                                 (0.09542222907052222, 12),\n",
            "                                                 (0.13481963134919334, 10),\n",
            "                                                 (0.581467152214236, 0)]\n",
            "[@debug] dataset.py:266 in knownClassesGet()\n",
            "         unique_sorted: array([[5.81467152e-01, 0.00000000e+00],\n",
            "                               [1.34819631e-01, 1.00000000e+01],\n",
            "                               [9.54222291e-02, 1.20000000e+01],\n",
            "                               [7.73599153e-02, 1.00000000e+00],\n",
            "                               [3.54411146e-02, 8.00000000e+00],\n",
            "                               [2.70383899e-02, 2.00000000e+00],\n",
            "                               [1.55448663e-02, 1.10000000e+01],\n",
            "                               [1.02757037e-02, 9.00000000e+00],\n",
            "                               [7.60649358e-03, 3.00000000e+00],\n",
            "                               [6.93413616e-03, 1.30000000e+01],\n",
            "                               [5.31610908e-03, 4.00000000e+00],\n",
            "                               [2.70546585e-03, 7.00000000e+00],\n",
            "                               [6.87928779e-05, 6.00000000e+00]])\n",
            "[@debug] dataset.py:270 in knownClassesGet()- unique.shape[0]: 13\n",
            "[@debug] dataset.py:271 in knownClassesGet()\n",
            "         self.paramsTrain.known_classes_percentage: 0.92\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 0\n",
            "         unique_sorted[idx]: array([0.58146715, 0.        ])\n",
            "         cumulative_percentage: 0.581467152214236\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 1\n",
            "         unique_sorted[idx]: array([ 0.13481963, 10.        ])\n",
            "         cumulative_percentage: 0.7162867835634292\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 2\n",
            "         unique_sorted[idx]: array([ 0.09542223, 12.        ])\n",
            "         cumulative_percentage: 0.8117090126339515\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 3\n",
            "         unique_sorted[idx]: array([0.07735992, 1.        ])\n",
            "         cumulative_percentage: 0.8890689279071556\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 4\n",
            "         unique_sorted[idx]: array([0.03544111, 8.        ])\n",
            "         cumulative_percentage: 0.9245100424819261\n",
            "[@debug] dataset.py:283 in knownClassesGet()\n",
            "         self.paramsTrain.known_classes: [0, 1, 10, 12]\n",
            "[@debug] dataset.py:322 in labelPreprocess()\n",
            "         self.paramsTrain.known_classes: [0, 1, 10, 12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] all_classes = [ 0  1  2  3  4  6  7  8  9 10 11 12 13]\n",
            "[@debug] self.paramsTrain.known_classes = [0, 1, 10, 12]\n",
            "[@debug] self.unknown_classes = [ 2  3  4  6  7  8  9 11 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:347 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  1,  2, 11, 13], dtype=uint8),\n",
            "                                                                array([69629012,  2501920,   332862,   580098,   410580]))\n",
            "[@debug] dataset.py:353 in labelPreprocess()\n",
            "         self.classes: array([ 0,  1,  2, 11, 13], dtype=uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] np.unique(self.full_label_train, return_counts=True) = (array([ 0,  1,  2, 11, 13], dtype=uint8), array([69629012,  2501920,   332862,   580098,   410580]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:357 in labelPreprocess()\n",
            "         self.labels2new_labels: {0: 0, 1: 1, 2: 2, 11: 3, 13: 4}\n",
            "         self.new_labels2labels: {0: 0, 1: 1, 2: 2, 3: 11, 4: 13}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming labels2new_labels...\n",
            "Transformed labels2new_labels. Moving bcknd to last...\n",
            "[@debug] dict_filename = results/label_translations/new_labels2labels_lm_20180315_S1.pkl\n",
            "[@debug] self.new_labels2labels = {0: 0, 1: 1, 2: 2, 3: 11, 4: 13}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:378 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                                array([69629012,  2501920,   332862,   580098,   410580]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved bcknd to last\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:387 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                                array([ 2501920,   332862,   580098,   410580, 69629012]))\n",
            "[@debug] dataset.py:388 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                               array([  788843,   107309,   154491,   151337, 72252492]))\n",
            "[@debug] dataset.py:391 in labelPreprocess()- self.class_n: 5\n",
            "[@debug] dataset.py:228 in create_load()\n",
            "         self.patches['train']['label'].shape: (7392, 32, 32)\n",
            "[@debug] dataset.py:229 in create_load()\n",
            "         np.unique(self.patches['train']['label'], return_counts = True): (array([0, 1, 2, 3, 4]), array([2501920,  332862,  580098,  410580, 3743948]))\n",
            "[@debug] dataset.py:230 in create_load()\n",
            "         self.patches['test']['label'].shape: (2528, 32, 32)\n",
            "[@debug] dataset.py:231 in create_load()\n",
            "         np.unique(self.patches['test']['label'], return_counts = True): (array([0, 1, 2, 3, 4]), array([ 788843,  107309,  154491,  151337, 1386692]))\n",
            "[@debug] dataset.py:236 in create_load()\n",
            "         np.unique(self.full_label_train,return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                               array([ 2501920,   332862,   580098,   410580, 69629012]))\n",
            "[@debug] dataset.py:237 in create_load()- self.class_n: 5\n",
            "[@debug] dataset.py:576 in loadMask()\n",
            "         str(self.paramsTrain.path): 'dataset/lm_data'\n",
            "[@debug] dataset.py:578 in loadMask()- self.mask.shape: (8484, 8658)\n",
            "[@debug] train_and_evaluate.py:154 in preprocess()\n",
            "         self.paramsTrain.class_n: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SELECT VALIDATION SET FROM TRAIN SET\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] train_and_evaluate.py:162 in preprocess()\n",
            "         self.paramsTrain.val_set: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] self.paramsTrain.val_set_mode = random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:416 in val_set_get()\n",
            "         self.patches['train']['n']: 7392\n",
            "         self.patches['val']['n']: 1108\n",
            "[@debug] dataset.py:417 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (7392, 2)\n",
            "[@debug] dataset.py:426 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (6284, 2)\n",
            "[@debug] dataset.py:427 in val_set_get()\n",
            "         self.patches['val']['coords'].shape: (1108, 2)\n",
            "[@debug] train_and_evaluate.py:166 in preprocess()\n",
            "         self.data.patches['val']['coords'].shape: (1108, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AUGMENTING TRAINING DATA\n",
            "[@debug] label_type = Nto1\n",
            "Before balancing:\n",
            "data.semantic_balance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:453 in semantic_balance()\n",
            "         balance[\"coords\"].shape: (2800, 2)\n",
            "[@debug] dataset.py:457 in semantic_balance()\n",
            "         np.unique(self.full_label_train, return_counts = True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                                  array([ 2501920,   332862,   580098,   410580, 69629012]))\n",
            "[@debug] dataset.py:463 in semantic_balance()\n",
            "         coords_classes.shape: (6284, 5)\n",
            "[@debug] dataset.py:465 in semantic_balance()\n",
            "         unique_train: array([0, 1, 2, 3, 4], dtype=uint8)\n",
            "[@debug] dataset.py:467 in semantic_balance()- bcknd_idx: 4\n",
            "[@debug] dataset.py:469 in semantic_balance()- psize: 32\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         patch_count: array([3703.,  532.,  856.,  698.,    0.])\n",
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 3703.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 0\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([2581, 3703]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (3703, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 532.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 1\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([5752,  532]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (532, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 856.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 2\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([5428,  856]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (856, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 698.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 3\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([5586,  698]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (698, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 3\n",
            "Balanced train unique (coords):\n",
            "[@debug] self.patches['train']['coords'].shape = (2800, 2)\n",
            "[@debug] self.data.patches['train']['coords'].shape = (2800, 2)\n",
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n",
            "[@debug] self.t_len = 12\n",
            "Initializing Model instance\n",
            "[@debug] self.mp = {'dense': {'recurrent_filters': 128, 'nb_dense_block': 2, 'growth_rate': 64, 'nb_layers_per_block': 1}, 'unet': {'recurrent_filters': 128, 'filter_size': 16}, 'atrous': {'recurrent_filters': 128, 'filter_size': 16, 'dilation_rate_mode': 'auto', 'dilation_rates': [1, 2, 4, 8]}}\n",
            "[@debug] self.stop_epoch = 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] train_and_evaluate.py:138 in setModel()\n",
            "         self.model.name: PosixPath('results/model/lm/model_best_UUnetConvLSTM_mar_lm_dummy.h5')\n",
            "[@debug] train_and_evaluate.py:140 in setModel()\n",
            "         self.model.name: PosixPath('results/model/lm/model_best_UUnetConvLSTM_mar_lm_dummy.h5')\n",
            "[@debug] train_and_evaluate.py:142 in setModel()\n",
            "         self.model.class_n: 4\n",
            "[@debug] train_and_evaluate.py:143 in setModel()- self.data.class_n: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] self.data.class_n = 5\n",
            "[@debug] self.t_len = 12\n",
            "[@debug] self.model_t_len = 12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[@debug] K.int_shape(x) = (None, 12, 8, 8, 64)\n",
            "[@debug] K.int_shape(res2) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(p3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(d3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(x) = (None, 12, 16, 16, 32)\n",
            "[@debug] K.int_shape(res2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(p2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(d2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(x) = (None, 12, 32, 32, 16)\n",
            "[@debug] K.int_shape(res2) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(p1) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(d1) = (None, 32, 32, 16)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 32, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 12, 32, 32, 1 304         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 12, 32, 32, 1 64          time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 12, 32, 32, 1 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 12, 32, 32, 1 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 12, 32, 32, 1 64          time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 12, 32, 32, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 12, 16, 16, 1 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 12, 16, 16, 3 4640        time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 12, 16, 16, 3 128         time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 12, 16, 16, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 12, 8, 8, 32) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 12, 8, 8, 64) 18496       time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 12, 8, 8, 64) 256         time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 12, 8, 8, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 12, 4, 4, 64) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 4, 4, 256)    2950144     time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     147520      conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8, 8, 64)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 128)    0           activation_4[0][0]               \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 64)     73792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 32)   18464       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 16, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 64)   0           activation_6[0][0]               \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   18464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 16)   4624        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           activation_8[0][0]               \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   4624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 4)    68          activation_9[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,244,868\n",
            "Trainable params: 3,244,164\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "[@debug] model.py:237 in train()\n",
            "         data.patches['train']['coords'].shape: (2800, 2)\n",
            "[@debug] model.py:242 in train()- data.t_len: 12\n",
            "[@debug] model.py:243 in train()\n",
            "         data.full_ims_train.shape: (12, 8484, 8658, 2)\n",
            "[@debug] model.py:244 in train()- self.model_t_len: 12\n",
            "[@debug] dataset.py:400 in addPaddingToInput()\n",
            "         im.shape: (12, 8484, 8658, 2)\n",
            "[@debug] model.py:250 in train()\n",
            "         data.full_ims_train.shape: (12, 8484, 8658, 2)\n",
            "[@debug] model.py:253 in train()\n",
            "         self.name: PosixPath('results/model/lm/model_best_UUnetConvLSTM_mar_lm_dummy.h5')\n",
            "[@debug] model.py:308 in applyFitMethod()- self.class_n: 4\n",
            "[@debug] model.py:327 in applyFitMethod()\n",
            "         data.patches['train']['coords'].shape: (2800, 2)\n",
            "[@debug] model.py:328 in applyFitMethod()\n",
            "         data.patches['train']['coords'][0:16]: array([[1776, 3824],\n",
            "                                                       [4144, 6064],\n",
            "                                                       [3536, 7120],\n",
            "                                                       [3280, 2896],\n",
            "                                                       [2640, 6416],\n",
            "                                                       [1424, 4176],\n",
            "                                                       [6352, 1744],\n",
            "                                                       [3536, 7056],\n",
            "                                                       [5872, 4624],\n",
            "                                                       [5360, 5520],\n",
            "                                                       [1552, 4112],\n",
            "                                                       [2000, 6288],\n",
            "                                                       [2640, 2256],\n",
            "                                                       [1648, 4240],\n",
            "                                                       [3472, 7088],\n",
            "                                                       [4144, 6576]])\n",
            "[@debug] model.py:329 in applyFitMethod()\n",
            "         data.patches['val']['coords'][0:16]: array([[1520, 4112],\n",
            "                                                     [5072, 1296],\n",
            "                                                     [4272, 3504],\n",
            "                                                     [2000, 6480],\n",
            "                                                     [6512, 2768],\n",
            "                                                     [6736, 2864],\n",
            "                                                     [ 848, 5200],\n",
            "                                                     [4432, 4240],\n",
            "                                                     [2480, 4272],\n",
            "                                                     [6640, 2896],\n",
            "                                                     [3248, 3760],\n",
            "                                                     [3312, 2800],\n",
            "                                                     [6320, 2960],\n",
            "                                                     [4144, 5584],\n",
            "                                                     [4560, 1840],\n",
            "                                                     [ 816, 6480]])\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] model.py:342 in applyFitMethod()\n",
            "         data.patches['val']['coords'].shape: (1108, 2)\n",
            "[@debug] model.py:343 in applyFitMethod()\n",
            "         data.patches['val']['coords']: array([[1520, 4112],\n",
            "                                               [5072, 1296],\n",
            "                                               [4272, 3504],\n",
            "                                               ...,\n",
            "                                               [1104, 5328],\n",
            "                                               [6768, 2544],\n",
            "                                               [6032, 3216]])\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 175\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.1087 - accuracy: 0.3636"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [59.1  19.91  4.92 56.82]\n",
            " — val_precision: [76.98 12.58 86.09 41.21]\n",
            " — val_recall: [47.96 47.75  2.53 91.46]\n",
            " — mean_f1: 35.1875\n",
            "oa 46.14\n",
            "Found best weights at epoch 1\n",
            "175/175 [==============================] - 51s 143ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.1087 - accuracy: 0.3636 - val_loss: 0.1054 - val_accuracy: 0.4059 - mean_f1: 35.1875\n",
            "Epoch 2/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0700 - accuracy: 0.2423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [75.1  37.41 34.87 67.3 ]\n",
            " — val_precision: [93.   23.51 99.99 54.68]\n",
            " — val_recall: [62.98 91.59 21.12 87.49]\n",
            " — mean_f1: 53.67\n",
            "oa 62.08\n",
            "Found best weights at epoch 2\n",
            "175/175 [==============================] - 24s 134ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0700 - accuracy: 0.2423 - val_loss: 0.0837 - val_accuracy: 0.4000 - mean_f1: 53.6700\n",
            "Epoch 3/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0565 - accuracy: 0.2639"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [93.73 70.2  98.06 81.66]\n",
            " — val_precision: [94.7  72.2  99.88 74.79]\n",
            " — val_recall: [92.78 68.31 96.3  89.92]\n",
            " — mean_f1: 85.9125\n",
            "oa 90.8\n",
            "Found best weights at epoch 3\n",
            "175/175 [==============================] - 24s 135ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0565 - accuracy: 0.2639 - val_loss: 0.0482 - val_accuracy: 0.5991 - mean_f1: 85.9125\n",
            "Epoch 4/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0503 - accuracy: 0.2783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [95.17 80.9  99.29 85.73]\n",
            " — val_precision: [96.18 82.55 98.99 80.47]\n",
            " — val_recall: [94.18 79.31 99.59 91.72]\n",
            " — mean_f1: 90.27250000000001\n",
            "oa 93.38\n",
            "Found best weights at epoch 4\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0503 - accuracy: 0.2783 - val_loss: 0.0426 - val_accuracy: 0.5902 - mean_f1: 90.2725\n",
            "Epoch 5/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0461 - accuracy: 0.2851"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [95.59 84.72 99.81 86.99]\n",
            " — val_precision: [97.01 83.92 99.77 81.42]\n",
            " — val_recall: [94.21 85.54 99.85 93.37]\n",
            " — mean_f1: 91.7775\n",
            "oa 94.19\n",
            "Found best weights at epoch 5\n",
            "175/175 [==============================] - 24s 135ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0461 - accuracy: 0.2851 - val_loss: 0.0398 - val_accuracy: 0.5865 - mean_f1: 91.7775\n",
            "Epoch 6/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0433 - accuracy: 0.2879"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.14 87.94 99.59 88.  ]\n",
            " — val_precision: [98.13 83.44 99.23 83.07]\n",
            " — val_recall: [94.23 92.96 99.95 93.55]\n",
            " — mean_f1: 92.91749999999999\n",
            "oa 94.89\n",
            "Found best weights at epoch 6\n",
            "175/175 [==============================] - 24s 136ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0433 - accuracy: 0.2879 - val_loss: 0.0384 - val_accuracy: 0.5743 - mean_f1: 92.9175\n",
            "Epoch 7/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0409 - accuracy: 0.2914"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.3  85.92 99.92 89.16]\n",
            " — val_precision: [96.96 87.45 99.89 85.  ]\n",
            " — val_recall: [95.64 84.45 99.94 93.76]\n",
            " — mean_f1: 92.82499999999999\n",
            "oa 95.07\n",
            "175/175 [==============================] - 24s 139ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0409 - accuracy: 0.2914 - val_loss: 0.0373 - val_accuracy: 0.5933 - mean_f1: 92.8250\n",
            "Epoch 8/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0394 - accuracy: 0.2919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.43 86.83 99.89 90.22]\n",
            " — val_precision: [97.07 89.08 99.8  85.76]\n",
            " — val_recall: [95.8  84.68 99.99 95.18]\n",
            " — mean_f1: 93.3425\n",
            "oa 95.37\n",
            "Found best weights at epoch 8\n",
            "175/175 [==============================] - 24s 136ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0394 - accuracy: 0.2919 - val_loss: 0.0363 - val_accuracy: 0.5924 - mean_f1: 93.3425\n",
            "Epoch 9/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0376 - accuracy: 0.2938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.55 83.85 99.92 91.56]\n",
            " — val_precision: [95.63 93.31 99.91 90.09]\n",
            " — val_recall: [97.49 76.14 99.93 93.08]\n",
            " — mean_f1: 92.97\n",
            "oa 95.45\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0376 - accuracy: 0.2938 - val_loss: 0.0355 - val_accuracy: 0.6177 - mean_f1: 92.9700\n",
            "Epoch 10/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0362 - accuracy: 0.2996"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.56 83.86 99.9  91.17]\n",
            " — val_precision: [95.13 94.59 99.83 91.87]\n",
            " — val_recall: [98.02 75.32 99.97 90.48]\n",
            " — mean_f1: 92.87250000000002\n",
            "oa 95.43\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0362 - accuracy: 0.2996 - val_loss: 0.0345 - val_accuracy: 0.6204 - mean_f1: 92.8725\n",
            "Epoch 11/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0352 - accuracy: 0.2994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.14 89.88 99.93 91.19]\n",
            " — val_precision: [96.95 91.25 99.91 91.15]\n",
            " — val_recall: [97.32 88.54 99.96 91.24]\n",
            " — mean_f1: 94.535\n",
            "oa 96.24\n",
            "Found best weights at epoch 11\n",
            "175/175 [==============================] - 24s 139ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0352 - accuracy: 0.2994 - val_loss: 0.0332 - val_accuracy: 0.6089 - mean_f1: 94.5350\n",
            "Epoch 12/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0335 - accuracy: 0.3022"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.91 89.11 99.95 90.26]\n",
            " — val_precision: [96.34 91.14 99.94 91.82]\n",
            " — val_recall: [97.49 87.18 99.96 88.75]\n",
            " — mean_f1: 94.05749999999999\n",
            "oa 95.94\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0335 - accuracy: 0.3022 - val_loss: 0.0329 - val_accuracy: 0.6121 - mean_f1: 94.0575\n",
            "Epoch 13/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0328 - accuracy: 0.3043"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.3  92.5  99.87 90.4 ]\n",
            " — val_precision: [97.96 90.3  99.8  88.88]\n",
            " — val_recall: [96.65 94.81 99.94 91.98]\n",
            " — mean_f1: 95.01750000000001\n",
            "oa 96.44\n",
            "Found best weights at epoch 13\n",
            "175/175 [==============================] - 25s 140ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0328 - accuracy: 0.3043 - val_loss: 0.0323 - val_accuracy: 0.5878 - mean_f1: 95.0175\n",
            "Epoch 14/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0315 - accuracy: 0.3044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [96.9  88.04 99.95 90.41]\n",
            " — val_precision: [96.26 93.06 99.93 90.26]\n",
            " — val_recall: [97.56 83.53 99.97 90.55]\n",
            " — mean_f1: 93.82499999999999\n",
            "oa 95.86\n",
            "175/175 [==============================] - 24s 137ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0315 - accuracy: 0.3044 - val_loss: 0.0324 - val_accuracy: 0.6108 - mean_f1: 93.8250\n",
            "Epoch 15/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0306 - accuracy: 0.3050"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.5  92.51 99.95 91.12]\n",
            " — val_precision: [97.73 91.06 99.94 91.03]\n",
            " — val_recall: [97.26 94.01 99.95 91.21]\n",
            " — mean_f1: 95.27\n",
            "oa 96.68\n",
            "Found best weights at epoch 15\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0306 - accuracy: 0.3050 - val_loss: 0.0310 - val_accuracy: 0.6009 - mean_f1: 95.2700\n",
            "Epoch 16/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0299 - accuracy: 0.3061"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.22 91.06 99.95 91.09]\n",
            " — val_precision: [97.64 90.07 99.93 89.77]\n",
            " — val_recall: [96.81 92.07 99.97 92.46]\n",
            " — mean_f1: 94.83000000000001\n",
            "oa 96.36\n",
            "175/175 [==============================] - 24s 139ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0299 - accuracy: 0.3061 - val_loss: 0.0311 - val_accuracy: 0.6003 - mean_f1: 94.8300\n",
            "Epoch 17/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0298 - accuracy: 0.3076"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.56 91.84 99.95 91.79]\n",
            " — val_precision: [96.82 95.52 99.98 93.13]\n",
            " — val_recall: [98.31 88.44 99.91 90.48]\n",
            " — mean_f1: 95.28500000000001\n",
            "oa 96.78\n",
            "Found best weights at epoch 17\n",
            "175/175 [==============================] - 24s 136ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0298 - accuracy: 0.3076 - val_loss: 0.0304 - val_accuracy: 0.6195 - mean_f1: 95.2850\n",
            "Epoch 18/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0284 - accuracy: 0.3091"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.59 94.1  99.91 90.8 ]\n",
            " — val_precision: [97.92 95.54 99.84 88.26]\n",
            " — val_recall: [97.26 92.7  99.98 93.48]\n",
            " — mean_f1: 95.60000000000001\n",
            "oa 96.83\n",
            "Found best weights at epoch 18\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0284 - accuracy: 0.3091 - val_loss: 0.0299 - val_accuracy: 0.6032 - mean_f1: 95.6000\n",
            "Epoch 19/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0274 - accuracy: 0.3088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.7  94.4  99.89 91.62]\n",
            " — val_precision: [98.39 92.49 99.82 89.68]\n",
            " — val_recall: [97.01 96.4  99.96 93.64]\n",
            " — mean_f1: 95.9025\n",
            "oa 97.01\n",
            "Found best weights at epoch 19\n",
            "175/175 [==============================] - 24s 139ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0274 - accuracy: 0.3088 - val_loss: 0.0291 - val_accuracy: 0.5912 - mean_f1: 95.9025\n",
            "Epoch 20/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0265 - accuracy: 0.3100"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.07 94.23 99.95 93.5 ]\n",
            " — val_precision: [97.95 95.32 99.93 93.33]\n",
            " — val_recall: [98.19 93.16 99.97 93.67]\n",
            " — mean_f1: 96.4375\n",
            "oa 97.49\n",
            "Found best weights at epoch 20\n",
            "175/175 [==============================] - 24s 137ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0265 - accuracy: 0.3100 - val_loss: 0.0280 - val_accuracy: 0.6071 - mean_f1: 96.4375\n",
            "Epoch 21/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0260 - accuracy: 0.3095"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.1  91.97 99.9  90.76]\n",
            " — val_precision: [98.56 87.11 99.83 87.74]\n",
            " — val_recall: [95.68 97.41 99.97 94.  ]\n",
            " — mean_f1: 94.9325\n",
            "oa 96.28\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0260 - accuracy: 0.3095 - val_loss: 0.0296 - val_accuracy: 0.5757 - mean_f1: 94.9325\n",
            "Epoch 22/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0251 - accuracy: 0.3096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.87 94.56 99.94 92.41]\n",
            " — val_precision: [98.46 93.38 99.91 90.33]\n",
            " — val_recall: [97.28 95.76 99.97 94.59]\n",
            " — mean_f1: 96.195\n",
            "oa 97.24\n",
            "175/175 [==============================] - 24s 137ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0251 - accuracy: 0.3096 - val_loss: 0.0273 - val_accuracy: 0.5921 - mean_f1: 96.1950\n",
            "Epoch 23/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0257 - accuracy: 0.3083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.06 93.44 99.96 93.7 ]\n",
            " — val_precision: [98.39 89.85 99.95 94.99]\n",
            " — val_recall: [97.73 97.33 99.97 92.44]\n",
            " — mean_f1: 96.28999999999999\n",
            "oa 97.42\n",
            "175/175 [==============================] - 25s 142ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0257 - accuracy: 0.3083 - val_loss: 0.0265 - val_accuracy: 0.5920 - mean_f1: 96.2900\n",
            "Epoch 24/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0243 - accuracy: 0.3079"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.66 93.56 99.87 92.19]\n",
            " — val_precision: [98.76 88.57 99.75 90.94]\n",
            " — val_recall: [96.59 99.15 99.99 93.48]\n",
            " — mean_f1: 95.82000000000001\n",
            "oa 96.97\n",
            "175/175 [==============================] - 24s 135ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0243 - accuracy: 0.3079 - val_loss: 0.0267 - val_accuracy: 0.5760 - mean_f1: 95.8200\n",
            "Epoch 25/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0237 - accuracy: 0.3089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.75 93.96 99.95 92.57]\n",
            " — val_precision: [99.19 89.39 99.91 89.27]\n",
            " — val_recall: [96.35 99.02 99.99 96.11]\n",
            " — mean_f1: 96.05749999999999\n",
            "oa 97.11\n",
            "175/175 [==============================] - 24s 135ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0237 - accuracy: 0.3089 - val_loss: 0.0263 - val_accuracy: 0.5773 - mean_f1: 96.0575\n",
            "Epoch 26/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0227 - accuracy: 0.3072"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.94 92.86 99.92 94.43]\n",
            " — val_precision: [99.39 88.36 99.84 91.1 ]\n",
            " — val_recall: [96.54 97.83 99.99 98.01]\n",
            " — mean_f1: 96.28750000000001\n",
            "oa 97.34\n",
            "175/175 [==============================] - 24s 136ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0227 - accuracy: 0.3072 - val_loss: 0.0254 - val_accuracy: 0.5788 - mean_f1: 96.2875\n",
            "Epoch 27/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0221 - accuracy: 0.3075"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.41 95.51 99.95 94.75]\n",
            " — val_precision: [99.43 93.29 99.89 91.4 ]\n",
            " — val_recall: [ 97.4   97.83 100.    98.34]\n",
            " — mean_f1: 97.155\n",
            "oa 97.94\n",
            "Found best weights at epoch 27\n",
            "175/175 [==============================] - 25s 142ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0221 - accuracy: 0.3075 - val_loss: 0.0247 - val_accuracy: 0.5883 - mean_f1: 97.1550\n",
            "Epoch 28/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0216 - accuracy: 0.3105"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.64 95.65 99.94 95.75]\n",
            " — val_precision: [99.28 94.07 99.88 93.78]\n",
            " — val_recall: [ 98.02  97.29 100.    97.81]\n",
            " — mean_f1: 97.495\n",
            "oa 98.23\n",
            "Found best weights at epoch 28\n",
            "175/175 [==============================] - 24s 135ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0216 - accuracy: 0.3105 - val_loss: 0.0234 - val_accuracy: 0.5963 - mean_f1: 97.4950\n",
            "Epoch 29/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0210 - accuracy: 0.3084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.42 94.66 99.9  95.43]\n",
            " — val_precision: [99.52 91.05 99.8  92.87]\n",
            " — val_recall: [ 97.34  98.57 100.    98.14]\n",
            " — mean_f1: 97.1025\n",
            "oa 97.94\n",
            "175/175 [==============================] - 23s 133ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0210 - accuracy: 0.3084 - val_loss: 0.0237 - val_accuracy: 0.5800 - mean_f1: 97.1025\n",
            "Epoch 30/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0210 - accuracy: 0.3067"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.2  93.94 99.75 94.49]\n",
            " — val_precision: [98.46 96.56 99.5  91.61]\n",
            " — val_recall: [ 97.93  91.45 100.    97.55]\n",
            " — mean_f1: 96.595\n",
            "oa 97.62\n",
            "175/175 [==============================] - 23s 134ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0210 - accuracy: 0.3067 - val_loss: 0.0234 - val_accuracy: 0.6060 - mean_f1: 96.5950\n",
            "Epoch 31/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0212 - accuracy: 0.3074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.04 95.29 99.96 92.19]\n",
            " — val_precision: [97.89 96.97 99.94 91.75]\n",
            " — val_recall: [98.18 93.66 99.97 92.64]\n",
            " — mean_f1: 96.37\n",
            "oa 97.41\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0212 - accuracy: 0.3074 - val_loss: 0.0234 - val_accuracy: 0.6102 - mean_f1: 96.3700\n",
            "Epoch 32/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0204 - accuracy: 0.3127"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [97.6  94.59 99.95 90.75]\n",
            " — val_precision: [97.73 97.83 99.97 88.  ]\n",
            " — val_recall: [97.48 91.55 99.94 93.68]\n",
            " — mean_f1: 95.7225\n",
            "oa 96.88\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0204 - accuracy: 0.3127 - val_loss: 0.0238 - val_accuracy: 0.6139 - mean_f1: 95.7225\n",
            "Epoch 33/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0194 - accuracy: 0.3069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.22 95.39 99.85 94.06]\n",
            " — val_precision: [99.49 91.84 99.7  90.74]\n",
            " — val_recall: [ 96.98  99.23 100.    97.64]\n",
            " — mean_f1: 96.88000000000001\n",
            "oa 97.71\n",
            "175/175 [==============================] - 25s 141ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0194 - accuracy: 0.3069 - val_loss: 0.0221 - val_accuracy: 0.5848 - mean_f1: 96.8800\n",
            "Epoch 34/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0187 - accuracy: 0.3085"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.58 94.68 99.87 96.51]\n",
            " — val_precision: [99.73 90.08 99.75 94.6 ]\n",
            " — val_recall: [ 97.46  99.77 100.    98.5 ]\n",
            " — mean_f1: 97.41\n",
            "oa 98.17\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0187 - accuracy: 0.3085 - val_loss: 0.0211 - val_accuracy: 0.5845 - mean_f1: 97.4100\n",
            "Epoch 35/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0182 - accuracy: 0.3082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.71 95.63 99.91 96.44]\n",
            " — val_precision: [99.84 91.94 99.82 93.79]\n",
            " — val_recall: [ 97.61  99.64 100.    99.24]\n",
            " — mean_f1: 97.6725\n",
            "oa 98.34\n",
            "Found best weights at epoch 35\n",
            "175/175 [==============================] - 24s 136ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0182 - accuracy: 0.3082 - val_loss: 0.0205 - val_accuracy: 0.5841 - mean_f1: 97.6725\n",
            "Epoch 36/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0176 - accuracy: 0.3089"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.5  94.12 99.93 96.46]\n",
            " — val_precision: [99.72 89.11 99.87 94.47]\n",
            " — val_recall: [ 97.3   99.74 100.    98.53]\n",
            " — mean_f1: 97.2525\n",
            "oa 98.06\n",
            "175/175 [==============================] - 24s 137ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0176 - accuracy: 0.3089 - val_loss: 0.0204 - val_accuracy: 0.5812 - mean_f1: 97.2525\n",
            "Epoch 37/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0172 - accuracy: 0.3082"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.7  95.61 99.93 96.4 ]\n",
            " — val_precision: [99.78 92.15 99.87 93.72]\n",
            " — val_recall: [ 97.64  99.34 100.    99.24]\n",
            " — mean_f1: 97.66\n",
            "oa 98.33\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0172 - accuracy: 0.3082 - val_loss: 0.0198 - val_accuracy: 0.5877 - mean_f1: 97.6600\n",
            "Epoch 38/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0167 - accuracy: 0.3077"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [99.21 97.39 99.91 97.62]\n",
            " — val_precision: [99.65 95.79 99.82 96.65]\n",
            " — val_recall: [ 98.78  99.05 100.    98.61]\n",
            " — mean_f1: 98.5325\n",
            "oa 98.97\n",
            "Found best weights at epoch 38\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0167 - accuracy: 0.3077 - val_loss: 0.0183 - val_accuracy: 0.5993 - mean_f1: 98.5325\n",
            "Epoch 39/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0166 - accuracy: 0.3097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.61 93.75 99.89 97.16]\n",
            " — val_precision: [99.45 89.95 99.79 96.07]\n",
            " — val_recall: [ 97.79  97.88 100.    98.27]\n",
            " — mean_f1: 97.35249999999999\n",
            "oa 98.18\n",
            "175/175 [==============================] - 24s 140ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0166 - accuracy: 0.3097 - val_loss: 0.0191 - val_accuracy: 0.5874 - mean_f1: 97.3525\n",
            "Epoch 40/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0163 - accuracy: 0.3078"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.71 96.44 99.92 95.3 ]\n",
            " — val_precision: [98.9  96.06 99.84 94.67]\n",
            " — val_recall: [ 98.52  96.83 100.    95.93]\n",
            " — mean_f1: 97.5925\n",
            "oa 98.3\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0163 - accuracy: 0.3078 - val_loss: 0.0181 - val_accuracy: 0.6050 - mean_f1: 97.5925\n",
            "Epoch 41/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0172 - accuracy: 0.3117"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.2  94.89 99.96 93.2 ]\n",
            " — val_precision: [97.63 97.61 99.97 94.34]\n",
            " — val_recall: [98.78 92.31 99.95 92.09]\n",
            " — mean_f1: 96.5625\n",
            "oa 97.61\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0172 - accuracy: 0.3117 - val_loss: 0.0186 - val_accuracy: 0.6233 - mean_f1: 96.5625\n",
            "Epoch 42/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0157 - accuracy: 0.3103"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.2  95.33 99.93 93.64]\n",
            " — val_precision: [99.3  91.6  99.86 91.19]\n",
            " — val_recall: [ 97.13  99.37 100.    96.23]\n",
            " — mean_f1: 96.775\n",
            "oa 97.66\n",
            "175/175 [==============================] - 24s 138ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0157 - accuracy: 0.3103 - val_loss: 0.0186 - val_accuracy: 0.5873 - mean_f1: 96.7750\n",
            "Epoch 43/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0149 - accuracy: 0.3097"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.49 94.42 99.95 95.93]\n",
            " — val_precision: [99.35 89.78 99.89 95.43]\n",
            " — val_recall: [ 97.64  99.58 100.    96.44]\n",
            " — mean_f1: 97.1975\n",
            "oa 98.03\n",
            "175/175 [==============================] - 25s 141ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0149 - accuracy: 0.3097 - val_loss: 0.0176 - val_accuracy: 0.5876 - mean_f1: 97.1975\n",
            "Epoch 44/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0145 - accuracy: 0.3096"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.74 95.08 99.94 96.72]\n",
            " — val_precision: [99.4  91.17 99.88 96.55]\n",
            " — val_recall: [ 98.09  99.33 100.    96.9 ]\n",
            " — mean_f1: 97.62\n",
            "oa 98.35\n",
            "175/175 [==============================] - 24s 140ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0145 - accuracy: 0.3096 - val_loss: 0.0168 - val_accuracy: 0.5905 - mean_f1: 97.6200\n",
            "Epoch 45/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0141 - accuracy: 0.3090"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.87 95.63 99.94 97.13]\n",
            " — val_precision: [99.65 92.   99.89 96.09]\n",
            " — val_recall: [ 98.11  99.56 100.    98.19]\n",
            " — mean_f1: 97.8925\n",
            "oa 98.53\n",
            "175/175 [==============================] - 24s 135ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0141 - accuracy: 0.3090 - val_loss: 0.0163 - val_accuracy: 0.5879 - mean_f1: 97.8925\n",
            "Epoch 46/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0137 - accuracy: 0.3094"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.92 95.43 99.93 97.55]\n",
            " — val_precision: [99.71 91.57 99.86 96.71]\n",
            " — val_recall: [ 98.15  99.62 100.    98.42]\n",
            " — mean_f1: 97.95750000000001\n",
            "oa 98.59\n",
            "175/175 [==============================] - 24s 137ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0137 - accuracy: 0.3094 - val_loss: 0.0160 - val_accuracy: 0.5887 - mean_f1: 97.9575\n",
            "Epoch 47/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0133 - accuracy: 0.3084"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " — val_f1: [98.96 95.76 99.93 97.44]\n",
            " — val_precision: [99.72 92.31 99.87 96.34]\n",
            " — val_recall: [ 98.22  99.47 100.    98.55]\n",
            " — mean_f1: 98.0225\n",
            "oa 98.64\n",
            "175/175 [==============================] - 24s 136ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0133 - accuracy: 0.3084 - val_loss: 0.0157 - val_accuracy: 0.5901 - mean_f1: 98.0225\n",
            "Epoch 48/70\n",
            " 45/175 [======>.......................] - ETA: 12s - batch: 22.0000 - size: 16.0000 - loss: 0.0132 - accuracy: 0.3205"
          ]
        }
      ]
    }
  ]
}