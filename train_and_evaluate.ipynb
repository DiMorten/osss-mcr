{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/osss-mcr/blob/coords7/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54f83de-1035-4b1b-92e9-48c0723ed5fb"
      },
      "source": [
        "!pip install icecream\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "!pip install unrar\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/lm_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.8.0)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.7/dist-packages (0.9.19)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.7/dist-packages (from kora) (1.3.26)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "Requirement already satisfied: unrar in /usr/local/lib/python3.7/dist-packages (0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa646f3-1b73-4464-d014-9702fd727611"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "481c05df-128b-4de9-f1a4-d571e38f2a9f"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf osss-mcr\n",
        "  !git clone --branch coords7 https://github.com/DiMorten/osss-mcr.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'osss-mcr'...\n",
            "remote: Enumerating objects: 2539, done.\u001b[K\n",
            "remote: Counting objects: 100% (338/338), done.\u001b[K\n",
            "remote: Compressing objects: 100% (251/251), done.\u001b[K\n",
            "remote: Total 2539 (delta 230), reused 153 (delta 62), pack-reused 2201\u001b[K\n",
            "Receiving objects: 100% (2539/2539), 37.67 MiB | 17.38 MiB/s, done.\n",
            "Resolving deltas: 100% (1696/1696), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9063fd49-f535-4ed1-b43b-88161cb40e69"
      },
      "source": [
        "# !cp -r /content/drive/MyDrive/PhD/datasets/lm_data /content/osss-mcr/dataset/\n",
        "\n",
        "os.chdir('/content/osss-mcr/dataset/')\n",
        "!gdown --id 1MPqRKFcT2GzWGQM7PO7vy8X-smf5kFAV"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1MPqRKFcT2GzWGQM7PO7vy8X-smf5kFAV\n",
            "To: /content/osss-mcr/dataset/lm_data.rar\n",
            "7.55GB [01:17, 97.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqHMMepwmHX8",
        "outputId": "73feb736-5305-4125-e2fe-186590bb8e32"
      },
      "source": [
        "!unrar x -y \"lm_data.rar\" \"/content/osss-mcr/dataset/\"\n",
        "os.remove(\"lm_data.rar\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from lm_data.rar\n",
            "\n",
            "Extracting  /content/osss-mcr/dataset/lm_data/coords_test.npy            \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/coords_test_centered.npy     \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/coords_train.npy           \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/coords_train_centered.npy     \b\b\b\b  0%\b\b\b\b\b  OK \n",
            "Creating    /content/osss-mcr/dataset/lm_data/in_sar                  OK\n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20160927_S1.npy     \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20161015_S1.npy     \b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20161120_S1.npy     \b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20161214_S1.npy     \b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170119_S1.npy     \b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170212_S1.npy     \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170308_S1.npy     \b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170413_S1.npy     \b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170519_S1.npy     \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170612_S1.npy     \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170706_S1.npy     \b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170811_S1.npy     \b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20170916_S1.npy     \b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20171010_S1.npy     \b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20171115_S1.npy     \b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20171209_S1.npy     \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20180114_S1.npy     \b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20180219_S1.npy     \b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20180315_S1.npy     \b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20180420_S1.npy     \b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20180514_S1.npy     \b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/in_sar/20180619_S1.npy     \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Creating    /content/osss-mcr/dataset/lm_data/labels                  OK\n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20160927_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20161015_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20161120_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20161214_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170119_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170212_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170308_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170413_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170519_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170612_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170706_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170811_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20170916_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20171010_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20171115_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20171209_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20180114_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20180219_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20180315_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20180420_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20180514_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/labels/20180619_S1.tif     \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  /content/osss-mcr/dataset/lm_data/TrainTestMask.tif          \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a2f84f-784e-45cf-ef36-dae9f4f598ba"
      },
      "source": [
        "os.chdir('/content/osss-mcr/')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['obj',\n",
              " 'evaluate_open_set.py',\n",
              " 'parameters',\n",
              " 'README.md',\n",
              " 'train_and_evaluate_open_set.ipynb',\n",
              " '__init__.py',\n",
              " '.gitignore',\n",
              " 'dataset',\n",
              " 'train_and_evaluate_openset.ipynb',\n",
              " '.git',\n",
              " 'evaluate.py',\n",
              " 'deb.py',\n",
              " 'train_and_evaluate.ipynb',\n",
              " 'environment.yml',\n",
              " 'train_and_evaluate_open_set.py',\n",
              " 'train_and_evaluate.py',\n",
              " 'src']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from src.densnet import DenseNetFCN\n",
        "from src.densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from src.keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from tensorflow.keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from tensorflow.keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "from src.generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from src.dataSource import DataSource, SARSource, Dataset, LEM, LEM2, CampoVerde\n",
        "from src.model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.params_train import ParamsTrain\n",
        "from parameters.params_mosaic import ParamsReconstruct\n",
        "\n",
        "from icecream import ic\n",
        "from src.monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from src.model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from src.dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from src.patch_extractor import PatchExtractor\n",
        "\n",
        "from src.mosaic import seq_add_padding, add_padding, Mosaic, MosaicHighRAM, MosaicHighRAMPostProcessing\n",
        "from src.postprocessing import PostProcessingMosaic\n",
        "\n",
        "from src.metrics import Metrics, MetricsTranslated\n",
        "\n",
        "ic.configureOutput(includeContext=True)\n",
        "np.random.seed(2021)\n",
        "tf.random.set_seed(2021)\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "tf.compat.v1.experimental.output_all_intermediates(True)\n",
        "\n",
        "from train_and_evaluate import TrainTest"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35733e53-7271-4409-a0f5-3fad1f994712"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  8 23:06:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/osss-mcr/networks/convlstm_networks/train_src/parameters/params_train.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2af2db55-550f-48b7-e313-92f11ce5fa30"
      },
      "source": [
        "paramsTrainCustom = {\n",
        "\t'getFullIms': True,\n",
        "\t'coordsExtract': True,\n",
        "\t'train': True,\n",
        "\t'openSetMethod': None, # Options: None, OpenPCS, OpenPCS++\n",
        "#\t\t'openSetLoadModel': True,\n",
        "\t'selectMainClasses': True,\n",
        "\t'dataset': 'lm', # lm: L Eduardo Magalhaes.\n",
        "\t'seq_date': 'mar',\t# jun, mar\t\n",
        "    'dataSource': SARSource()\n",
        "}\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/', **paramsTrainCustom)\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] params_train.py:107 in __init__()- self.seq_date: 'mar'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] params_train.py:166 in __init__()- self.stride: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['no_mode.json', 'parameters_openset.json', 'params_batchprocessing.py', '__init__.py', '__pycache__', 'parameters_closedset_groupclasses.json', 'params_mosaic.py', 'save_nonaugmented_train_patches.json', 'params_train.py']\n",
            "[@debug] self.seq_mode = fixed\n",
            "[@debug] self.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7f8c91e1bb50>\n",
            "[@debug] self.ds = <src.dataSource.LEM object at 0x7f8c91e88250>\n",
            "[@debug] dataSource.name = SARSource\n",
            "self.im_list ['20170413_S1', '20170519_S1', '20170612_S1', '20170706_S1', '20170811_S1', '20170916_S1', '20171010_S1', '20171115_S1', '20171209_S1', '20180114_S1', '20180219_S1', '20180315_S1']\n",
            "fixed mar\n",
            "[@debug] self.t_len = 12\n",
            "20170413\n",
            "20170519\n",
            "20170612\n",
            "20170706\n",
            "20170811\n",
            "20170916\n",
            "20171010\n",
            "20171115\n",
            "20171209\n",
            "20180114\n",
            "20180219\n",
            "20180315\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[103, 139, 163, 187, 223, 259, 283, 319, 343, 14, 50, 74]\n",
            "[[0.9917   0.4104  ]\n",
            " [0.849    0.142   ]\n",
            " [0.6763   0.03214 ]\n",
            " [0.4744   0.000663]\n",
            " [0.1897   0.1079  ]\n",
            " [0.01993  0.3604  ]\n",
            " [0.00414  0.564   ]\n",
            " [0.133    0.84    ]\n",
            " [0.2998   0.958   ]\n",
            " [0.611    0.988   ]\n",
            " [0.8726   0.8335  ]\n",
            " [0.975    0.6562  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XFXeoNjGXSo",
        "outputId": "e1936cd9-372d-4696-cfb0-07b4c5526ea4"
      },
      "source": [
        "trainTest.main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <src.dataSource.SARSource object at 0x7f8c92ce1b10>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('dataset/lm_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('dataset/lm_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/osss-mcr'\n",
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8484, 8658, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20170413_S1',\n",
            "                                '20170519_S1',\n",
            "                                '20170612_S1',\n",
            "                                '20170706_S1',\n",
            "                                '20170811_S1',\n",
            "                                '20170916_S1',\n",
            "                                '20171010_S1',\n",
            "                                '20171115_S1',\n",
            "                                '20171209_S1',\n",
            "                                '20180114_S1',\n",
            "                                '20180219_S1',\n",
            "                                '20180315_S1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170413_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.136962890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 133.125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "dataset/lm_data/labels/20170413_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170413_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "1 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170519_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.158203125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 358.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "dataset/lm_data/labels/20170519_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170519_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "2 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170612_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1300048828125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 136.875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170612_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170612_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    18593,   268963,    84263,    45419,   106962,\n",
            "         286551,  1325915,    21332,   208028,    84083,   770815,\n",
            "          38849,  2345394]))\n",
            "3 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170706_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1263427734375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 158.75\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170706_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170706_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13], dtype=int8), array([67849305,    12634,   185207,    73895,    45419,    11279,\n",
            "         262098,   939013,    21332,   199301,    45499,   770815,\n",
            "          38849,  2999826]))\n",
            "4 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170811_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1195068359375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 152.125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170811_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170811_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,    74031,    10661,    45419,     5872,   106217,\n",
            "         186264,    21332,   194734,    39957,   770815,    38849,\n",
            "        4105947,     5069]))\n",
            "5 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20170916_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1163330078125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 157.875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20170916_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20170916_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,    25250,    43089,     2529,    10214,    12391,\n",
            "          21332,   194734,    12001,   739031,    70633,  4450376,\n",
            "          23587]))\n",
            "6 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20171010_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.115966796875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 164.75\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20171010_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20171010_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  4,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,     6337,    43089,    21332,    88766,    28092,\n",
            "         734589,    75075,  4574286,    33601]))\n",
            "7 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20171115_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1326904296875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 141.25\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20171115_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20171115_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  4,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,    22686,     9933,    43089,    21332,    75788,\n",
            "          46374,   734589,    75075,  4524955,    51346]))\n",
            "8 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20171209_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1416015625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 142.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20171209_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20171209_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  4,  5,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,   801632,   168412,    43089,     4153,    21332,\n",
            "         117985,    46374,   734589,    75075,  3506223,    86303]))\n",
            "9 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20180114_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.162109375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 151.5\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20180114_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20180114_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,  3322749,   408374,    26142,    43089,     4153,\n",
            "          21332,   153357,    46374,   734589,    75075,   393731,\n",
            "         376202]))\n",
            "10 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20180219_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1680908203125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 154.5\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20180219_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20180219_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,  3442264,   437303,   151144,    43089,      625,\n",
            "          21332,   174664,    46374,   734589,    75075,   255706,\n",
            "         223002]))\n",
            "11 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = dataset/lm_data/in_sar/20180315_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.17919921875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 173.625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = -1.0\n",
            "dataset/lm_data/labels/20180315_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = dataset/lm_data/labels/20180315_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14], dtype=int8), array([67849305,  3290763,   440171,   151144,    43089,    28864,\n",
            "            625,    21332,   173538,    46374,   734589,    71457,\n",
            "         561917,    41304]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataSource.py:254 in im_load()\n",
            "         patch[\"full_ims\"].shape: (12, 8484, 8658, 2)\n",
            "[@debug] dataSource.py:255 in im_load()\n",
            "         patch[\"full_label_ims\"].shape: (12, 8484, 8658)\n",
            "[@debug] dataSource.py:256 in im_load()\n",
            "         patch[\"full_ims\"].dtype: dtype('float16')\n",
            "[@debug] dataSource.py:257 in im_load()\n",
            "         patch[\"full_label_ims\"].dtype: dtype('int8')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] np.unique(patch['full_label_ims'],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "      dtype=int8), array([814191660,  10948507,   2561907,    665775,    528718,    377736,\n",
            "         1238182,   5116663,    255984,   1996951,    609668,   9000640,\n",
            "          711710,  32409149,    840414]))\n",
            "-1.0 1.0 0.1404\n",
            "[@debug] self.dataset.name = lm\n",
            "[@debug] self.dataset.scaler_name = lm\n",
            "[@debug] self.dataset.seq_mode = fixed\n",
            "[@debug] self.dataset.seq_date = mar\n",
            "[@debug] self.dataset.scaler_load = False\n",
            "[@debug] im.shape = (12, 8484, 8658, 2)\n",
            "[@debug] im_flat[mask_flat==1,:].shape = (51633252, 2)\n",
            "0.0001221 1.0 0.0494\n",
            "[@debug] im_norm.shape = (12, 8484, 8658, 2)\n",
            "FINISHED NORMALIZING, RESULT:\n",
            "-60.66 58.44 3.367\n",
            "[@debug] im.shape = (12, 8484, 8658)\n",
            "[@debug] mask_train.shape = (8484, 8658)\n",
            "[@debug] im.dtype = uint8\n",
            "[@debug] mask_train.dtype = uint8\n",
            "[@debug] im_train.shape = (12, 8484, 8658)\n",
            "Train masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [829820412   8219740   1823768    467950    398108    236613    916694\n",
            "   4216447    139692   1659002    541417   7124176    679430  24636794\n",
            "    573421]\n",
            "Test masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] [865824912   2728767    738139    197825    130610    141123    321488\n",
            "    900216    116292    337949     68251   1876464     32280   7772355\n",
            "    266993]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:127 in getFullIms()\n",
            "         self.paramsTrain.path / 'full_ims/full_ims_test.npy': PosixPath('dataset/lm_data/full_ims/full_ims_test.npy')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STARTED PATCH EXTRACTION\n",
            "[@debug] gridx.shape = (271,)\n",
            "[@debug] gridy.shape = (266,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] patch_extractor.py:205 in extract()\n",
            "         coords_train.shape: (7392, 2)\n",
            "         coords_test.shape: (2528, 2)\n",
            "[@debug] patch_extractor.py:206 in extract()\n",
            "         coords_train.dtype: dtype('int64')\n",
            "[@debug] patch_extractor.py:207 in extract()\n",
            "         coords_train[0]: array([5456,  880])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:96 in __init__()- self.class_n: 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] self.t_len = 12\n",
            "Initializing Dataset instance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] train_and_evaluate.py:123 in setData()- self.data.class_n: 14\n",
            "[@debug] dataset.py:199 in create_load()\n",
            "         os.path.dirname(os.path.abspath(__file__)): '/content/osss-mcr/src'\n",
            "[@debug] dataset.py:200 in create_load()\n",
            "         os.getcwd(): '/content/osss-mcr'\n",
            "[@debug] dataset.py:204 in create_load()\n",
            "         self.patches['train']['coords'].shape: (7392, 2)\n",
            "[@debug] dataset.py:297 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "                                                                     dtype=uint8),\n",
            "                                                                array([69151701,  2501920,   332862,   116340,    32729,    22874,\n",
            "                                                                           296,    11641,   152495,    44214,   580098,    66886,\n",
            "                                                                        410580,    29836]))\n",
            "[@debug] dataset.py:298 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "                                                                    dtype=uint8),\n",
            "                                                               array([72152076,   788843,   107309,    34804,    10360,     5990,\n",
            "                                                                          329,     9691,    21043,     2160,   154491,     4571,\n",
            "                                                                       151337,    11468]))\n",
            "[@debug] dataset.py:318 in labelPreprocess()\n",
            "         self.paramsTrain.selectMainClasses: True\n",
            "[@debug] dataset.py:252 in knownClassesGet()\n",
            "         unique: array([ 0,  1,  2,  3,  4,  5,  7,  8,  9, 10, 11, 12, 13, 14],\n",
            "                       dtype=uint8)\n",
            "         count: array([69151701,  2501920,   332862,   116340,    32729,    22874,\n",
            "                            296,    11641,   152495,    44214,   580098,    66886,\n",
            "                         410580,    29836])\n",
            "[@debug] dataset.py:256 in knownClassesGet()\n",
            "         unique: array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11, 12, 13], dtype=uint8)\n",
            "         count: array([2501920,  332862,  116340,   32729,   22874,     296,   11641,\n",
            "                        152495,   44214,  580098,   66886,  410580,   29836])\n",
            "[@debug] dataset.py:259 in knownClassesGet()- total_count: 4302771\n",
            "[@debug] dataset.py:261 in knownClassesGet()\n",
            "         count_percentage: array([5.81467152e-01, 7.73599153e-02, 2.70383899e-02, 7.60649358e-03,\n",
            "                                  5.31610908e-03, 6.87928779e-05, 2.70546585e-03, 3.54411146e-02,\n",
            "                                  1.02757037e-02, 1.34819631e-01, 1.55448663e-02, 9.54222291e-02,\n",
            "                                  6.93413616e-03])\n",
            "[@debug] dataset.py:262 in knownClassesGet()\n",
            "         sorted(zip(count_percentage, unique)): [(6.879287789194451e-05, 6),\n",
            "                                                 (0.0027054658497977233, 7),\n",
            "                                                 (0.005316109084122766, 4),\n",
            "                                                 (0.006934136164811002, 13),\n",
            "                                                 (0.007606493582856257, 3),\n",
            "                                                 (0.010275703726737955, 9),\n",
            "                                                 (0.015544866319866894, 11),\n",
            "                                                 (0.027038389911989275, 2),\n",
            "                                                 (0.03544111457477054, 8),\n",
            "                                                 (0.07735991527320417, 1),\n",
            "                                                 (0.09542222907052222, 12),\n",
            "                                                 (0.13481963134919334, 10),\n",
            "                                                 (0.581467152214236, 0)]\n",
            "[@debug] dataset.py:266 in knownClassesGet()\n",
            "         unique_sorted: array([[5.81467152e-01, 0.00000000e+00],\n",
            "                               [1.34819631e-01, 1.00000000e+01],\n",
            "                               [9.54222291e-02, 1.20000000e+01],\n",
            "                               [7.73599153e-02, 1.00000000e+00],\n",
            "                               [3.54411146e-02, 8.00000000e+00],\n",
            "                               [2.70383899e-02, 2.00000000e+00],\n",
            "                               [1.55448663e-02, 1.10000000e+01],\n",
            "                               [1.02757037e-02, 9.00000000e+00],\n",
            "                               [7.60649358e-03, 3.00000000e+00],\n",
            "                               [6.93413616e-03, 1.30000000e+01],\n",
            "                               [5.31610908e-03, 4.00000000e+00],\n",
            "                               [2.70546585e-03, 7.00000000e+00],\n",
            "                               [6.87928779e-05, 6.00000000e+00]])\n",
            "[@debug] dataset.py:270 in knownClassesGet()- unique.shape[0]: 13\n",
            "[@debug] dataset.py:271 in knownClassesGet()\n",
            "         self.paramsTrain.known_classes_percentage: 0.92\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 0\n",
            "         unique_sorted[idx]: array([0.58146715, 0.        ])\n",
            "         cumulative_percentage: 0.581467152214236\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 1\n",
            "         unique_sorted[idx]: array([ 0.13481963, 10.        ])\n",
            "         cumulative_percentage: 0.7162867835634292\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 2\n",
            "         unique_sorted[idx]: array([ 0.09542223, 12.        ])\n",
            "         cumulative_percentage: 0.8117090126339515\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 3\n",
            "         unique_sorted[idx]: array([0.07735992, 1.        ])\n",
            "         cumulative_percentage: 0.8890689279071556\n",
            "[@debug] dataset.py:274 in knownClassesGet()\n",
            "         idx: 4\n",
            "         unique_sorted[idx]: array([0.03544111, 8.        ])\n",
            "         cumulative_percentage: 0.9245100424819261\n",
            "[@debug] dataset.py:283 in knownClassesGet()\n",
            "         self.paramsTrain.known_classes: [0, 1, 10, 12]\n",
            "[@debug] dataset.py:322 in labelPreprocess()\n",
            "         self.paramsTrain.known_classes: [0, 1, 10, 12]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] all_classes = [ 0  1  2  3  4  6  7  8  9 10 11 12 13]\n",
            "[@debug] self.paramsTrain.known_classes = [0, 1, 10, 12]\n",
            "[@debug] self.unknown_classes = [ 2  3  4  6  7  8  9 11 13]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:347 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  1,  2, 11, 13], dtype=uint8),\n",
            "                                                                array([69629012,  2501920,   332862,   580098,   410580]))\n",
            "[@debug] dataset.py:353 in labelPreprocess()\n",
            "         self.classes: array([ 0,  1,  2, 11, 13], dtype=uint8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] np.unique(self.full_label_train, return_counts=True) = (array([ 0,  1,  2, 11, 13], dtype=uint8), array([69629012,  2501920,   332862,   580098,   410580]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:357 in labelPreprocess()\n",
            "         self.labels2new_labels: {0: 0, 1: 1, 2: 2, 11: 3, 13: 4}\n",
            "         self.new_labels2labels: {0: 0, 1: 1, 2: 2, 3: 11, 4: 13}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transforming labels2new_labels...\n",
            "Transformed labels2new_labels. Moving bcknd to last...\n",
            "[@debug] dict_filename = results/label_translations/new_labels2labels_lm_20180315_S1.pkl\n",
            "[@debug] self.new_labels2labels = {0: 0, 1: 1, 2: 2, 3: 11, 4: 13}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:378 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                                array([69629012,  2501920,   332862,   580098,   410580]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved bcknd to last\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:387 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                                array([ 2501920,   332862,   580098,   410580, 69629012]))\n",
            "[@debug] dataset.py:388 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                               array([  788843,   107309,   154491,   151337, 72252492]))\n",
            "[@debug] dataset.py:391 in labelPreprocess()- self.class_n: 5\n",
            "[@debug] dataset.py:228 in create_load()\n",
            "         self.patches['train']['label'].shape: (7392, 32, 32)\n",
            "[@debug] dataset.py:229 in create_load()\n",
            "         np.unique(self.patches['train']['label'], return_counts = True): (array([0, 1, 2, 3, 4]), array([2501920,  332862,  580098,  410580, 3743948]))\n",
            "[@debug] dataset.py:230 in create_load()\n",
            "         self.patches['test']['label'].shape: (2528, 32, 32)\n",
            "[@debug] dataset.py:231 in create_load()\n",
            "         np.unique(self.patches['test']['label'], return_counts = True): (array([0, 1, 2, 3, 4]), array([ 788843,  107309,  154491,  151337, 1386692]))\n",
            "[@debug] dataset.py:236 in create_load()\n",
            "         np.unique(self.full_label_train,return_counts=True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                               array([ 2501920,   332862,   580098,   410580, 69629012]))\n",
            "[@debug] dataset.py:237 in create_load()- self.class_n: 5\n",
            "[@debug] dataset.py:576 in loadMask()\n",
            "         str(self.paramsTrain.path): 'dataset/lm_data'\n",
            "[@debug] dataset.py:578 in loadMask()- self.mask.shape: (8484, 8658)\n",
            "[@debug] train_and_evaluate.py:154 in preprocess()\n",
            "         self.paramsTrain.class_n: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SELECT VALIDATION SET FROM TRAIN SET\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] train_and_evaluate.py:162 in preprocess()\n",
            "         self.paramsTrain.val_set: True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] self.paramsTrain.val_set_mode = random\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:416 in val_set_get()\n",
            "         self.patches['train']['n']: 7392\n",
            "         self.patches['val']['n']: 1108\n",
            "[@debug] dataset.py:417 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (7392, 2)\n",
            "[@debug] dataset.py:426 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (6284, 2)\n",
            "[@debug] dataset.py:427 in val_set_get()\n",
            "         self.patches['val']['coords'].shape: (1108, 2)\n",
            "[@debug] train_and_evaluate.py:166 in preprocess()\n",
            "         self.data.patches['val']['coords'].shape: (1108, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== AUGMENTING TRAINING DATA\n",
            "[@debug] label_type = Nto1\n",
            "Before balancing:\n",
            "data.semantic_balance\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:453 in semantic_balance()\n",
            "         balance[\"coords\"].shape: (2800, 2)\n",
            "[@debug] dataset.py:457 in semantic_balance()\n",
            "         np.unique(self.full_label_train, return_counts = True): (array([0, 1, 2, 3, 4], dtype=uint8),\n",
            "                                                                  array([ 2501920,   332862,   580098,   410580, 69629012]))\n",
            "[@debug] dataset.py:463 in semantic_balance()\n",
            "         coords_classes.shape: (6284, 5)\n",
            "[@debug] dataset.py:465 in semantic_balance()\n",
            "         unique_train: array([0, 1, 2, 3, 4], dtype=uint8)\n",
            "[@debug] dataset.py:467 in semantic_balance()- bcknd_idx: 4\n",
            "[@debug] dataset.py:469 in semantic_balance()- psize: 32\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         patch_count: array([3703.,  532.,  856.,  698.,    0.])\n",
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 3703.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 0\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([2581, 3703]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (3703, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 532.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 1\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([5752,  532]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (532, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 856.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 2\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([5428,  856]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (856, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] dataset.py:488 in semantic_balance()\n",
            "         patch_count[clss]: 698.0\n",
            "[@debug] dataset.py:492 in semantic_balance()- clss: 3\n",
            "[@debug] dataset.py:495 in semantic_balance()\n",
            "         idxs.shape: (6284,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:496 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([5586,  698]))\n",
            "[@debug] dataset.py:501 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (698, 2)\n",
            "[@debug] dataset.py:502 in semantic_balance()- samples_per_class: 700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] clss = 3\n",
            "Balanced train unique (coords):\n",
            "[@debug] self.patches['train']['coords'].shape = (2800, 2)\n",
            "[@debug] self.data.patches['train']['coords'].shape = (2800, 2)\n",
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n",
            "[@debug] self.t_len = 12\n",
            "Initializing Model instance\n",
            "[@debug] self.mp = {'dense': {'recurrent_filters': 128, 'nb_dense_block': 2, 'growth_rate': 64, 'nb_layers_per_block': 1}, 'unet': {'recurrent_filters': 128, 'filter_size': 16}, 'atrous': {'recurrent_filters': 128, 'filter_size': 16, 'dilation_rate_mode': 'auto', 'dilation_rates': [1, 2, 4, 8]}}\n",
            "[@debug] self.stop_epoch = 400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] train_and_evaluate.py:138 in setModel()\n",
            "         self.model.name: PosixPath('results/model/lm/model_best_UUnetConvLSTM_mar_lm_dummy.h5')\n",
            "[@debug] train_and_evaluate.py:140 in setModel()\n",
            "         self.model.name: PosixPath('results/model/lm/model_best_UUnetConvLSTM_mar_lm_dummy.h5')\n",
            "[@debug] train_and_evaluate.py:142 in setModel()\n",
            "         self.model.class_n: 4\n",
            "[@debug] train_and_evaluate.py:143 in setModel()- self.data.class_n: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[@debug] self.data.class_n = 5\n",
            "[@debug] self.t_len = 12\n",
            "[@debug] self.model_t_len = 12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[@debug] K.int_shape(x) = (None, 12, 8, 8, 64)\n",
            "[@debug] K.int_shape(res2) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(p3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(d3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(x) = (None, 12, 16, 16, 32)\n",
            "[@debug] K.int_shape(res2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(p2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(d2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(x) = (None, 12, 32, 32, 16)\n",
            "[@debug] K.int_shape(res2) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(p1) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(d1) = (None, 32, 32, 16)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 32, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 12, 32, 32, 1 304         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 12, 32, 32, 1 64          time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 12, 32, 32, 1 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 12, 32, 32, 1 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 12, 32, 32, 1 64          time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 12, 32, 32, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 12, 16, 16, 1 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 12, 16, 16, 3 4640        time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 12, 16, 16, 3 128         time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 12, 16, 16, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 12, 8, 8, 32) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 12, 8, 8, 64) 18496       time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 12, 8, 8, 64) 256         time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 12, 8, 8, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 12, 4, 4, 64) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 4, 4, 256)    2950144     time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     147520      conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8, 8, 64)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 128)    0           activation_4[0][0]               \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 64)     73792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 32)   18464       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 16, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 64)   0           activation_6[0][0]               \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   18464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 16)   4624        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           activation_8[0][0]               \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   4624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 4)    68          activation_9[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,244,868\n",
            "Trainable params: 3,244,164\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "[@debug] model.py:237 in train()\n",
            "         data.patches['train']['coords'].shape: (2800, 2)\n",
            "[@debug] model.py:242 in train()- data.t_len: 12\n",
            "[@debug] model.py:243 in train()\n",
            "         data.full_ims_train.shape: (12, 8484, 8658, 2)\n",
            "[@debug] model.py:244 in train()- self.model_t_len: 12\n",
            "[@debug] dataset.py:400 in addPaddingToInput()\n",
            "         im.shape: (12, 8484, 8658, 2)\n",
            "[@debug] model.py:250 in train()\n",
            "         data.full_ims_train.shape: (12, 8484, 8658, 2)\n",
            "[@debug] model.py:253 in train()\n",
            "         self.name: PosixPath('results/model/lm/model_best_UUnetConvLSTM_mar_lm_dummy.h5')\n",
            "[@debug] model.py:308 in applyFitMethod()- self.class_n: 4\n",
            "[@debug] model.py:327 in applyFitMethod()\n",
            "         data.patches['train']['coords'].shape: (2800, 2)\n",
            "[@debug] model.py:328 in applyFitMethod()\n",
            "         data.patches['train']['coords'][0:16]: array([[1776, 3824],\n",
            "                                                       [4144, 6064],\n",
            "                                                       [3536, 7120],\n",
            "                                                       [3280, 2896],\n",
            "                                                       [2640, 6416],\n",
            "                                                       [1424, 4176],\n",
            "                                                       [6352, 1744],\n",
            "                                                       [3536, 7056],\n",
            "                                                       [5872, 4624],\n",
            "                                                       [5360, 5520],\n",
            "                                                       [1552, 4112],\n",
            "                                                       [2000, 6288],\n",
            "                                                       [2640, 2256],\n",
            "                                                       [1648, 4240],\n",
            "                                                       [3472, 7088],\n",
            "                                                       [4144, 6576]])\n",
            "[@debug] model.py:329 in applyFitMethod()\n",
            "         data.patches['val']['coords'][0:16]: array([[1520, 4112],\n",
            "                                                     [5072, 1296],\n",
            "                                                     [4272, 3504],\n",
            "                                                     [2000, 6480],\n",
            "                                                     [6512, 2768],\n",
            "                                                     [6736, 2864],\n",
            "                                                     [ 848, 5200],\n",
            "                                                     [4432, 4240],\n",
            "                                                     [2480, 4272],\n",
            "                                                     [6640, 2896],\n",
            "                                                     [3248, 3760],\n",
            "                                                     [3312, 2800],\n",
            "                                                     [6320, 2960],\n",
            "                                                     [4144, 5584],\n",
            "                                                     [4560, 1840],\n",
            "                                                     [ 816, 6480]])\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] model.py:342 in applyFitMethod()\n",
            "         data.patches['val']['coords'].shape: (1108, 2)\n",
            "[@debug] model.py:343 in applyFitMethod()\n",
            "         data.patches['val']['coords']: array([[1520, 4112],\n",
            "                                               [5072, 1296],\n",
            "                                               [4272, 3504],\n",
            "                                               ...,\n",
            "                                               [1104, 5328],\n",
            "                                               [6768, 2544],\n",
            "                                               [6032, 3216]])\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 175\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.1088 - accuracy: 0.3639"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  val_f1: [59.24 19.78  3.63 56.87]\n",
            "  val_precision: [76.96 12.5  83.13 41.27]\n",
            "  val_recall: [48.15 47.4   1.85 91.48]\n",
            "  mean_f1: 34.88\n",
            "oa 46.13\n",
            "Found best weights at epoch 1\n",
            "175/175 [==============================] - 53s 174ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.1088 - accuracy: 0.3639 - val_loss: 0.1058 - val_accuracy: 0.4078 - mean_f1: 34.8800\n",
            "Epoch 2/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0701 - accuracy: 0.2422"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  val_f1: [72.87 35.95 36.02 67.06]\n",
            "  val_precision: [92.87 22.35 99.98 54.47]\n",
            "  val_recall: [59.96 91.86 21.97 87.22]\n",
            "  mean_f1: 52.975\n",
            "oa 60.25\n",
            "Found best weights at epoch 2\n",
            "175/175 [==============================] - 28s 162ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0701 - accuracy: 0.2422 - val_loss: 0.0847 - val_accuracy: 0.3812 - mean_f1: 52.9750\n",
            "Epoch 3/70\n",
            "175/175 [==============================] - ETA: 0s - batch: 87.0000 - size: 16.0000 - loss: 0.0566 - accuracy: 0.2634"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 69\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  val_f1: [93.74 68.8  97.75 81.74]\n",
            "  val_precision: [94.39 71.15 99.91 75.43]\n",
            "  val_recall: [93.1  66.61 95.68 89.18]\n",
            "  mean_f1: 85.5075\n",
            "oa 90.68\n",
            "Found best weights at epoch 3\n",
            "175/175 [==============================] - 29s 166ms/step - batch: 87.0000 - size: 16.0000 - loss: 0.0566 - accuracy: 0.2634 - val_loss: 0.0487 - val_accuracy: 0.6025 - mean_f1: 85.5075\n",
            "Epoch 4/70\n",
            "141/175 [=======================>......] - ETA: 4s - batch: 70.0000 - size: 16.0000 - loss: 0.0511 - accuracy: 0.2763"
          ]
        }
      ]
    }
  ]
}