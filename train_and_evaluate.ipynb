{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set/blob/coords5/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5d3244-8ba1-4b20-9e05-65790ddcaad6"
      },
      "source": [
        "!pip install icecream\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/cv_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.0 icecream-2.1.1\n",
            "Collecting kora\n",
            "  Downloading kora-0.9.19-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting fastcore\n",
            "  Downloading fastcore-1.3.26-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Installing collected packages: fastcore, kora\n",
            "Successfully installed fastcore-1.3.26 kora-0.9.19\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb5ffeb-db25-4c13-dd73-609888677e82"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "355a04c5-1d20-4ad3-c071-de557ca435ce"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf FCN_ConvLSTM_Crop_Recognition_Open_Set\n",
        "  !git clone --branch coords5 https://github.com/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FCN_ConvLSTM_Crop_Recognition_Open_Set'...\n",
            "remote: Enumerating objects: 2189, done.\u001b[K\n",
            "remote: Counting objects: 100% (2189/2189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1618/1618), done.\u001b[K\n",
            "remote: Total 2189 (delta 1440), reused 1062 (delta 366), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2189/2189), 37.52 MiB | 29.35 MiB/s, done.\n",
            "Resolving deltas: 100% (1440/1440), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/cv_data /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18461916-1b98-4653-a0d1-29212fe8896e"
      },
      "source": [
        "os.chdir('/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mosaic.py.old',\n",
              " 'postprocessing.py',\n",
              " 'model_input_mode.py',\n",
              " 'model_best_UUnet4ConvLSTM_jun_cv_criteria_0_92',\n",
              " 'densnet_timedistributed.py',\n",
              " '__init__.py',\n",
              " 'keras_weighted_categorical_crossentropy.py',\n",
              " 'deb.py',\n",
              " 'model.py',\n",
              " 'modelArchitecture.py',\n",
              " 'main.py',\n",
              " 'patch_extractor.py',\n",
              " 'parameters',\n",
              " 'mosaic.py',\n",
              " 'metrics.py',\n",
              " 'monitor.py',\n",
              " 'dataset.py',\n",
              " 'generator.py',\n",
              " 'open_set.py',\n",
              " 'obj',\n",
              " 'dataSource.py',\n",
              " 'densnet.py',\n",
              " 'analysis']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from densnet import DenseNetFCN\n",
        "from densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from tensorflow.keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from tensorflow.keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#from datagenerator import DataGenerator\n",
        "from generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from dataSource import DataSource, SARSource, OpticalSource, Dataset, LEM, LEM2, CampoVerde, OpticalSourceWithClouds, Humidity\n",
        "from model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.parameters_reader import ParamsTrain\n",
        "\n",
        "from icecream import ic\n",
        "from monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from patch_extractor import PatchExtractor\n",
        "ic.configureOutput(includeContext=False)\n",
        "np.random.seed(2021)\n",
        "tf.random.set_seed(2021)\n",
        "\n",
        "from main import TrainTest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18b82085-c870-4a85-b557-727917031716"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Aug 22 23:03:57 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/parameters/parameters_reader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc0931e-d849-4a39-a9a8-5286ac596868"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/')\n",
        "paramsTrain.mim = MIMFixed_PaddedSeq()\n",
        "\n",
        "paramsTrain.getFullIms = True\n",
        "paramsTrain.coordsExtract = True\n",
        "paramsTrain.train = True\n",
        "\n",
        "paramsTrain.train_overlap_percentage = 0\n",
        "paramsTrain.trainGeneratorRandom = False\n",
        "paramsTrain.patch_len = 32\n",
        "paramsTrain.stride = int(paramsTrain.patch_len - paramsTrain.patch_len * paramsTrain.train_overlap_percentage)\n",
        "paramsTrain.patch_step_train = paramsTrain.stride\n",
        "paramsTrain.patch_step_test = paramsTrain.patch_len # to do: paramsTrain.getCalculatedParams() does these calculations\n",
        "\n",
        "paramsTrain.dataset = 'cv'\n",
        "paramsTrain.seq_date = 'jun'\n",
        "paramsTrain.path = Path(\"../../../dataset/dataset/\") / (paramsTrain.dataset + \"_data\")\n",
        "\n",
        "paramsTrain.test_overlap_percentage = 0\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "paramsTrain.openSetMethod = None\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n",
        "patchExtractor = PatchExtractor(paramsTrain, trainTest.ds)\t"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:115 in __init__()- self.seq_date: 'mar'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:174 in __init__()- self.stride: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['parameters_reader.py', 'save_nonaugmented_train_patches_unknownclasses.json', 'save_nonaugmented_train_patches.json', 'cv', 'twokkc_parameters_closedset_groupclasses.json', 'twokkc_parameters_openset.json', '__pycache__', 'twokkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches_lessclass8.json', 'allkkc_save_nonaugmented_train_patches.json', 'params_batchprocessing.py', 'parameters_openset_lessclass8.json', '__init__.py', 'params_reconstruct.py', 'no_mode.json', 'allkkc_parameters_openset.json', 'parameters_openset.json', 'parameters_closedset_groupclasses.json', 'parameters_openset_specifyunknownclasses.json', 'parameters_closedset_groupclasses_lessclass8.json']\n",
            "[@debug] self.seq_mode = fixed\n",
            "[@debug] self.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7fd425ecec10>\n",
            "[@debug] self.ds = <dataSource.CampoVerde object at 0x7fd4264cab10>\n",
            "20151029\n",
            "20151110\n",
            "20151122\n",
            "20151204\n",
            "20151216\n",
            "20160121\n",
            "20160214\n",
            "20160309\n",
            "20160321\n",
            "20160508\n",
            "20160520\n",
            "20160613\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[302, 314, 326, 338, 350, 21, 45, 69, 81, 129, 141, 165]\n",
            "[[0.05084 0.7197 ]\n",
            " [0.1053  0.807  ]\n",
            " [0.1764  0.8813 ]\n",
            " [0.2612  0.9395 ]\n",
            " [0.3562  0.979  ]\n",
            " [0.6685  0.9707 ]\n",
            " [0.843   0.8643 ]\n",
            " [0.96    0.6963 ]\n",
            " [0.99    0.598  ]\n",
            " [0.905   0.2068 ]\n",
            " [0.8364  0.1301 ]\n",
            " [0.66    0.02637]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <dataSource.SARSource object at 0x7fd425ff8e10>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('../../../dataset/dataset/cv_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('../../../dataset/dataset/cv_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqA-z0Ju9-xO"
      },
      "source": [
        "## Download or load sequence of images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaFQV6M9yKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88b28e97-2b48-4e29-fe12-ece010cd9ae5"
      },
      "source": [
        "if paramsTrain.getFullIms == True:\n",
        "  patchExtractor.getFullIms()\t\n",
        "else:\n",
        "  patchExtractor.fullImsLoad()\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8492, 7995, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20151029_S1',\n",
            "                                '20151110_S1',\n",
            "                                '20151122_S1',\n",
            "                                '20151204_S1',\n",
            "                                '20151216_S1',\n",
            "                                '20160121_S1',\n",
            "                                '20160214_S1',\n",
            "                                '20160309_S1',\n",
            "                                '20160321_S1',\n",
            "                                '20160508_S1',\n",
            "                                '20160520_S1',\n",
            "                                '20160613_S1']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151029_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1871337890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 4.172325134277344e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151029_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151029_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    45178,    51808,   131138,   438371,   155189,\n",
            "        5136068,     1007,   156217]))\n",
            "1 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151110_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.180419921875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.9267578125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 2.384185791015625e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151110_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151110_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1524080,    27056,    11783,   432952,   419824,\n",
            "         155189,  3386868,     1007,   156217]))\n",
            "2 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151122_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1802978515625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.7099609375\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 2.384185791015625e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151122_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151122_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1524080,    27056,    11783,   432952,   419824,\n",
            "         155189,  3386868,     1007,   156217]))\n",
            "3 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151204_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1793212890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.447265625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 1.1920928955078125e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151204_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151204_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  4496663,    35095,    18211,     2197,    11783,\n",
            "         366875,   419824,   155189,   451915,     1007,   156217]))\n",
            "4 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151216_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1737060546875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.373046875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 1.7881393432617188e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151216_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151216_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  4496663,    35095,    18211,     2197,    11783,\n",
            "         366875,   419824,   155189,   451915,     1007,   156217]))\n",
            "5 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160121_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.159912109375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 138.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 3.2186508178710938e-06\n",
            "../../../dataset/dataset/cv_data/labels/20160121_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160121_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2956904,     8039,    18211,     2197,     8859,\n",
            "         419824,   155189,  2388529,     1007,   156217]))\n",
            "6 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160214_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.171630859375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.4169921875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 7.748603820800781e-07\n",
            "../../../dataset/dataset/cv_data/labels/20160214_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160214_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2183414,     8039,   116684,     2197,     8006,\n",
            "         419824,   155189,  3064399,     1007,   156217]))\n",
            "7 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160309_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.188232421875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 2.869140625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 3.5762786865234375e-07\n",
            "../../../dataset/dataset/cv_data/labels/20160309_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160309_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    10049,   900649,  2084968,     2197,     8006,\n",
            "         419824,   155189,  2376870,     1007,   156217]))\n",
            "8 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160321_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.16064453125\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.5390625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160321_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160321_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    10049,   900649,  2084968,     2197,     8006,\n",
            "         419824,   155189,  2376870,     1007,   156217]))\n",
            "9 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160508_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.154541015625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.1572265625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160508_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160508_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2187712,  2771075,    57536,     2285,   236822,\n",
            "         525054,   155189,    22079,     1007,   156217]))\n",
            "10 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160520_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.16552734375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.634765625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160520_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160520_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2187712,  2771075,    57536,     2285,   236822,\n",
            "         525054,   155189,    22079,     1007,   156217]))\n",
            "11 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160613_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.140380859375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 4.57421875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 0.0\n",
            "../../../dataset/dataset/cv_data/labels/20160613_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160613_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1441022,  2573657,    57536,   225585,   525054,\n",
            "         155189,   979709,     1007,   156217]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataSource.py:369 in im_load()\n",
            "         patch[\"full_ims\"].shape: (12, 8492, 7995, 2)\n",
            "[@debug] dataSource.py:370 in im_load()\n",
            "         patch[\"full_label_ims\"].shape: (12, 8492, 7995)\n",
            "[@debug] dataSource.py:371 in im_load()\n",
            "         patch[\"full_ims\"].dtype: dtype('float16')\n",
            "[@debug] dataSource.py:372 in im_load()\n",
            "         patch[\"full_label_ims\"].dtype: dtype('int8')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] np.unique(patch['full_label_ims'],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([741342768,  17247080,   7809932,  12457060,    185790,     51702,\n",
            "         2462898,   5372125,   1862268,  24044169,     12084,   1874604]))\n",
            "0.0 1.0 0.1702\n",
            "[@debug] self.dataset.name = cv\n",
            "[@debug] self.dataset.scaler_name = cv\n",
            "[@debug] self.dataset.seq_mode = fixed\n",
            "[@debug] self.dataset.seq_date = jun\n",
            "[@debug] self.dataset.scaler_load = False\n",
            "[@debug] im.shape = (12, 8492, 7995, 2)\n",
            "[@debug] im_flat[mask_flat==1,:].shape = (38664648, 2)\n",
            "0.0001407 1.0 0.0779\n",
            "[@debug] im_norm.shape = (12, 8492, 7995, 2)\n",
            "FINISHED NORMALIZING, RESULT:\n",
            "-1.432 51.53 3.117\n",
            "[@debug] im.shape = (12, 8492, 7995)\n",
            "[@debug] mask_train.shape = (8492, 7995)\n",
            "[@debug] im.dtype = uint8\n",
            "[@debug] mask_train.dtype = uint8\n",
            "[@debug] im_train.shape = (12, 8492, 7995)\n",
            "Train masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11] [776057832   9399025   4170646   6930141    103494     34628   1280237\n",
            "   2371008    861648  12705225      8388    800208]\n",
            "Test masked unique/count [ 0  1  2  3  4  5  6  7  8  9 10 11] [780007416   7848055   3639286   5526919     82296     17074   1182661\n",
            "   3001117   1000620  11338944      3696   1074396]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:127 in getFullIms()\n",
            "         self.paramsTrain.path / 'full_ims/full_ims_test.npy': PosixPath('../../../dataset/dataset/cv_data/full_ims/full_ims_test.npy')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FPmIpS-Hqu"
      },
      "source": [
        "## Extract coords of image patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzJoNO896wl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da2f8c1-7384-46cb-dafd-7efac02c3576"
      },
      "source": [
        "\n",
        "if paramsTrain.coordsExtract == True:\n",
        "  patchExtractor.extract()\n",
        "\n",
        "del patchExtractor\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "STARTED PATCH EXTRACTION\n",
            "[@debug] gridx.shape = (250,)\n",
            "[@debug] gridy.shape = (266,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:205 in extract()\n",
            "         coords_train.shape: (4983, 2)\n",
            "         coords_test.shape: (4626, 2)\n",
            "[@debug] patch_extractor.py:206 in extract()\n",
            "         coords_train.dtype: dtype('int64')\n",
            "[@debug] patch_extractor.py:207 in extract()\n",
            "         coords_train[0]: array([7568,  656])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZztSJXG977M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fefe14-f33f-4b64-b1d4-56c089657a08"
      },
      "source": [
        "\ttrainTest.setData()\n",
        "\n",
        "\n",
        "\ttrainTest.preprocess(paramsTrain.model_name_id) # move into if\n",
        "\n",
        "\ttrainTest.setModel()\n",
        "\n",
        "\tif paramsTrain.train == True:\n",
        "\t\ttrainTest.train()\n",
        "\telse:\n",
        "\t\ttrainTest.modelLoad(paramsTrain.model_name_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:96 in __init__()- self.class_n: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] self.t_len = 12\n",
            "Initializing Dataset instance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] main.py:118 in setData()- self.data.class_n: 10\n",
            "[@debug] main.py:146 in preprocess()\n",
            "         self.model_name: '../results/convlstm_results/model/lm/model_best_UUnetConvLSTM_mar_lm_nomode.h5'\n",
            "[@debug] dataset.py:186 in create_load()\n",
            "         os.path.dirname(os.path.abspath(__file__)): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n",
            "[@debug] dataset.py:187 in create_load()\n",
            "         os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n",
            "[@debug] dataset.py:191 in create_load()\n",
            "         self.patches['train']['coords'].shape: (4983, 2)\n",
            "[@debug] dataset.py:284 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8),\n",
            "                                                                array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "                                                                         71804,   617076,      699,    66684]))\n",
            "[@debug] dataset.py:285 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8),\n",
            "                                                               array([65000618,   730790,  1199149,    25986,    88785,   312353,\n",
            "                                                                        83385,   362633,      308,    89533]))\n",
            "[@debug] dataset.py:289 in labelPreprocess()\n",
            "         self.paramsTrain.known_classes: array([ 1,  2,  3,  5,  6,  7,  8,  9, 10], dtype=uint8)\n",
            "[@debug] dataset.py:333 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8),\n",
            "                                                                array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "                                                                         71804,   617076,      699,    66684]))\n",
            "[@debug] dataset.py:339 in labelPreprocess()\n",
            "         self.classes: array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] np.unique(self.full_label_train, return_counts=True) = (array([ 0,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=uint8), array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "          71804,   617076,      699,    66684]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:343 in labelPreprocess()\n",
            "         self.labels2new_labels: {0: 0, 2: 1, 3: 2, 4: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8, 11: 9}\n",
            "         self.new_labels2labels: {0: 0, 1: 2, 2: 3, 3: 4, 4: 6, 5: 7, 6: 8, 7: 9, 8: 10, 9: 11}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Transforming labels2new_labels...\n",
            "Transformed labels2new_labels. Moving bcknd to last...\n",
            "[@debug] dict_filename = results/label_translations/new_labels2labels_cv_20160613_S1.pkl\n",
            "[@debug] self.new_labels2labels = {0: 0, 1: 2, 2: 3, 3: 4, 4: 6, 5: 7, 6: 8, 7: 9, 8: 10, 9: 11}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:364 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                                array([64671486,   710232,  1374508,    31550,   136800,   212701,\n",
            "                                                                         71804,   617076,      699,    66684]))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Moved bcknd to last\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:373 in labelPreprocess()\n",
            "         np.unique(self.full_label_train, return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                                array([  710232,  1374508,    31550,   136800,   212701,    71804,\n",
            "                                                                        617076,      699,    66684, 64671486]))\n",
            "[@debug] dataset.py:374 in labelPreprocess()\n",
            "         np.unique(self.full_label_test, return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                               array([  730790,  1199149,    25986,    88785,   312353,    83385,\n",
            "                                                                       362633,      308,    89533, 65000618]))\n",
            "[@debug] dataset.py:377 in labelPreprocess()- self.class_n: 10\n",
            "[@debug] dataset.py:215 in create_load()\n",
            "         self.patches['train']['label'].shape: (4983, 32, 32)\n",
            "[@debug] dataset.py:216 in create_load()\n",
            "         np.unique(self.patches['train']['label'], return_counts = True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
            "                                                                           array([ 710232, 1374508,   31550,  136800,  212701,   71804,  617076,\n",
            "                                                                                     699,   66684, 1880538]))\n",
            "[@debug] dataset.py:217 in create_load()\n",
            "         self.patches['test']['label'].shape: (4626, 32, 32)\n",
            "[@debug] dataset.py:218 in create_load()\n",
            "         np.unique(self.patches['test']['label'], return_counts = True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
            "                                                                          array([ 730790, 1199149,   25986,   88785,  312353,   83385,  362633,\n",
            "                                                                                    308,   89533, 1844102]))\n",
            "[@debug] dataset.py:223 in create_load()\n",
            "         np.unique(self.full_label_train,return_counts=True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                               array([  710232,  1374508,    31550,   136800,   212701,    71804,\n",
            "                                                                       617076,      699,    66684, 64671486]))\n",
            "[@debug] dataset.py:224 in create_load()- self.class_n: 10\n",
            "[@debug] main.py:151 in preprocess()- self.paramsTrain.class_n: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== SELECT VALIDATION SET FROM TRAIN SET\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] main.py:159 in preprocess()- self.paramsTrain.val_set: True\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] self.paramsTrain.val_set_mode = random\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:402 in val_set_get()\n",
            "         self.patches['train']['n']: 4983\n",
            "         self.patches['val']['n']: 747\n",
            "[@debug] dataset.py:403 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (4983, 2)\n",
            "[@debug] dataset.py:412 in val_set_get()\n",
            "         self.patches['train']['coords'].shape: (4236, 2)\n",
            "[@debug] dataset.py:413 in val_set_get()\n",
            "         self.patches['val']['coords'].shape: (747, 2)\n",
            "[@debug] main.py:163 in preprocess()\n",
            "         self.data.patches['val']['coords'].shape: (747, 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "=== AUGMENTING TRAINING DATA\n",
            "[@debug] label_type = Nto1\n",
            "Before balancing:\n",
            "data.semantic_balance\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:439 in semantic_balance()\n",
            "         balance[\"coords\"].shape: (6300, 2)\n",
            "[@debug] dataset.py:443 in semantic_balance()\n",
            "         np.unique(self.full_label_train, return_counts = True): (array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
            "                                                                  array([  710232,  1374508,    31550,   136800,   212701,    71804,\n",
            "                                                                          617076,      699,    66684, 64671486]))\n",
            "[@debug] dataset.py:449 in semantic_balance()\n",
            "         coords_classes.shape: (4236, 10)\n",
            "[@debug] dataset.py:451 in semantic_balance()\n",
            "         unique_train: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)\n",
            "[@debug] dataset.py:453 in semantic_balance()- bcknd_idx: 9\n",
            "[@debug] dataset.py:455 in semantic_balance()- psize: 32\n",
            "[@debug] dataset.py:468 in semantic_balance()\n",
            "         patch_count: array([1055., 1820.,   55.,  196.,  352.,  125.,  882.,    6.,  120.,\n",
            "                                0.])\n",
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 1055.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 0\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([3181, 1055]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (1055, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 1820.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 1\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([2416, 1820]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (1820, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()- patch_count[clss]: 55.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 2\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4181,   55]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (55, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 196.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 3\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4040,  196]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (196, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 352.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 4\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([3884,  352]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (352, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 125.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 5\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4111,  125]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (125, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 882.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 6\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([3354,  882]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (882, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()- patch_count[clss]: 6.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 7\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4230,    6]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (6, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] dataset.py:474 in semantic_balance()\n",
            "         patch_count[clss]: 120.0\n",
            "[@debug] dataset.py:478 in semantic_balance()- clss: 8\n",
            "[@debug] dataset.py:481 in semantic_balance()\n",
            "         idxs.shape: (4236,)\n",
            "         idxs.dtype: dtype('bool')\n",
            "[@debug] dataset.py:482 in semantic_balance()\n",
            "         np.unique(idxs, return_counts = True): (array([False,  True]), array([4116,  120]))\n",
            "[@debug] dataset.py:487 in semantic_balance()\n",
            "         balance[\"class_coords\"].shape: (120, 2)\n",
            "[@debug] dataset.py:488 in semantic_balance()- samples_per_class: 700\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] clss = 8\n",
            "Balanced train unique (coords):\n",
            "[@debug] self.patches['train']['coords'].shape = (6300, 2)\n",
            "[@debug] self.data.patches['train']['coords'].shape = (6300, 2)\n",
            "Initializing object...\n",
            "12 2\n",
            "[@debug] self.channel_n = 2\n",
            "[@debug] self.t_len = 12\n",
            "Initializing Model instance\n",
            "[@debug] self.mp = {'dense': {'recurrent_filters': 128, 'nb_dense_block': 2, 'growth_rate': 64, 'nb_layers_per_block': 1}, 'unet': {'recurrent_filters': 128, 'filter_size': 16}, 'atrous': {'recurrent_filters': 128, 'filter_size': 16, 'dilation_rate_mode': 'auto', 'dilation_rates': [1, 2, 4, 8]}}\n",
            "[@debug] self.stop_epoch = 400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] main.py:132 in setModel()\n",
            "         self.model.name: PosixPath('../results/convlstm_results/model/lm/../results/convlstm_results/model/lm/model_best_UUnetConvLSTM_mar_lm_nomode.h5')\n",
            "[@debug] main.py:134 in setModel()- self.model.class_n: 9\n",
            "[@debug] main.py:135 in setModel()- self.data.class_n: 10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] self.data.class_n = 10\n",
            "[@debug] self.t_len = 12\n",
            "[@debug] self.model_t_len = 12\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[@debug] K.int_shape(x) = (None, 12, 8, 8, 64)\n",
            "[@debug] K.int_shape(res2) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(p3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(d3) = (None, 8, 8, 64)\n",
            "[@debug] K.int_shape(x) = (None, 12, 16, 16, 32)\n",
            "[@debug] K.int_shape(res2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(p2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(d2) = (None, 16, 16, 32)\n",
            "[@debug] K.int_shape(x) = (None, 12, 32, 32, 16)\n",
            "[@debug] K.int_shape(res2) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(p1) = (None, 32, 32, 16)\n",
            "[@debug] K.int_shape(d1) = (None, 32, 32, 16)\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 12, 32, 32,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 12, 32, 32, 1 304         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 12, 32, 32, 1 64          time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 12, 32, 32, 1 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 12, 32, 32, 1 2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 12, 32, 32, 1 64          time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 12, 32, 32, 1 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 12, 16, 16, 1 0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 12, 16, 16, 3 4640        time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 12, 16, 16, 3 128         time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 12, 16, 16, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 12, 8, 8, 32) 0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_5 (TimeDistrib (None, 12, 8, 8, 64) 18496       time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 12, 8, 8, 64) 256         time_distributed_5[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 12, 8, 8, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_6 (TimeDistrib (None, 12, 4, 4, 64) 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv_lst_m2d (ConvLSTM2D)       (None, 4, 4, 256)    2950144     time_distributed_6[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose (Conv2DTranspo (None, 8, 8, 64)     147520      conv_lst_m2d[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 8, 8, 64)     256         conv2d_transpose[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 8, 8, 64)     0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 8, 8, 64)     0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 128)    0           activation_4[0][0]               \n",
            "                                                                 lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 8, 8, 64)     73792       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 8, 8, 64)     256         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 8, 8, 64)     0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 32)   18464       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 32)   128         conv2d_transpose_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 16, 16, 32)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 16, 16, 64)   0           activation_6[0][0]               \n",
            "                                                                 lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 32)   18464       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 16)   4624        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_transpose_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 32, 32, 16)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           activation_8[0][0]               \n",
            "                                                                 lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   4624        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 16)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 9)    153         activation_9[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,244,953\n",
            "Trainable params: 3,244,249\n",
            "Non-trainable params: 704\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "[@debug] model.py:243 in train()\n",
            "         data.patches['train']['coords'].shape: (6300, 2)\n",
            "[@debug] model.py:248 in train()- data.t_len: 12\n",
            "[@debug] model.py:249 in train()\n",
            "         data.full_ims_train.shape: (12, 8492, 7995, 2)\n",
            "[@debug] model.py:250 in train()- self.model_t_len: 12\n",
            "[@debug] dataset.py:386 in addPaddingToInput()\n",
            "         im.shape: (12, 8492, 7995, 2)\n",
            "[@debug] model.py:256 in train()\n",
            "         data.full_ims_train.shape: (12, 8492, 7995, 2)\n",
            "[@debug] model.py:311 in applyFitMethod()- self.class_n: 9\n",
            "[@debug] model.py:330 in applyFitMethod()\n",
            "         data.patches['train']['coords'].shape: (6300, 2)\n",
            "[@debug] model.py:331 in applyFitMethod()\n",
            "         data.patches['train']['coords'][0:16]: array([[5744, 1488],\n",
            "                                                       [5552, 2032],\n",
            "                                                       [5328, 3440],\n",
            "                                                       [6544, 1392],\n",
            "                                                       [5712, 1456],\n",
            "                                                       [4080, 3472],\n",
            "                                                       [6992, 2000],\n",
            "                                                       [2928, 2224],\n",
            "                                                       [ 432, 6160],\n",
            "                                                       [5680, 1456],\n",
            "                                                       [5680, 1488],\n",
            "                                                       [2288, 4976],\n",
            "                                                       [3984, 7664],\n",
            "                                                       [ 688, 5808],\n",
            "                                                       [5680, 1456],\n",
            "                                                       [1616, 4624]])\n",
            "[@debug] model.py:332 in applyFitMethod()\n",
            "         data.patches['val']['coords'][0:16]: array([[4048, 7472],\n",
            "                                                     [ 528, 6256],\n",
            "                                                     [ 496, 6288],\n",
            "                                                     [3632, 2736],\n",
            "                                                     [3536, 4464],\n",
            "                                                     [ 944, 5520],\n",
            "                                                     [7344,  976],\n",
            "                                                     [1776, 4240],\n",
            "                                                     [7344, 1040],\n",
            "                                                     [4752, 1808],\n",
            "                                                     [7824,  848],\n",
            "                                                     [3440, 5040],\n",
            "                                                     [4368, 3472],\n",
            "                                                     [3600, 2992],\n",
            "                                                     [1488, 4368],\n",
            "                                                     [4048, 3664]])\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] generator.py:170 in __init__()- self.batch_size: 16\n",
            "[@debug] generator.py:172 in __init__()- self.patch_size: 32\n",
            "[@debug] model.py:345 in applyFitMethod()\n",
            "         data.patches['val']['coords'].shape: (747, 2)\n",
            "[@debug] model.py:346 in applyFitMethod()\n",
            "         data.patches['val']['coords']: array([[4048, 7472],\n",
            "                                               [ 528, 6256],\n",
            "                                               [ 496, 6288],\n",
            "                                               ...,\n",
            "                                               [4304, 6416],\n",
            "                                               [1776, 4048],\n",
            "                                               [3024, 2096]])\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 393\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 393\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.2291 - accuracy: 0.3700"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [67.61 89.79 20.7   5.98 60.15 78.25 57.5   0.   32.74]\n",
            " — val_precision: [61.71 89.07 27.16 51.13 58.68 73.61 62.27  0.   30.59]\n",
            " — val_recall: [74.76 90.51 16.72  3.17 61.69 83.52 53.41  0.   35.22]\n",
            " — mean_f1: 45.857777777777784\n",
            "oa 72.86\n",
            "Found best weights at epoch 1\n",
            "393/393 [==============================] - 59s 97ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.2291 - accuracy: 0.3700 - val_loss: 0.1395 - val_accuracy: 0.2819 - mean_f1: 45.8578\n",
            "Epoch 2/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.1563 - accuracy: 0.2802"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [72.31 91.32 40.02 50.05 46.26 71.58 60.39  0.   31.13]\n",
            " — val_precision: [69.16 89.87 27.23 59.37 67.98 57.35 71.7   0.   22.56]\n",
            " — val_recall: [75.75 92.81 75.48 43.25 35.06 95.21 52.16  0.   50.2 ]\n",
            " — mean_f1: 51.45111111111111\n",
            "oa 74.69\n",
            "Found best weights at epoch 2\n",
            "393/393 [==============================] - 38s 96ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.1563 - accuracy: 0.2802 - val_loss: 0.1173 - val_accuracy: 0.2475 - mean_f1: 51.4511\n",
            "Epoch 3/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.1266 - accuracy: 0.2101"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [73.5  92.17 56.24 59.17 52.51 81.84 67.93  0.   47.35]\n",
            " — val_precision: [80.49 90.86 39.61 45.19 74.35 71.2  74.64  0.   33.21]\n",
            " — val_recall: [67.63 93.51 96.91 85.66 40.59 96.22 62.33  0.   82.43]\n",
            " — mean_f1: 58.96777777777778\n",
            "oa 77.9\n",
            "Found best weights at epoch 3\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.1266 - accuracy: 0.2101 - val_loss: 0.1017 - val_accuracy: 0.1883 - mean_f1: 58.9678\n",
            "Epoch 4/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.1033 - accuracy: 0.1749"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [77.51 92.6  78.34 61.92 69.44 85.81 70.89  0.   59.28]\n",
            " — val_precision: [81.38 91.61 65.21 47.45 86.34 77.35 77.04  0.   44.66]\n",
            " — val_recall: [73.99 93.6  98.07 89.1  58.07 96.34 65.65  0.   88.12]\n",
            " — mean_f1: 66.19888888888889\n",
            "oa 81.43\n",
            "Found best weights at epoch 4\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.1033 - accuracy: 0.1749 - val_loss: 0.0876 - val_accuracy: 0.1970 - mean_f1: 66.1989\n",
            "Epoch 5/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0870 - accuracy: 0.1645"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [78.49 93.1  84.72 68.11 78.77 87.67 74.42  0.   64.83]\n",
            " — val_precision: [84.79 92.19 74.36 53.51 89.31 80.01 76.67  0.   52.14]\n",
            " — val_recall: [73.07 94.03 98.43 93.66 70.45 96.96 72.31  0.   85.7 ]\n",
            " — mean_f1: 70.01222222222222\n",
            "oa 83.66\n",
            "Found best weights at epoch 5\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0870 - accuracy: 0.1645 - val_loss: 0.0784 - val_accuracy: 0.1871 - mean_f1: 70.0122\n",
            "Epoch 6/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0745 - accuracy: 0.1611"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [81.17 93.48 80.66 72.34 85.06 87.27 77.51  0.   64.39]\n",
            " — val_precision: [89.7  92.19 68.23 58.49 86.86 78.8  79.09  0.   59.72]\n",
            " — val_recall: [74.12 94.8  98.63 94.77 83.34 97.77 75.99  0.   69.87]\n",
            " — mean_f1: 71.32\n",
            "oa 85.59\n",
            "Found best weights at epoch 6\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0745 - accuracy: 0.1611 - val_loss: 0.0730 - val_accuracy: 0.1721 - mean_f1: 71.3200\n",
            "Epoch 7/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0658 - accuracy: 0.1609"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [82.45 94.62 89.26 74.11 88.27 92.83 80.62  0.   69.46]\n",
            " — val_precision: [90.05 94.3  81.38 60.21 86.04 88.68 80.22  0.   71.28]\n",
            " — val_recall: [76.04 94.94 98.82 96.35 90.62 97.37 81.03  0.   67.73]\n",
            " — mean_f1: 74.62444444444446\n",
            "oa 87.54\n",
            "Found best weights at epoch 7\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0658 - accuracy: 0.1609 - val_loss: 0.0654 - val_accuracy: 0.1821 - mean_f1: 74.6244\n",
            "Epoch 8/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0591 - accuracy: 0.1615"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [85.16 95.47 92.06 76.78 89.27 93.11 84.18  0.   73.39]\n",
            " — val_precision: [91.08 95.53 86.14 63.62 88.41 88.8  83.69  0.   72.04]\n",
            " — val_recall: [79.97 95.4  98.87 96.8  90.15 97.86 84.67  0.   74.79]\n",
            " — mean_f1: 76.60222222222222\n",
            "oa 89.4\n",
            "Found best weights at epoch 8\n",
            "393/393 [==============================] - 37s 94ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0591 - accuracy: 0.1615 - val_loss: 0.0594 - val_accuracy: 0.1885 - mean_f1: 76.6022\n",
            "Epoch 9/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0532 - accuracy: 0.1593"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [85.11 96.29 94.61 76.37 90.4  94.09 85.93  0.   77.97]\n",
            " — val_precision: [91.48 97.75 90.78 62.85 90.61 90.3  82.63  0.   71.5 ]\n",
            " — val_recall: [79.57 94.87 98.78 97.29 90.19 98.2  89.5   0.   85.72]\n",
            " — mean_f1: 77.86333333333333\n",
            "oa 90.21\n",
            "Found best weights at epoch 9\n",
            "393/393 [==============================] - 36s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0532 - accuracy: 0.1593 - val_loss: 0.0582 - val_accuracy: 0.1880 - mean_f1: 77.8633\n",
            "Epoch 10/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0496 - accuracy: 0.1603"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [86.48 96.63 94.61 77.72 90.25 92.04 87.96  0.   79.4 ]\n",
            " — val_precision: [91.82 96.94 90.54 64.55 90.66 86.43 87.39  0.   74.48]\n",
            " — val_recall: [81.72 96.32 99.05 97.66 89.84 98.42 88.54  0.   85.02]\n",
            " — mean_f1: 78.34333333333333\n",
            "oa 91.12\n",
            "Found best weights at epoch 10\n",
            "393/393 [==============================] - 37s 93ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0496 - accuracy: 0.1603 - val_loss: 0.0553 - val_accuracy: 0.1875 - mean_f1: 78.3433\n",
            "Epoch 11/70\n",
            "393/393 [==============================] - ETA: 0s - batch: 196.0000 - size: 16.0000 - loss: 0.0454 - accuracy: 0.1583"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n",
            "[@debug] generator.py:192 in __len__()- n_batches: 46\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " — val_f1: [87.27 96.78 93.04 81.02 91.55 93.16 87.74  0.   80.23]\n",
            " — val_precision: [92.99 97.87 87.95 69.66 90.66 88.57 84.4   0.   79.07]\n",
            " — val_recall: [82.21 95.71 98.75 96.83 92.47 98.26 91.35  0.   81.42]\n",
            " — mean_f1: 78.97666666666666\n",
            "oa 91.56\n",
            "Found best weights at epoch 11\n",
            "393/393 [==============================] - 36s 92ms/step - batch: 196.0000 - size: 16.0000 - loss: 0.0454 - accuracy: 0.1583 - val_loss: 0.0514 - val_accuracy: 0.1884 - mean_f1: 78.9767\n",
            "Epoch 12/70\n",
            "163/393 [===========>..................] - ETA: 18s - batch: 81.0000 - size: 16.0000 - loss: 0.0426 - accuracy: 0.1540"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lD8P03YG0IX"
      },
      "source": [
        "## Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im68QpP-JvbR"
      },
      "source": [
        "paramsMosaic = ParamsReconstruct(paramsTrain)\n",
        "\n",
        "paramsMosaic.mosaic_flag = True\n",
        "\n",
        "trainTest.evaluate(paramsMosaic)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}