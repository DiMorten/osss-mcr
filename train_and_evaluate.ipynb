{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set/blob/coords5/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a0b8790-c228-41b7-8ad2-9840fc686663"
      },
      "source": [
        "!pip install icecream\n",
        "#%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/cv_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.0 icecream-2.1.1\n",
            "TensorFlow 1.x selected.\n",
            "Collecting kora\n",
            "  Downloading kora-0.9.19-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting fastcore\n",
            "  Downloading fastcore-1.3.26-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Installing collected packages: fastcore, kora\n",
            "Successfully installed fastcore-1.3.26 kora-0.9.19\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bd553c2-5fb8-40bb-fb2f-730fcdae4e55"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "ef05059f-7e46-4fd0-8da7-650215b2e462"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf FCN_ConvLSTM_Crop_Recognition_Open_Set\n",
        "  !git clone --branch coords5 https://github.com/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FCN_ConvLSTM_Crop_Recognition_Open_Set'...\n",
            "remote: Enumerating objects: 2228, done.\u001b[K\n",
            "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 2228 (delta 9), reused 21 (delta 5), pack-reused 2201\u001b[K\n",
            "Receiving objects: 100% (2228/2228), 37.51 MiB | 39.15 MiB/s, done.\n",
            "Resolving deltas: 100% (1475/1475), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/cv_data /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "390eaf85-7a2d-4542-faf8-8ac010fcb5d2"
      },
      "source": [
        "os.chdir('/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['densnet.py',\n",
              " 'metrics.py',\n",
              " 'patch_extractor.py',\n",
              " 'keras_weighted_categorical_crossentropy.py',\n",
              " 'modelArchitecture.py',\n",
              " 'parameters',\n",
              " '__init__.py',\n",
              " 'postprocessing.py',\n",
              " 'deb.py',\n",
              " 'obj',\n",
              " 'analysis',\n",
              " 'monitor.py',\n",
              " 'main.py',\n",
              " 'mosaic.py',\n",
              " 'densnet_timedistributed.py',\n",
              " 'mosaic.py.old',\n",
              " 'train_openset.py',\n",
              " 'dataset.py',\n",
              " 'model.py',\n",
              " 'open_set.py',\n",
              " 'model_input_mode.py',\n",
              " 'generator.py',\n",
              " 'dataSource.py']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam,Adagrad \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from densnet import DenseNetFCN\n",
        "from densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from tensorflow.keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from tensorflow.keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from tensorflow.keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#from datagenerator import DataGenerator\n",
        "from generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from dataSource import DataSource, SARSource, OpticalSource, Dataset, LEM, LEM2, CampoVerde, OpticalSourceWithClouds, Humidity\n",
        "from model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.parameters_reader import ParamsTrain\n",
        "\n",
        "from icecream import ic\n",
        "from monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from patch_extractor import PatchExtractor\n",
        "ic.configureOutput(includeContext=False)\n",
        "np.random.seed(2021)\n",
        "#tf.random.set_seed(2021)\n",
        "\n",
        "from main import TrainTest"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2728b50a-a3db-49f4-d924-37b2af73aa31"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Aug 23 17:02:16 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/parameters/parameters_reader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae81da0-c376-4ba6-d179-a579019c43cc"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/')\n",
        "paramsTrain.mim = MIMFixed_PaddedSeq()\n",
        "\n",
        "paramsTrain.getFullIms = True\n",
        "paramsTrain.coordsExtract = True\n",
        "paramsTrain.train = True\n",
        "\n",
        "paramsTrain.train_overlap_percentage = 0\n",
        "paramsTrain.trainGeneratorRandom = False\n",
        "paramsTrain.patch_len = 32\n",
        "paramsTrain.stride = int(paramsTrain.patch_len - paramsTrain.patch_len * paramsTrain.train_overlap_percentage)\n",
        "paramsTrain.patch_step_train = paramsTrain.stride\n",
        "paramsTrain.patch_step_test = paramsTrain.patch_len # to do: paramsTrain.getCalculatedParams() does these calculations\n",
        "\n",
        "paramsTrain.dataset = 'cv'\n",
        "paramsTrain.seq_date = 'jun'\n",
        "paramsTrain.path = Path(\"../../../dataset/dataset/\") / (paramsTrain.dataset + \"_data\")\n",
        "\n",
        "paramsTrain.test_overlap_percentage = 0\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "paramsTrain.openSetMethod = None\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n",
        "patchExtractor = PatchExtractor(paramsTrain, trainTest.ds)\t"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:115 in __init__()- self.seq_date: 'mar'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:174 in __init__()- self.stride: 32\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['save_nonaugmented_train_patches_unknownclasses.json', 'parameters_closedset_groupclasses.json', '__init__.py', 'parameters_reader.py', 'parameters_closedset_groupclasses_lessclass8.json', 'twokkc_save_nonaugmented_train_patches.json', 'parameters_openset_lessclass8.json', 'cv', 'parameters_openset_specifyunknownclasses.json', 'parameters_openset.json', 'twokkc_parameters_openset.json', 'params_batchprocessing.py', '__pycache__', 'no_mode.json', 'allkkc_save_nonaugmented_train_patches.json', 'twokkc_parameters_closedset_groupclasses.json', 'save_nonaugmented_train_patches_lessclass8.json', 'save_nonaugmented_train_patches.json', 'allkkc_parameters_openset.json', 'params_reconstruct.py']\n",
            "[@debug] self.seq_mode = fixed\n",
            "[@debug] self.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7faf93286b10>\n",
            "[@debug] self.ds = <dataSource.CampoVerde object at 0x7faf97b22a10>\n",
            "20151029\n",
            "20151110\n",
            "20151122\n",
            "20151204\n",
            "20151216\n",
            "20160121\n",
            "20160214\n",
            "20160309\n",
            "20160321\n",
            "20160508\n",
            "20160520\n",
            "20160613\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[302, 314, 326, 338, 350, 21, 45, 69, 81, 129, 141, 165]\n",
            "[[0.05084 0.7197 ]\n",
            " [0.1053  0.807  ]\n",
            " [0.1764  0.8813 ]\n",
            " [0.2612  0.9395 ]\n",
            " [0.3562  0.979  ]\n",
            " [0.6685  0.9707 ]\n",
            " [0.843   0.8643 ]\n",
            " [0.96    0.6963 ]\n",
            " [0.99    0.598  ]\n",
            " [0.905   0.2068 ]\n",
            " [0.8364  0.1301 ]\n",
            " [0.66    0.02637]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <dataSource.SARSource object at 0x7faf972a6890>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('../../../dataset/dataset/cv_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('../../../dataset/dataset/cv_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqA-z0Ju9-xO"
      },
      "source": [
        "## Download or load sequence of images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaFQV6M9yKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e36d3d48-87a3-4f36-a66a-f270994fb424"
      },
      "source": [
        "if paramsTrain.getFullIms == True:\n",
        "  patchExtractor.getFullIms()\t\n",
        "else:\n",
        "  patchExtractor.fullImsLoad()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8492, 7995, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20151029_S1',\n",
            "                                '20151110_S1',\n",
            "                                '20151122_S1',\n",
            "                                '20151204_S1',\n",
            "                                '20151216_S1',\n",
            "                                '20160121_S1',\n",
            "                                '20160214_S1',\n",
            "                                '20160309_S1',\n",
            "                                '20160321_S1',\n",
            "                                '20160508_S1',\n",
            "                                '20160520_S1',\n",
            "                                '20160613_S1']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151029_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1871337890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 4.172325134277344e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151029_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151029_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,    45178,    51808,   131138,   438371,   155189,\n",
            "        5136068,     1007,   156217]))\n",
            "1 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151110_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.180419921875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.9267578125\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 2.384185791015625e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151110_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151110_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1524080,    27056,    11783,   432952,   419824,\n",
            "         155189,  3386868,     1007,   156217]))\n",
            "2 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151122_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1802978515625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.7099609375\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 2.384185791015625e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151122_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151122_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  1524080,    27056,    11783,   432952,   419824,\n",
            "         155189,  3386868,     1007,   156217]))\n",
            "3 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151204_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1793212890625\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 3.447265625\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 1.1920928955078125e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151204_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151204_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  4496663,    35095,    18211,     2197,    11783,\n",
            "         366875,   419824,   155189,   451915,     1007,   156217]))\n",
            "4 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20151216_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.1737060546875\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.373046875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 1.7881393432617188e-07\n",
            "../../../dataset/dataset/cv_data/labels/20151216_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20151216_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  4496663,    35095,    18211,     2197,    11783,\n",
            "         366875,   419824,   155189,   451915,     1007,   156217]))\n",
            "5 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160121_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.159912109375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 138.0\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 3.2186508178710938e-06\n",
            "../../../dataset/dataset/cv_data/labels/20160121_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160121_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2956904,     8039,    18211,     2197,     8859,\n",
            "         419824,   155189,  2388529,     1007,   156217]))\n",
            "6 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160214_S1.npy\n",
            "[@debug] patch[\"full_ims\"].dtype = float16\n",
            "[@debug] np.average(patch[\"full_ims\"][t_step]) = 0.171630859375\n",
            "[@debug] np.max(patch[\"full_ims\"][t_step]) = 1.4169921875\n",
            "[@debug] np.min(patch[\"full_ims\"][t_step]) = 7.748603820800781e-07\n",
            "../../../dataset/dataset/cv_data/labels/20160214_S1.tif\n",
            "[@debug] conf[\"path\"]/(self.dataSource.label_folder+\"/\"+label_names[t_step]+\".tif\") = ../../../dataset/dataset/cv_data/labels/20160214_S1.tif\n",
            "[@debug] np.unique(patch[\"full_label_ims\"][t_step],return_counts=True) = (array([ 0,  1,  2,  3,  4,  6,  7,  8,  9, 10, 11], dtype=int8), array([61778564,  2183414,     8039,   116684,     2197,     8006,\n",
            "         419824,   155189,  3064399,     1007,   156217]))\n",
            "7 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/cv_data/in_sar/20160309_S1.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FPmIpS-Hqu"
      },
      "source": [
        "## Extract coords of image patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzJoNO896wl"
      },
      "source": [
        "\n",
        "if paramsTrain.coordsExtract == True:\n",
        "  patchExtractor.extract()\n",
        "\n",
        "del patchExtractor\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZztSJXG977M"
      },
      "source": [
        "\ttrainTest.setData()\n",
        "\n",
        "\n",
        "\ttrainTest.preprocess(paramsTrain.model_name_id) # move into if\n",
        "\n",
        "\ttrainTest.setModel()\n",
        "\n",
        "\tif paramsTrain.train == True:\n",
        "\t\ttrainTest.train()\n",
        "\telse:\n",
        "    # copy pre trained model to paramsTrain.model_name_id\n",
        "\t\ttrainTest.modelLoad(paramsTrain.model_name_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lD8P03YG0IX"
      },
      "source": [
        "## Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im68QpP-JvbR"
      },
      "source": [
        "from parameters.params_reconstruct import ParamsReconstruct\n",
        "import pathlib\n",
        "\n",
        "pathlib.Path('results/spatial_results').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "paramsMosaic = ParamsReconstruct(paramsTrain)\n",
        "\n",
        "paramsMosaic.mosaic_flag = True\n",
        "paramsMosaic.open_set_mode = False\n",
        "\n",
        "trainTest.evaluate(paramsMosaic)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}