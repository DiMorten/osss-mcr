{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set/blob/coords4/train_and_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ7UjI3YD4w8"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZd_oJYCkmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1e73fce-d70f-42a7-c0d4-b62bdb02f0e4"
      },
      "source": [
        "!pip install icecream\n",
        "%tensorflow_version 1.x\n",
        "import os\n",
        "!pip install kora\n",
        "from kora import drive\n",
        "import time\n",
        "!pip install colorama\n",
        "\n",
        "ds_path='/content/drive/My Drive/PhD/datasets/cv_data/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.7/dist-packages (2.1.1)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.4.4)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.0.5)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from icecream) (0.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: kora in /usr/local/lib/python3.7/dist-packages (0.9.19)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.7/dist-packages (from kora) (1.3.24)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from kora) (5.5.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.1.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastcore->kora) (21.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (57.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->kora) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->kora) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->kora) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastcore->kora) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->kora) (0.7.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cosqh5n5Pewo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29b58a26-9e0e-4c44-8819-6738b21b110a"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "a2a817bc-1c36-4c10-8717-ca2d1054b290"
      },
      "source": [
        "git_clone = True\n",
        "\n",
        "if git_clone == True:\n",
        "  os.chdir('/content')\n",
        "  %rm -rf FCN_ConvLSTM_Crop_Recognition_Open_Set\n",
        "  !git clone --branch coords4 https://github.com/DiMorten/FCN_ConvLSTM_Crop_Recognition_Open_Set.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'FCN_ConvLSTM_Crop_Recognition_Open_Set'...\n",
            "remote: Enumerating objects: 1911, done.\u001b[K\n",
            "remote: Counting objects: 100% (1911/1911), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1391/1391), done.\u001b[K\n",
            "remote: Total 1911 (delta 1237), reused 976 (delta 335), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1911/1911), 37.35 MiB | 25.84 MiB/s, done.\n",
            "Resolving deltas: 100% (1237/1237), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdj6CiT0Dz9l"
      },
      "source": [
        "## Download images into proper folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q1eoQFaYvB4"
      },
      "source": [
        "!cp -r /content/drive/MyDrive/PhD/datasets/cv_data /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvzH-luqPoiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447ce586-3647-4c18-8e4f-0c6be9393b7d"
      },
      "source": [
        "os.chdir('/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src')\n",
        "os.getcwd()\n",
        "os.listdir()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['keras_weighted_categorical_crossentropy.py',\n",
              " 'mosaic.py',\n",
              " 'patch_extractor.py',\n",
              " '__init__.py',\n",
              " 'metrics.py',\n",
              " 'model_best_UUnet4ConvLSTM_jun_cv_criteria_0_92',\n",
              " 'mosaic.py.old',\n",
              " 'densnet.py',\n",
              " 'analysis',\n",
              " 'dataset.py',\n",
              " 'monitor.py',\n",
              " 'densnet_timedistributed.py',\n",
              " 'deb.py',\n",
              " 'model_input_mode.py',\n",
              " 'model.py',\n",
              " 'generator.py',\n",
              " 'main.py',\n",
              " 'obj',\n",
              " 'parameters']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUsDu9hhDZT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0d612f-0063-4e1b-8848-8280181c1eaf"
      },
      "source": [
        "from colorama import init\n",
        "init()\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout, Conv2DTranspose\n",
        "# from keras.callbacks import ModelCheckpoint , EarlyStopping\n",
        "from keras.optimizers import Adam,Adagrad \n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "import keras\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "import cv2\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras import metrics\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,f1_score,accuracy_score,classification_report\n",
        "# Local\n",
        "from densnet import DenseNetFCN\n",
        "from densnet_timedistributed import DenseNetFCNTimeDistributed\n",
        "\n",
        "#from metrics import fmeasure,categorical_accuracy\n",
        "import deb\n",
        "from keras_weighted_categorical_crossentropy import weighted_categorical_crossentropy, sparse_accuracy_ignoring_last_label, weighted_categorical_crossentropy_ignoring_last_label, categorical_focal_ignoring_last_label, weighted_categorical_focal_ignoring_last_label\n",
        "from keras.models import load_model\n",
        "from keras.layers import ConvLSTM2D, UpSampling2D, multiply\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.regularizers import l1,l2\n",
        "import time\n",
        "import pickle\n",
        "#from keras_self_attention import SeqSelfAttention\n",
        "import pdb\n",
        "import pathlib\n",
        "from pathlib import Path, PureWindowsPath\n",
        "from keras.layers import Conv3DTranspose, Conv3D\n",
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "#from datagenerator import DataGenerator\n",
        "from generator import DataGenerator, DataGeneratorWithCoords, DataGeneratorWithCoordsRandom\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "sys.path.append('../../../dataset/dataset/patches_extract_script/')\n",
        "from dataSource import DataSource, SARSource, OpticalSource, Dataset, LEM, LEM2, CampoVerde, OpticalSourceWithClouds, Humidity\n",
        "from model_input_mode import MIMFixed, MIMVarLabel, MIMVarSeqLabel, MIMVarLabel_PaddedSeq, MIMFixedLabelAllLabels, MIMFixed_PaddedSeq\n",
        "from parameters.parameters_reader import ParamsTrain\n",
        "\n",
        "from icecream import ic\n",
        "from monitor import Monitor, MonitorNPY, MonitorGenerator, MonitorNPYAndGenerator\n",
        "import natsort\n",
        "from model import NetModel, ModelFit, ModelLoadGeneratorWithCoords\n",
        "from dataset import Dataset, DatasetWithCoords\n",
        "\n",
        "from patch_extractor import PatchExtractor\n",
        "ic.configureOutput(includeContext=False)\n",
        "np.random.seed(2021)\n",
        "tf.set_random_seed(2021)\n",
        "\n",
        "from main import TrainTest"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "[@debug] parameters_reader.py:92 in __init__()- self.seq_date: 'mar'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:151 in __init__()- self.stride: 25\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['parameters_openset.json', 'parameters_reader.py', 'save_nonaugmented_train_patches_lessclass8.json', '__pycache__', 'parameters_closedset_groupclasses_lessclass8.json', 'params_batchprocessing.py', '__init__.py', 'twokkc_parameters_openset.json', 'parameters_closedset_groupclasses.json', 'twokkc_save_nonaugmented_train_patches.json', 'parameters_openset_specifyunknownclasses.json', 'twokkc_parameters_closedset_groupclasses.json', 'cv', 'parameters_openset_lessclass8.json', 'params_reconstruct.py', 'allkkc_parameters_openset.json', 'save_nonaugmented_train_patches.json', 'allkkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches_unknownclasses.json', 'no_mode.json']\n",
            "[@debug] paramsTrain.seq_mode = fixed\n",
            "[@debug] paramsTrain.mim = <model_input_mode.MIMFixed_PaddedSeq object at 0x7f29d00ea6d0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIs_yF23Psa_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e88f724a-fd8f-45c0-9dc6-8e641a203361"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jul 31 19:51:19 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ODvyAOie5NU"
      },
      "source": [
        "## Set parameters\n",
        "\n",
        "Parameters can be modified in /content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/parameters/parameters_reader.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On6HSUJwDsCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f117e622-4629-48ac-f757-9b44f255d7af"
      },
      "source": [
        "\n",
        "\n",
        "paramsTrain = ParamsTrain('parameters/')\n",
        "paramsTrain.mim = MIMFixed_PaddedSeq()\n",
        "\n",
        "paramsTrain.getFullIms = True\n",
        "paramsTrain.coordsExtract = True\n",
        "paramsTrain.train = True\n",
        "\n",
        "paramsTrain.train_overlap_percentage = 0\n",
        "paramsTrain.trainGeneratorRandom = False\n",
        "paramsTrain.patch_len = 32\n",
        "\n",
        "paramsTrain.dataset = 'cv'\n",
        "paramsTrain.seq_date = 'jun'\n",
        "\n",
        "paramsTrain.dataSource = SARSource()\n",
        "\n",
        "trainTest = TrainTest(paramsTrain)\n",
        "\n",
        "patchExtractor = PatchExtractor(paramsTrain, trainTest.ds)\t\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:92 in __init__()- self.seq_date: 'mar'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "self.known_classes [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] parameters_reader.py:151 in __init__()- self.stride: 25\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['parameters_openset.json', 'parameters_reader.py', 'save_nonaugmented_train_patches_lessclass8.json', '__pycache__', 'parameters_closedset_groupclasses_lessclass8.json', 'params_batchprocessing.py', '__init__.py', 'twokkc_parameters_openset.json', 'parameters_closedset_groupclasses.json', 'twokkc_save_nonaugmented_train_patches.json', 'parameters_openset_specifyunknownclasses.json', 'twokkc_parameters_closedset_groupclasses.json', 'cv', 'parameters_openset_lessclass8.json', 'params_reconstruct.py', 'allkkc_parameters_openset.json', 'save_nonaugmented_train_patches.json', 'allkkc_save_nonaugmented_train_patches.json', 'save_nonaugmented_train_patches_unknownclasses.json', 'no_mode.json']\n",
            "[@debug] self.ds = <dataSource.LEM object at 0x7f29d00ead10>\n",
            "[@debug] dataSource.name = SARSource\n",
            "self.im_list ['20170413_S1', '20170519_S1', '20170612_S1', '20170706_S1', '20170811_S1', '20170916_S1', '20171010_S1', '20171115_S1', '20171209_S1', '20180114_S1', '20180219_S1', '20180315_S1']\n",
            "fixed mar\n",
            "[@debug] self.t_len = 12\n",
            "20170413\n",
            "20170519\n",
            "20170612\n",
            "20170706\n",
            "20170811\n",
            "20170916\n",
            "20171010\n",
            "20171115\n",
            "20171209\n",
            "20180114\n",
            "20180219\n",
            "20180315\n",
            "dotys_sin_cos.shape (12, 2)\n",
            "[103, 139, 163, 187, 223, 259, 283, 319, 343, 14, 50, 74]\n",
            "[[0.9917   0.4104  ]\n",
            " [0.849    0.142   ]\n",
            " [0.6763   0.03214 ]\n",
            " [0.4744   0.000663]\n",
            " [0.1897   0.1079  ]\n",
            " [0.01993  0.3604  ]\n",
            " [0.00414  0.564   ]\n",
            " [0.133    0.84    ]\n",
            " [0.2998   0.958   ]\n",
            " [0.611    0.988   ]\n",
            " [0.8726   0.8335  ]\n",
            " [0.975    0.6562  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:17 in __init__()\n",
            "         self.dataSource: <dataSource.SARSource object at 0x7f29d00eafd0>\n",
            "[@debug] patch_extractor.py:26 in __init__()\n",
            "         self.conf['path']/self.label_folder/\"/\": PosixPath('/')\n",
            "[@debug] patch_extractor.py:35 in __init__()\n",
            "         self.conf[\"in_npy_path\"]: PosixPath('../../../dataset/dataset/lm_data/in_sar')\n",
            "[@debug] patch_extractor.py:43 in __init__()\n",
            "         self.conf[\"train\"][\"mask\"][\"dir\"]: PosixPath('../../../dataset/dataset/lm_data/TrainTestMask.tif')\n",
            "[@debug] patch_extractor.py:44 in __init__()\n",
            "         os.getcwd(): '/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqA-z0Ju9-xO"
      },
      "source": [
        "## Download or load sequence of images\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaFQV6M9yKS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "d94c684d-cf3d-47a6-eed8-b01a5971cea4"
      },
      "source": [
        "if paramsTrain.getFullIms == True:\n",
        "  patchExtractor.getFullIms()\t\n",
        "else:\n",
        "  patchExtractor.fullImsLoad()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[@debug] patch_extractor.py:90 in getFullIms()\n",
            "         patch[\"full_ims\"].shape: (12, 8484, 8658, 2)\n",
            "[@debug] patch_extractor.py:91 in getFullIms()\n",
            "         self.dataset.im_list: ['20170413_S1',\n",
            "                                '20170519_S1',\n",
            "                                '20170612_S1',\n",
            "                                '20170706_S1',\n",
            "                                '20170811_S1',\n",
            "                                '20170916_S1',\n",
            "                                '20171010_S1',\n",
            "                                '20171115_S1',\n",
            "                                '20171209_S1',\n",
            "                                '20180114_S1',\n",
            "                                '20180219_S1',\n",
            "                                '20180315_S1']\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 0\n",
            "[@debug] conf[\"in_npy_path\"]/(im_names[t_step]+\".npy\") = ../../../dataset/dataset/lm_data/in_sar/20170413_S1.npy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-723faed84226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mparamsTrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFullIms\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpatchExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetFullIms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mpatchExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullImsLoad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/networks/convlstm_networks/train_src/patch_extractor.py\u001b[0m in \u001b[0;36mgetFullIms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0madd_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \t\tpatch=self.dataset.im_load(patch,self.dataset.im_list,\n\u001b[0;32m---> 96\u001b[0;31m \t\t\tself.dataset.label_list,add_id,self.conf) # replace patch[full_ims] for self.full_ims\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \t\tpatch[\"full_ims\"] = self.dataSource.clip_undesired_values(\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/patches_extract_script/dataSource.py\u001b[0m in \u001b[0;36mim_load\u001b[0;34m(self, patch, im_names, label_names, add_id, conf)\u001b[0m\n\u001b[1;32m    352\u001b[0m                         \u001b[0mdeb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in_npy_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                         \u001b[0;31m#patch[\"full_ims\"][t_step] = np.load(conf[\"in_npy_path\"]+names[t_step]+\".npy\")[:,:,:2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                         \u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_ims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"in_npy_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m                         \u001b[0;31m#patch[\"full_ims\"][t_step] = np.load(conf[\"in_npy_path\"]+names[t_step]+\".npy\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                         \u001b[0mdeb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"full_ims\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FCN_ConvLSTM_Crop_Recognition_Open_Set/dataset/dataset/patches_extract_script/dataSource.py\u001b[0m in \u001b[0;36mim_load\u001b[0;34m(self, filename, conf)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfull_ims\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mim_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../dataset/dataset/lm_data/in_sar/20170413_S1.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FPmIpS-Hqu"
      },
      "source": [
        "## Extract coords of image patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzJoNO896wl"
      },
      "source": [
        "\n",
        "if paramsTrain.coordsExtract == True:\n",
        "  patchExtractor.extract()\n",
        "\n",
        "del patchExtractor\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZztSJXG977M"
      },
      "source": [
        "\n",
        "model_name_id = 'model_best_' + paramsTrain.model_type + '_' + \\\n",
        "    paramsTrain.seq_date + '_' + paramsTrain.dataset + '_' + \\\n",
        "    paramsTrain.model_name + '.h5'\n",
        "\n",
        "\n",
        "trainTest.setData()\n",
        "trainTest.setModel()\n",
        "\n",
        "trainTest.preprocess() # move into if\n",
        "if paramsTrain.train == True:\n",
        "  trainTest.train()\n",
        "else:\n",
        "  trainTest.modelLoad(model_name_id)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lD8P03YG0IX"
      },
      "source": [
        "## Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im68QpP-JvbR"
      },
      "source": [
        "trainTest.evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}